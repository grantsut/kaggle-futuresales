{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a push notification with Pushbullet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "def pushbullet_message(title, body):\n",
    "    msg = {\"type\": \"note\", \"title\": title, \"body\": body}\n",
    "    TOKEN = 'o.eE2zQwESe8DAJM0IlglDUdkTpmYkYT2L'\n",
    "    resp = requests.post('https://api.pushbullet.com/v2/pushes', \n",
    "                         data=json.dumps(msg),\n",
    "                         headers={'Authorization': 'Bearer ' + TOKEN,\n",
    "                                  'Content-Type': 'application/json'})\n",
    "    if resp.status_code != 200:\n",
    "        raise Exception('Error',resp.status_code)\n",
    "    else:\n",
    "        print ('Message sent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and saving snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_categories = pd.read_csv(\"data/item_categories.csv\")\n",
    "items = pd.read_csv(\"data/items.csv\")\n",
    "sales_train = pd.read_csv(\"data/sales_train.csv\")\n",
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "shops = pd.read_csv(\"data/shops.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in hdf5 format\n",
    "item_categories.to_hdf(\"data/item_categories.h5\",key=\"item_categories\",mode=\"w\")\n",
    "items.to_hdf(\"data/items.h5\",\"items\",mode=\"w\")\n",
    "sales_train.to_hdf(\"data/sales_train.h5\",\"sales_train\",mode=\"w\")\n",
    "sample_submission.to_hdf(\"data/sample_submission.h5\",\"sample_submission\",mode=\"w\")\n",
    "shops.to_hdf(\"data/shops.h5\",\"shops\",mode=\"w\")\n",
    "test.to_hdf(\"data/test.h5\",\"test\",mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from hdf5 format (separate files for simplicity)\n",
    "item_categories = pd.read_hdf(\"data/item_categories.h5\")\n",
    "items = pd.read_hdf(\"data/items.h5\")\n",
    "sales_train = pd.read_hdf(\"data/sales_train.h5\")\n",
    "sample_submission = pd.read_hdf(\"data/sample_submission.h5\")\n",
    "shops = pd.read_hdf(\"data/shops.h5\")\n",
    "test = pd.read_hdf(\"data/test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the item categories xls to csv while adding integer encoding of categories\n",
    "cat = pd.read_excel('data_eng/item_categories_enhanced.xls', header=1)\n",
    "cat['supercategory_id'] = cat['supercategory'].factorize()[0]\n",
    "cat['platform_id'] = cat['platform'].factorize()[0]\n",
    "cat.to_csv('data_eng/item_categories_enhanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickles\n",
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate shops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://www.kaggle.com/dlarionov/feature-engineering-xgboost\n",
    "\n",
    "# Якутск Орджоникидзе, 56\n",
    "train.loc[train.shop_id == 0, 'shop_id'] = 57\n",
    "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
    "# Якутск ТЦ \"Центральный\"\n",
    "train.loc[train.shop_id == 1, 'shop_id'] = 58\n",
    "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
    "# Жуковский ул. Чкалова 39м²\n",
    "train.loc[train.shop_id == 10, 'shop_id'] = 11\n",
    "test.loc[test.shop_id == 10, 'shop_id'] = 11\n",
    "\n",
    "# From https://www.kaggle.com/tylerssssss/feature-engineering-lightgbm\n",
    "\n",
    "train.loc[train.shop_id == 0, 'shop_id'] = 57\n",
    "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
    "\n",
    "train.loc[train.shop_id == 1, 'shop_id'] = 58\n",
    "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
    "\n",
    "train.loc[train.shop_id == 40, 'shop_id'] = 39\n",
    "test.loc[test.shop_id == 40, 'shop_id'] = 39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers and 1 item with a negative sales price\n",
    "sales_train = sales_train[(sales_train.item_price < 500000) & (sales_train.item_price > 0)]\n",
    "sales_train = sales_train[sales_train.item_cnt_day < 1001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First word & artist name extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'items' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2f478c94bdfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m def add_name_features(\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactorize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfillna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m99\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"artist_name_or_first_word\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprune_quantile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m ):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'items' is not defined"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "def add_name_features(\n",
    "    matrix, factorize=True, items=items, fillna_value=-99, feature_name=\"artist_name_or_first_word\",\n",
    "    prune_quantile=0.25\n",
    "):\n",
    "    # This extracts artist names for music categories and adds them as a feature.\n",
    "    def extract_artist(st):\n",
    "\n",
    "        st = st.strip()\n",
    "        if st.startswith(\"V/A\"):\n",
    "            artist = \"V/A\"\n",
    "        elif st.startswith(\"СБ\"):\n",
    "            artist = \"СБ\"\n",
    "        else:\n",
    "            # Retrieves artist names using the double space or all uppercase pattern\n",
    "            mus_artist_dubspace = re.compile(r\".{2,}?(?=\\s{2,})\")\n",
    "            match_dubspace = mus_artist_dubspace.match(st)\n",
    "            mus_artist_capsonly = re.compile(r\"^([^a-zа-я]+\\s)+\")\n",
    "            match_capsonly = mus_artist_capsonly.match(st)\n",
    "            candidates = [match_dubspace, match_capsonly]\n",
    "            candidates = [m[0] for m in candidates if m is not None]\n",
    "            # Sometimes one of the patterns catches some extra words so choose the shortest one\n",
    "            if len(candidates):\n",
    "                artist = min(candidates, key=len)\n",
    "            else:\n",
    "                # If neither of the previous patterns found something, use the dot-space pattern\n",
    "                mus_artist_dotspace = re.compile(r\".{2,}?(?=\\.\\s)\")\n",
    "                match = mus_artist_dotspace.match(st)\n",
    "                if match:\n",
    "                    artist = match[0]\n",
    "                else:\n",
    "                    artist = \"\"\n",
    "        artist = artist.upper()\n",
    "        artist = re.sub(r\"[^A-ZА-Я ]||\\bTHE\\b\", \"\", artist)\n",
    "        artist = re.sub(r\"\\s{2,}\", \" \", artist)\n",
    "        artist = artist.strip()\n",
    "        return artist\n",
    "\n",
    "    def first_word(string):\n",
    "        # This cleans the string of special characters, excess spaces and stopwords then extracts the first word\n",
    "        all_stopwords = stopwords.words(\"russian\")\n",
    "        all_stopwords = all_stopwords + stopwords.words(\"english\")\n",
    "        string = re.sub(r\"[^\\w\\s]\", \"\", string)\n",
    "        string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "        tokens = string.lower().split()\n",
    "        tokens = [t for t in tokens if t not in all_stopwords]\n",
    "        token = tokens[0] if len(tokens) > 0 else \"\"\n",
    "        return token\n",
    "\n",
    "    music_categories = [55, 56, 57, 58, 59, 60]\n",
    "    items.loc[items.item_category_id.isin(music_categories), feature_name] = items.loc[items.item_category_id.isin(music_categories), \"item_name\"].apply(\n",
    "        extract_artist\n",
    "    )\n",
    "\n",
    "    items.loc[items[feature_name] == \"\", feature_name] = \"other music\"\n",
    "\n",
    "    items.loc[~items.item_category_id.isin(music_categories), feature_name] = items.loc[~items.item_category_id.isin(music_categories), \"item_name\"].apply(\n",
    "        first_word\n",
    "    )\n",
    "\n",
    "    items.loc[items[feature_name] == \"\", feature_name] = \"other non-music\"\n",
    "\n",
    "    if factorize:\n",
    "        items[feature_name] = items[feature_name].factorize(na_sentinel=fillna_value)[0]\n",
    "\n",
    "    matrix = matrix.merge(items[[\"item_id\", feature_name]], on=\"item_id\", how=\"left\",)\n",
    "    if fillna_value is not None:\n",
    "        matrix[feature_name] = matrix[feature_name].fillna(fillna_value)\n",
    "    \n",
    "    if prune_quantile>0:  # replace low-occurence words / artists by a category marker\n",
    "        vc = matrix['artist_name_or_first_word'].value_counts().rename('first_word_vcs')\n",
    "        matrix = matrix.merge(vc, left_on='artist_name_or_first_word', right_index=True, how='left')\n",
    "        prune_mask = matrix.first_word_vcs<=matrix['first_word_vcs'].quantile(prune_quantile)\n",
    "        matrix.loc[prune_mask, 'artist_name_or_first_word'] = -matrix.loc[prune_mask, 'item_category_id']\n",
    "        matrix = matrix.drop(columns='first_word_vcs')\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bag of word representations of item names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17297 words\n"
     ]
    }
   ],
   "source": [
    "lexical_features = False\n",
    "if lexical_features is not False:\n",
    "    # Item name correction code\n",
    "    if (dev_skip == False) & (lexical_features == True):\n",
    "        import re\n",
    "\n",
    "        def name_correction(x):\n",
    "            x = x.lower()\n",
    "            x = x.partition(\"[\")[0]\n",
    "            x = x.partition(\"(\")[0]\n",
    "            x = re.sub(\"[^A-Za-z0-9А-Яа-я]+\", \" \", x)\n",
    "            x = x.replace(\"  \", \" \")\n",
    "            x = x.strip()\n",
    "            return x\n",
    "\n",
    "        items[\"item_name\"] = items[\"item_name\"].apply(lambda x: name_correction(x))\n",
    "\n",
    "        # Function to create matrix of token representations of item names\n",
    "        def create_item_id_bow_matrix(items):\n",
    "            # Adds word token features to the items dataframe, taken from the item names\n",
    "\n",
    "            # Fit a count vectorizer and create the bag of words matrix\n",
    "            from nltk.corpus import stopwords\n",
    "            from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "            russian_stopwords = stopwords.words(\"russian\")\n",
    "            vectorizer = CountVectorizer(stop_words=russian_stopwords)\n",
    "            X = vectorizer.fit_transform(items.loc[:, \"item_name\"])\n",
    "\n",
    "            # Convert the matrix to pandas sparse matrix format and concatenate it to the items matrix\n",
    "            X = pd.DataFrame.sparse.from_spmatrix(X)\n",
    "            items = pd.concat([items, X], axis=1)\n",
    "\n",
    "            # Create appropriate column names for the token features\n",
    "            print(f\"{len(vectorizer.vocabulary_)} words\")\n",
    "            featuremap = {\n",
    "                col: \"token_\" + token\n",
    "                for col, token in zip(\n",
    "                    range(len(vectorizer.vocabulary_)), vectorizer.get_feature_names()\n",
    "                )\n",
    "            }\n",
    "            items = items.rename(columns=featuremap)\n",
    "\n",
    "            return items\n",
    "\n",
    "        items_bow = create_item_id_bow_matrix(items)\n",
    "        items_bow = items_bow.drop(columns=[\"item_name\", \"item_category_id\"])\n",
    "        # Drop any tokens which only occur once\n",
    "        items_bow = items_bow.drop(columns=items_bow.columns[(items_bow.sum(axis=0) < 2)])\n",
    "        if bow_features:\n",
    "            df = df.merge(items_bow, on=\"item_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 5], [2, 4, 6]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(list, zip((1,2), (3,4), (5,6))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item name similarity feature\n",
    "Calculates the mean sales of the n items with names most similar to each item, lagged by 1 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create itemname similarity matrix\n",
    "if (dev_skip == False) & (lexical_features == True):\n",
    "    if load_data == False:\n",
    "        # Convert to sparse matrix, drop first item_id column (sparse matrix multiplication much faster than dense)\n",
    "        from scipy.sparse import csr_matrix\n",
    "\n",
    "        ib = csr_matrix(items_bow.to_numpy()[:, 1:])\n",
    "        # Compute dot product of BOW token matrix\n",
    "        itemname_similarity = np.dot(ib, ib.T)\n",
    "        itemname_similarity = pd.DataFrame.sparse.from_spmatrix(\n",
    "            itemname_similarity, index=items.item_id, columns=items.item_id\n",
    "        )\n",
    "    else:\n",
    "        itemname_similarity = pd.read_hdf(\"data/itemname_similarity.h5\")\n",
    "\n",
    "    del items_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing.dummy as mp # Using .dummy version of multiprocessing module because thread-based but not process-based parallelism worked on Windows\n",
    "\n",
    "if (dev_skip==False) & (lexical_features==True):\n",
    "    \n",
    "    neighbours_list = [1,3]\n",
    "    load_filename = f'data/similar_item_features/closest_itemname_ME_1.pk1.gz'\n",
    "    save_filename = f'data/similar_item_features/closest_itemname_ME_1.pk1.gz'\n",
    "    \n",
    "    create_new = True \n",
    "    if load_data==True:\n",
    "        create_new = False\n",
    "        try:\n",
    "            dfstore = pd.read_pickle(load_filename)\n",
    "        except FileNotFoundError:\n",
    "            print(\"Saved features not found, creating from scratch.\")\n",
    "            create_new = True\n",
    "    if create_new==True:\n",
    "        \n",
    "        dfstore = df.loc[:,['date_block_num','item_id','item_cnt_month']]\n",
    "        \n",
    "        # This works faster with a dense array for some reason\n",
    "        if pd.api.types.is_sparse(itemname_similarity[0]):\n",
    "            itsim = itemname_similarity.sparse.to_dense()\n",
    "        else:\n",
    "            itsim = itemname_similarity\n",
    "        \n",
    "        for lag in lags:\n",
    "\n",
    "            storelist = []\n",
    "            \n",
    "            for date_block_num in tqdm(range(3,35)):\n",
    "                \n",
    "                print(f\"Date block {date_block_num}, lag {lag}\")\n",
    "                \n",
    "                ids = dfstore.loc[dfstore.date_block_num==date_block_num,'item_id'].unique()\n",
    "\n",
    "                # Get subset of items in lag month\n",
    "                ids_prev = dfstore.loc[dfstore.date_block_num==(date_block_num-lag),'item_id'].unique()\n",
    "                \n",
    "                # Define a function to be used with the map function. Returns a dictionary of feature values for the current item_id, date_block_num and lag\n",
    "                def sim_name_target(item_id):\n",
    "                    tmpdict = {'date_block_num': date_block_num, 'item_id': item_id}\n",
    "                    # Make set of ids without current item\n",
    "                    ids_other = ids_prev[ids_prev!=item_id]\n",
    "                    # Get similarity values for current item\n",
    "                    itsim_prev = itsim.loc[item_id,ids_other]\n",
    "                    \n",
    "                    for neighbours in neighbours_list:\n",
    "                        \n",
    "                        item_featurename = f'item_id-{neighbours}closestitemname-ME-lag{lag}'\n",
    "\n",
    "                        # Get top n similar items\n",
    "                        itsim_prev_largest = itsim_prev.nlargest(neighbours)\n",
    "                        # Remove zero values\n",
    "                        itsim_prev_largest = itsim_prev_largest.loc[itsim_prev_largest>0]\n",
    "                        # Get target values for similar items, save\n",
    "                        targets_mean = dfstore.loc[(dfstore.date_block_num==(date_block_num-lag)) & (dfstore.item_id.isin(itsim_prev_largest.index)),['item_cnt_month']].mean()\n",
    "                        tmpdict[item_featurename] = targets_mean.item()\n",
    "                    return tmpdict\n",
    "\n",
    "                pool = mp.Pool()\n",
    "                tmplist = pool.map(sim_name_target, list(ids))\n",
    "                # Add returned dictionary list to store list\n",
    "                storelist = storelist + tmplist\n",
    "            \n",
    "            # Convert list of dicts to dataframe\n",
    "            dftmp = pd.DataFrame(storelist)\n",
    "            # Merge results with dfstore and save\n",
    "            dfstore = dfstore.merge(dftmp, how='left', on=['date_block_num', 'item_id'])\n",
    "            filename = f'data/similar_item_features/similar_items_ME_lag_{lag}.pk1.gz'\n",
    "            dfstore.to_pickle(filename)\n",
    "\n",
    "        try: \n",
    "            dfstore = dfstore.drop(columns='item_cnt_month')\n",
    "        except KeyError:\n",
    "            pass\n",
    "        dfstore = reduce_mem_usage(dfstore)\n",
    "        dfstore.to_pickle(save_filename)\n",
    "\n",
    "    df = df.merge(dfstore, how=\"left\", on=[\"date_block_num\", \"item_id\"])\n",
    "    \n",
    "    df.to_pickle(\"checkpoints/dfcheckpoint_6.pk1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shop cities and item subcategories\n",
    "(from https://www.kaggle.com/dlarionov/feature-engineering-xgboost) \\\n",
    "\\\n",
    "Observations:\n",
    "\n",
    "* Each shop_name starts with the city name.\n",
    "* Each category contains type and subtype in its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "shops.loc[shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\n",
    "shops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\n",
    "shops.loc[shops.city == '!Якутск', 'city'] = 'Якутск'\n",
    "shops['city_code'] = LabelEncoder().fit_transform(shops['city'])\n",
    "shop_labels = shops[['shop_id','city_code']]\n",
    "\n",
    "item_categories['split'] = item_categories['item_category_name'].str.split('-')\n",
    "item_categories['type'] = item_categories['split'].map(lambda x: x[0].strip())\n",
    "item_categories['type_code'] = LabelEncoder().fit_transform(item_categories['type'])\n",
    "# if subtype is nan then type\n",
    "item_categories['subtype'] = item_categories['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "item_categories['subtype_code'] = LabelEncoder().fit_transform(item_categories['subtype'])\n",
    "item_cat_labels = item_categories[['item_category_id','type_code', 'subtype_code']]\n",
    "\n",
    "shop_labels.to_csv('data/shop_labels.csv')\n",
    "shop_labels.to_hdf('data/shop_labels.h5','shop_labels', mode='w')\n",
    "item_cat_labels.to_csv('data/item_cat_labels.csv')\n",
    "item_cat_labels.to_hdf('data/item_cat_labels.h5','item_cat_labels', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagged feature (e.g. target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag_feature(df, feature_series, grouping_fields, lag, fillna=None):\n",
    "    '''\n",
    "    Lag a feature in \"feature_series\" by a specific amount \"lag\" and add it to datatable \"df\".\n",
    "    Missing values caused by inconsistencies between items and shops in different date blocks\n",
    "    are filled by the method specified by \"fillna\".\n",
    "    \n",
    "    Arguments:\n",
    "    fillna: Missing value fill method, options \"none\", \"ffill_only\" (fill with last available value),\n",
    "    \"ffill_bfill\" (fill with last present value then fill remaining values with next available value)\n",
    "    \n",
    "    '''\n",
    "    feature_series = feature_series.copy()\n",
    "    \n",
    "    feature_name = feature_series.name + '-lag_' + str(lag)\n",
    "    feature_series.name = feature_name\n",
    "    \n",
    "    feature_series = feature_series.reset_index()\n",
    "    \n",
    "    if type(grouping_fields) not in (str, list):\n",
    "        raise TypeError\n",
    "    if len(grouping_fields)==0:\n",
    "        feature_series['date_block_num'] += lag\n",
    "        return df.merge(feature_series, on=['date_block_num'], how='left')\n",
    "    if type(grouping_fields)==str:\n",
    "        grouping_fields = [grouping_fields]\n",
    "        \n",
    "    feature_series['date_block_num'] += lag\n",
    "    \n",
    "    df = df.merge(feature_series, on=['date_block_num'] + grouping_fields, how='left')\n",
    "    \n",
    "    if fillna == 'ffill_bfill':\n",
    "        df[feature_name] = df.groupby(grouping_fields)[feature_name].fillna(method='ffill').fillna(method='bfill')\n",
    "    elif fillna == 'ffill_only':\n",
    "        df[feature_name] = df.groupby(grouping_fields)[feature_name].fillna(method='ffill')\n",
    "    elif type(fillna) is int or type(fillna) is float:\n",
    "        df[feature_name] = df.groupby(grouping_fields)[feature_name].fillna(fillna)\n",
    "    elif fillna == None:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create series of target (item_cnt_month) then add lagged versions with add_lag_feature\n",
    "if dev_skip==False:\n",
    "    targetseries = df.loc[:,['date_block_num', 'item_id', 'shop_id', 'item_cnt_month']]\n",
    "    targetseries = targetseries.set_index(['date_block_num', 'item_id', 'shop_id'])\n",
    "    targetseries = targetseries['item_cnt_month']\n",
    "    for lag in tqdm([1,2,3,12]):\n",
    "        df = add_lag_feature(df, targetseries, ['item_id', 'shop_id'], lag, fillna=0)\n",
    "    del(targetseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean encoding\n",
    "Use the rolling method somehow or just use the mean for each month and lag the feature by 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean encode items, shops and categories by month and then lag with the add_lags function\n",
    "item_ME = train.groupby(['date_block_num','item_id']).item_cnt_month.mean().rename('item_id_ME')\n",
    "shop_ME = train.groupby(['date_block_num','shop_id']).item_cnt_month.mean().rename('shop_id_ME')\n",
    "item_cat_ME = train.groupby(['date_block_num','item_category_id']).item_cnt_month.mean().rename('item_category_id_ME')\n",
    "date_block_num_ME = train.groupby(['date_block_num']).item_cnt_month.mean().rename('date_block_num_ME')\n",
    "shop_category_id_ME = df.groupby(['date_block_num','shop_id','item_category_id']).item_cnt_month.mean().rename('shop_id-item_category_id-ME')\n",
    "shop_type_ME = df.groupby(['date_block_num','shop_id','type_code']).item_cnt_month.mean().rename('shop_id-type_code-ME')\n",
    "shop_subtype_ME = df.groupby(['date_block_num','shop_id','subtype_code']).item_cnt_month.mean().rename('shop_id-subtype_code-ME')\n",
    "\n",
    "lags = [1,2,3,12]\n",
    "\n",
    "for lag in lags:\n",
    "    train = add_lag_feature(train, item_ME, 'item_id', lag, fillna='ffill_bfill')\n",
    "    train = add_lag_feature(train, shop_ME, 'shop_id', lag, fillna='ffill_bfill')\n",
    "    train = add_lag_feature(train, item_cat_ME, 'item_category_id', lag, fillna='ffill_bfill')\n",
    "    train = add_lag_feature(train, date_block_num_ME, '', lag, fillna='ffill_bfill')\n",
    "    df = add_lag_feature(df, shop_category_id_ME, ['shop_id','item_category_id'], lag, fillna='ffill_bfill')\n",
    "    df = add_lag_feature(df, shop_type_ME, ['shop_id','type_code'], lag, fillna='ffill_bfill')\n",
    "    df = add_lag_feature(df, shop_subtype_ME, ['shop_id','subtype_code'], lag, fillna='ffill_bfill')\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-month rolling mean encoding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_train_test(sales_train, test):\n",
    "    # Create a train set with all items and all shops in all date blocks.\n",
    "    # Aggregate sales to the month level\n",
    "    sales_train_grouped = sales_train.groupby(\n",
    "        [\"date_block_num\", \"item_id\", \"shop_id\"]\n",
    "    ).agg({\"item_cnt_day\": \"sum\"})\n",
    "    sales_train_grouped = sales_train_grouped.rename(\n",
    "        columns={\"item_cnt_day\": \"item_cnt_month\"}\n",
    "    )\n",
    "\n",
    "    # Create sets of items, shops and date blocks\n",
    "    item_ids = set(sales_train.item_id).union(set(test.item_id))\n",
    "    shop_ids = set(sales_train.shop_id).union(set(test.shop_id))\n",
    "    date_block_nums = set(sales_train.date_block_num).union(set([34]))\n",
    "\n",
    "    # Create all permutations as indexes\n",
    "    indexdataframe = pd.DataFrame(\n",
    "        np.array(list(itertools.product(date_block_nums, item_ids, shop_ids))),\n",
    "        columns=[\"date_block_num\", \"item_id\", \"shop_id\"],\n",
    "    )\n",
    "\n",
    "    m = indexdataframe.merge(\n",
    "        sales_train_grouped, how=\"left\", on=[\"date_block_num\", \"item_id\", \"shop_id\"]\n",
    "    )\n",
    "    m.item_cnt_month = m.item_cnt_month.fillna(0)\n",
    "\n",
    "    shop_first_sales = (\n",
    "        train.groupby(\"shop_id\").date_block_num.min().rename(\"shop_first_month\")\n",
    "    )\n",
    "    shop_last_sales = (\n",
    "        train.groupby(\"shop_id\").date_block_num.max().rename(\"shop_last_month\")\n",
    "    )\n",
    "    item_first_sales = (\n",
    "        train.groupby(\"item_id\").date_block_num.min().rename(\"item_first_month\")\n",
    "    )\n",
    "    m = m.merge(shop_first_sales, on=\"shop_id\", how=\"left\")\n",
    "    m = m.merge(shop_last_sales, on=\"shop_id\", how=\"left\")\n",
    "    m = m.merge(item_first_sales, on=\"item_id\", how=\"left\")\n",
    "\n",
    "    mask = (\n",
    "        (m.date_block_num < m.shop_first_month)\n",
    "        | (m.date_block_num < m.item_first_month)\n",
    "        | (m.date_block_num > m.shop_last_month)\n",
    "    )\n",
    "\n",
    "    m = m.drop(columns=['shop_first_month', 'shop_last_month', 'item_first_month'])\n",
    "    \n",
    "    m.loc[mask, \"item_cnt_month\"] = np.nan\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = create_full_train_test(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual expanding mean feature (not using pandas expanding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs = {\"item_cnt_month\":\"mean\"}\n",
    "newname = 'shop_id_item_category_id_expanding_ME'\n",
    "groupers = [\"shop_id\", \"item_category_id\"]\n",
    "features = []\n",
    "for dbn in tqdm(range(1, 35)):\n",
    "    ids = matrix.query(f\"date_block_num=={dbn}\")['item_id'].unique()\n",
    "    f_temp = (\n",
    "        matrix.loc[(matrix.date_block_num<dbn) & (matrix.item_id.isin(ids)), :]\n",
    "        .groupby(groupers)\n",
    "        .agg(aggs)\n",
    "        .rename(columns={'item_cnt_month':newname})\n",
    "    )\n",
    "    f_temp[\"date_block_num\"] = dbn\n",
    "    features.append(f_temp)\n",
    "features = pd.concat(features).reset_index()\n",
    "\n",
    "features = fu.reduce_mem_usage(features)\n",
    "\n",
    "matrix = matrix.merge(features, on=[\"date_block_num\"] + groupers, how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom functions commented out below should have been replaced with the general function \"add_rolling_ME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_rolling_item_shop_ME(matrix, window = 3, min_periods=1, ewm=False):\n",
    "#     ''' Creates a rolling or exponential weighted mean item_cnt_month feature for each\n",
    "#     item_id-shop_id combination and merges it with a feature matrix. Assumes the existence of complete\n",
    "#     matrix of monthly shop-item counts \"m\". Parameter \"window\" acts as the halflife parameter if\n",
    "#     ewm=True'''\n",
    "#     im = m.groupby(['shop_id', 'item_id','date_block_num']).item_cnt_month.mean()\n",
    "#     if ewm:\n",
    "#         imr = im.groupby(['shop_id', 'item_id']).ewm(halflife=window, min_periods=min_periods).mean()\n",
    "#         feat_name = f\"shop_item_ME_ewm_hl_{window}\"\n",
    "#     else:\n",
    "#         imr = im.groupby(['shop_id', 'item_id']).rolling(window=window, min_periods=min_periods).mean()\n",
    "#         feat_name = f\"shop_item_ME_rol_win_{window}\"\n",
    "#     im = im.reset_index()\n",
    "#     im[feat_name] = imr.to_numpy()\n",
    "#     im = im.drop(columns='item_cnt_month')\n",
    "#     im['date_block_num'] += 1\n",
    "#     matrix = matrix.merge(im, on=['date_block_num', 'shop_id', 'item_id'], how='left')\n",
    "#     return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_rolling_item_ME(matrix, window = 3, min_periods=1, ewm=False):\n",
    "#     ''' Creates a rolling mean item_cnt_month feature for each item_id and merges it\n",
    "#     with a feature matrix. Assumes the existence of complete matrix of monthly shop-item\n",
    "#     counts \"m\" '''\n",
    "#     im = m.groupby(['item_id','date_block_num']).item_cnt_month.mean()\n",
    "#     if ewm:\n",
    "#         imr = im.groupby(['item_id']).ewm(halflife=window, min_periods=min_periods).mean()\n",
    "#         feat_name = f\"item_id_ME_ewm_hl_{window}\"\n",
    "#     else:\n",
    "#         imr = im.groupby(['item_id']).rolling(window=window, min_periods=min_periods).mean()\n",
    "#         feat_name = f\"item_id_ME_rol_win_{window}\"\n",
    "#     im = im.reset_index()\n",
    "#     im[feat_name] = imr.to_numpy()\n",
    "#     im = im.drop(columns='item_cnt_month')\n",
    "#     im['date_block_num'] += 1\n",
    "#     matrix = matrix.merge(im, on=['date_block_num', 'item_id'], how='left')\n",
    "#     return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rolling_ME(\n",
    "    matrix, features, window=3, min_periods=1, ewm=False, source_matrix=None\n",
    "):\n",
    "    \"\"\"Add a rolling mean item_cnt_month feature for a specificed categorical feature\n",
    "    or features. Calculates using the feature matrix and therefore does not insert zeros\n",
    "    for features with zero sales in a specific month (use feature specific rolling ME\n",
    "    functions for rolling item or item-shop features)\"\"\"\n",
    "    if type(features) != list:\n",
    "        raise TypeError(\"features argument must be a list\")\n",
    "    if source_matrix is None:\n",
    "        source_matrix = matrix\n",
    "    im = source_matrix.groupby(features + [\"date_block_num\"]).item_cnt_month.mean()\n",
    "    if ewm:\n",
    "        imr = im.groupby(features).ewm(halflife=window, min_periods=min_periods).mean()\n",
    "        feat_name = f\"{'_'.join(features)}_ME_ewm_hl_{window}\"\n",
    "    else:\n",
    "        imr = im.groupby(features).rolling(window=window, min_periods=min_periods).mean()\n",
    "        feat_name = f\"{'_'.join(features)}_ME_rol_win_{window}\"\n",
    "    im = im.reset_index()\n",
    "    im[feat_name] = imr.to_numpy()\n",
    "    im = im.drop(columns=\"item_cnt_month\")\n",
    "    im[\"date_block_num\"] += 1\n",
    "    matrix = matrix.merge(im, on=[\"date_block_num\"] + features, how=\"left\")\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [2, 6, 12]\n",
    "for window in tqdm(windows, desc=\"shop_item\"):\n",
    "    matrix = add_rolling_ME(\n",
    "        matrix, features=[\"shop_id\", \"item_id\"], window=window, source_matrix=m\n",
    "    )\n",
    "for window in tqdm(windows):\n",
    "    matrix = add_rolling_ME(matrix, features=[\"item_id\"], window=window, source_matrix=m)\n",
    "for features in tqdm(\n",
    "    [\n",
    "        \"shop_id\",\n",
    "        \"supercategory_id\",\n",
    "        \"platform_id\",\n",
    "        \"item_category_id\",\n",
    "        \"digital\",\n",
    "        [\"shop_id\", \"item_category_id\"],\n",
    "    ]\n",
    "):\n",
    "    for window in tqdm(windows):\n",
    "        matrix = add_rolling_ME(matrix, features, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [1]\n",
    "for window in tqdm(windows):\n",
    "    matrix = add_rolling_ME(\n",
    "        matrix, features=[\"shop_id\", \"item_id\"], window=window, ewm=True, source_matrix=m\n",
    "    )\n",
    "for window in tqdm(windows):\n",
    "    matrix = add_rolling_ME(\n",
    "        matrix, features=[\"item_id\"], window=window, ewm=True, source_matrix=m\n",
    "    )\n",
    "for feature in tqdm(\n",
    "    [\"shop_id\", \"supercategory_id\", \"platform_id\", \"item_category_id\", \"digital\"]\n",
    "):\n",
    "    for window in tqdm(windows):\n",
    "        matrix = add_rolling_ME(matrix, feature, window, ewm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(m, windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple periodicity feature (i.e. date block mod 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonality feature \n",
    "train['date_block_month'] = train.date_block_num % 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Days in current month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "_uuid": "e23f0201056b73368e3b70d4c36c6bb9e4a55291"
   },
   "outputs": [],
   "source": [
    "days_in_month = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "train['days_in_month'] = train['date_block_month'].map(days_in_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean item price in previous month\n",
    "Mean is calculated as the mean of all item sales rather than the mean of the mean price at each shop \\\n",
    "Also possible to include further lags, giving models opportunity to calculate changes in price over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_revenue_all_shops = df.groupby(['date_block_num','item_id'])['item_revenue_month'].sum()\n",
    "item_count_all_shops = df.groupby(['date_block_num','item_id'])['item_cnt_month'].sum()\n",
    "mean_item_price_all_shops = item_revenue_all_shops / item_count_all_shops\n",
    "mean_item_price_all_shops = mean_item_price_all_shops.rename('mean_item_price_all_shops')\n",
    "\n",
    "lags = [1,2,3,12]\n",
    "\n",
    "# Missing entries backfilled then forward filled\n",
    "for lag in lags:\n",
    "    df = add_lag_feature(df, mean_item_price_all_shops, 'item_id', lag, fillna='ffill_bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time since first / last sale of an item, or an item in a shop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time since first appearance of an item can be calculated as a simple groupby operation.\\\n",
    "Other \"time since\" features can not be calculated in this way however. Use one of the other routines which also calculates this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Months since first appearance of item, calculated by a groupby-transform operation (fast!)\n",
    "train['item_since_first_sale'] = train.groupby('item_id')['date_block_num'].transform(lambda x: x - x.min())\n",
    "train['item_since_first_sale'] = train['item_since_first_sale'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell calculates the time since the first sale of an item in a specific shop.\\\n",
    "Slow, better options are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time since first appearance of item at a specific shop\n",
    "store = pd.DataFrame()\n",
    "ts = time.time()\n",
    "gruppy = train[['date_block_num','shop_id','item_id','item_cnt_month']].groupby(['shop_id','item_id'])\n",
    "for group, items in gruppy:\n",
    "    items['shop_item_since_first_sale'] = items.date_block_num - items.date_block_num[items.item_cnt_month>0].min()\n",
    "    store = store.append(items)\n",
    "items['shop_item_since_first_sale'] = items['shop_item_since_first_sale'].fillna(0)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row iterating code for calculating time from first and last shop-item sale combination.\\\n",
    "Faster version using iteration over a groupby object is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3458a7056c963167760921417d1f863f074f2b39"
   },
   "outputs": [],
   "source": [
    "matrix = train.copy()\n",
    "ts = time.time()\n",
    "\n",
    "# Shop / item combination section\n",
    "cachefirst_shop_item = {}\n",
    "cachelast_shop_item = {}\n",
    "matrix['shop_item_last_sale'] = -1\n",
    "matrix['shop_item_first_sale'] = -1\n",
    "matrix['shop_item_last_sale'] = matrix['shop_item_last_sale'].astype(np.int8)\n",
    "matrix['shop_item_first_sale'] = matrix['shop_item_first_sale'].astype(np.int8)\n",
    "for idx, row in matrix.iterrows():    \n",
    "    key = str(row.item_id)+' '+str(row.shop_id)\n",
    "    if key not in cachefirst_shop_item:\n",
    "        if row.item_cnt_month!=0:\n",
    "            cachefirst_shop_item[key] = row.date_block_num\n",
    "            cachelast_shop_item[key] = row.date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cachelast_shop_item[key]\n",
    "        first_date_block_num = cachefirst_shop_item[key]\n",
    "        matrix.at[idx, 'shop_item_last_sale'] = row.date_block_num - last_date_block_num\n",
    "        matrix.at[idx, 'shop_item_first_sale'] = row.date_block_num - first_date_block_num\n",
    "        if row.item_cnt_month!=0:\n",
    "            cachelast_shop_item[key] = row.date_block_num\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fast code for making time since first / last item sale features\n",
    "Groupby iterator -> dictionary list -> feature dataframe -> merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3458a7056c963167760921417d1f863f074f2b39"
   },
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "\n",
    "cachefirst_item = {}\n",
    "cachelast_item = {}\n",
    "\n",
    "storelist = []\n",
    "\n",
    "# Use a groupby object to iterate over all date block / item combinations in the training data\n",
    "gruppy = train[['date_block_num','shop_id','item_id','item_cnt_month']].groupby(['date_block_num','item_id'])\n",
    "\n",
    "for group, items in gruppy:\n",
    "    \n",
    "    date_block_num = group[0]\n",
    "    item_id = group[1]\n",
    "    \n",
    "    # Use item_id as a unique key for the cache dictionaries\n",
    "    key = item_id\n",
    "    if key not in cachefirst_item:\n",
    "        cachefirst_item[key] = date_block_num\n",
    "        cachelast_item[key] = date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cachelast_item[key]\n",
    "        first_date_block_num = cachefirst_item[key]\n",
    "        # Features are stored in a list of dictionaries which is used to construct a dataframe, as this is much faster than appending features row-wise\n",
    "        tempdict = {'date_block_num':date_block_num,\n",
    "                   'item_id':item_id,\n",
    "                   'item_last_sale': date_block_num - last_date_block_num,\n",
    "                    'item_first_sale': date_block_num - first_date_block_num}\n",
    "        cachelast_item[key] = date_block_num\n",
    "        storelist.append(tempdict)\n",
    "\n",
    "# Create a dataframe from the list\n",
    "df = pd.DataFrame(storelist)\n",
    "\n",
    "# Merge the new dataframe with main train frame\n",
    "train = train.merge(df, on=['date_block_num','item_id'], how='left')\n",
    "\n",
    "# Fill missing values with 0\n",
    "train[['item_last_sale','item_first_sale']] = train[['item_last_sale','item_first_sale']].fillna(0)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fast code for making time since first / last shop-item sale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3458a7056c963167760921417d1f863f074f2b39"
   },
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "\n",
    "# Shop / item combination section\n",
    "cachefirst_shop_item = {}\n",
    "cachelast_shop_item = {}\n",
    "\n",
    "storelist = []\n",
    "\n",
    "# Use a groupby object to iterate over all date block / shop / item combinations in the training data\n",
    "gruppy = train[['date_block_num','shop_id','item_id','item_cnt_month']].groupby(['date_block_num','shop_id','item_id'])\n",
    "\n",
    "for group, items in tqdm(gruppy):\n",
    "    \n",
    "    date_block_num = group[0]\n",
    "    shop_id = group[1]\n",
    "    item_id = group[2]\n",
    "    \n",
    "    # Use item_id-shop_id combination as a unique key for the cache dictionaries\n",
    "    key = str(item_id)+' '+str(shop_id)\n",
    "    if key not in cachefirst_shop_item:\n",
    "        # Update caches if item_cnt_month > 0\n",
    "        # item_cnt_month is at final position in items frame (each group is a single row)\n",
    "        if items.iat[0,-1]>0:\n",
    "            cachefirst_shop_item[key] = date_block_num\n",
    "            cachelast_shop_item[key] = date_block_num\n",
    "\n",
    "    else:\n",
    "        last_date_block_num = cachelast_shop_item[key]\n",
    "        first_date_block_num = cachefirst_shop_item[key]\n",
    "        # Features are stored in a list of dictionaries which is used to construct a dataframe, as this is much faster than appending features row-wise\n",
    "        tempdict = {'date_block_num':date_block_num,\n",
    "                    'shop_id':shop_id,\n",
    "                   'item_id':item_id,\n",
    "                   'shop_item_last_sale': date_block_num - last_date_block_num,\n",
    "                    'shop_item_first_sale': date_block_num - first_date_block_num}\n",
    "        if items.iat[0,-1]>0:\n",
    "            cachelast_shop_item[key] = date_block_num\n",
    "        storelist.append(tempdict)\n",
    "        \n",
    "# Create a dataframe from the list\n",
    "df = pd.DataFrame(storelist)\n",
    "\n",
    "# Merge the new dataframe with main train frame\n",
    "train = train.merge(df, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "\n",
    "# Fill missing values with 0\n",
    "train[['shop_item_last_sale','shop_item_first_sale']] = train[['shop_item_last_sale','shop_item_first_sale']].fillna(0)\n",
    "\n",
    "del storelist, cachelast_shop_item, cachefirst_shop_item\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shop age (date blocks since first appearance of shop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Months since first appearance of item, calculated by a groupby-transform operation (fast!)\n",
    "df['shop_age'] = df.groupby('shop_id')['date_block_num'].transform(lambda x: x - x.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage change in an aggregate feature over a specified period\n",
    "(e.g. percentage change in total shop revenue compared to 3 months previously)\n",
    "Feature lagged by one month to maintain validity of time splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shop revenue change month on month \\\n",
    "Total item sales month on month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pct_change(df, group_feats, quantity='item_cnt_month', agg_function='sum', periods=1, fill_method=None, fill_inf=True, clip_value=None):\n",
    "    '''\n",
    "    Adds a column of month-to-month proportion change values for an aggregate sum of a specific feature\n",
    "    \"quantity\" grouped by feature \"group_feats\".\n",
    "    \n",
    "    Arguments:\n",
    "    df (Dataframe): dataframe to add feature to\n",
    "    group_feats (str or list): column or list of columns to group items by when generating aggregate features\n",
    "    quantity (str): column to generate aggregate feature on\n",
    "    agg_function (str): aggregate function to use, possible values \"sum\" or \"mean\"\n",
    "    periods (int or str): time deltas to use when calculating percentage changes of the aggregate feature\n",
    "    fill_method: argument passed to the fill_method argument of pandas.Series.pct_change(). NOTE this does\n",
    "    not prevent NaNs existing in the generated column\n",
    "    clip_value: positive absolute value used to set the negative and positive clip boundaries of the new feature\n",
    "    '''\n",
    "    \n",
    "    # Put string arguments for arguments \"periods\" and \"group_feats\" into lists\n",
    "    if type(periods) not in (int, list):\n",
    "        raise TypeError\n",
    "    if type(periods)==int:\n",
    "        periods = [periods]\n",
    "        \n",
    "    if type(group_feats) not in (str, list):\n",
    "        raise TypeError\n",
    "    if type(group_feats)==str:\n",
    "        group_feats = [group_feats]\n",
    "\n",
    "    # group_feats_full: list of grouping columns + time column\n",
    "    group_feats_full = ['date_block_num'] + group_feats\n",
    "    \n",
    "    # Create a template index of all group feature values in all months (original df misses levels in months where they have no sales)\n",
    "    idx = pd.MultiIndex.from_product([df[col].unique() for col in group_feats_full],\n",
    "                                    names=group_feats_full)\n",
    "    template = pd.DataFrame(index=idx)\n",
    "    template = template.sort_index()\n",
    "    \n",
    "    # Create aggregate feature and merge the results with the template\n",
    "    if agg_function=='sum':\n",
    "        aggs = df.groupby(group_feats_full)[quantity].sum()\n",
    "    elif agg_function=='mean':\n",
    "        aggs = df.groupby(group_feats_full)[quantity].mean()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid agg_function!\")\n",
    "    template = template.merge(aggs, on=group_feats_full, how='left')\n",
    "    \n",
    "    # Generate pct_change feature for each specified period, clip values then add to df with a lag of 1\n",
    "    for period in periods:\n",
    "        feat_name = '-'.join(group_feats + [quantity] + [agg_function] + ['delta'] + [str(period)])\n",
    "        template[feat_name] = (template.groupby(group_feats)[quantity]\n",
    "                                .transform(lambda x: x.pct_change(periods=period, fill_method=fill_method)))\n",
    "        \n",
    "        # Sometimes inf values are created because of anomalies\n",
    "        if fill_inf:\n",
    "            template.loc[template[feat_name]==np.inf,feat_name] = np.nan\n",
    "            template[feat_name] = template.groupby(group_feats)[feat_name].fillna(method=fill_method)\n",
    "        \n",
    "        # Censor large values\n",
    "        if clip_value is not None:\n",
    "            template[feat_name] = template[feat_name].clip(lower=-clip_value, upper=clip_value)\n",
    "        \n",
    "        # Add to df with a lag of 1\n",
    "        if 'date_block_num' not in template.columns:\n",
    "            template = template.reset_index()\n",
    "        template['date_block_num'] += 1\n",
    "        df = df.merge(template.loc[:,['date_block_num'] + group_feats + [feat_name]], on=group_feats_full, how='left')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Lagged) sales of items with item_id 1 above or 1 below item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_neighbor_item_features(matrix, feature, group= ['item_id']):\n",
    "    # Item_id minus 1\n",
    "    f = matrix.groupby([\"date_block_num\"] + group)[feature].agg(\"mean\")\n",
    "    name_minus = \"minus1_\" + feature\n",
    "    f.name = name_minus\n",
    "    f = f.reset_index([\"date_block_num\"] + group)\n",
    "    f[\"item_id\"] = f[\"item_id\"] + 1\n",
    "    f['date_block_num'] += 1\n",
    "    matrix = matrix.merge(f, on=[\"date_block_num\"] + group, how='left')\n",
    "    matrix[name_minus] = matrix[name_minus].fillna(99)\n",
    "    # Item_id plus 1\n",
    "    name_plus = \"plus1_\" + feature\n",
    "    f = f.rename(columns={name_minus:name_plus})\n",
    "    f[\"item_id\"] = f[\"item_id\"] - 2\n",
    "    f['date_block_num']\n",
    "    matrix = matrix.merge(f, on=[\"date_block_num\"] + group, how='left')\n",
    "    matrix[name_plus] = matrix[name_plus].fillna(99)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select features according to feature importances in a trained lightgbm booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropxfeatures(booster, n_drop):\n",
    "    ''' Return a list of columns with the bottom n_drop feature importances removed.'''\n",
    "    allfeats = booster.feature_name_\n",
    "    featimportances = booster.feature_importances_\n",
    "    idx = featimportances.argsort()[n_drop:]\n",
    "    return list(np.array(allfeats)[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split a musical item name into artist and title strings from musical items in the Kaggle \"predict future sales\" competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist_title_split(item_name):\n",
    "    '''\n",
    "    Splits an item name string for a music item into an artist and title string.\n",
    "    Not perfect.\n",
    "    '''\n",
    "    import re\n",
    "\n",
    "    def name_correction(x):\n",
    "        x = x.partition('[')[0]\n",
    "        x = x.partition('(')[0]\n",
    "        x = re.sub('[^A-Za-z0-9А-Яа-я]+', ' ', x)\n",
    "        x = x.replace('  ', ' ')\n",
    "        x = x.strip()\n",
    "        return x\n",
    "\n",
    "    def findnumericorvolidx(word_list, start):\n",
    "        # Find the first string item in a list which is either numeric or begins with \"Vol\"\n",
    "        numeric_or_vol_list = [word.isnumeric() | (word[:3]=='Vol') for word in word_list]\n",
    "        try:\n",
    "            title_start_idx = numeric_or_vol_list[start:].index(True) + start\n",
    "        except ValueError:\n",
    "            title_start_idx = None\n",
    "        return title_start_idx\n",
    "\n",
    "    name_clean = name_correction(item_name)\n",
    "#     print(name_clean)\n",
    "    word_list = name_clean.split()\n",
    "    # Planet music case\n",
    "    if name_clean[:12] == \"Planet Music\":\n",
    "        artist = \"Planet Music\"\n",
    "        title = \" \".join(word_list[2:])\n",
    "    # V/A case\n",
    "    elif (name_clean[:3] == \"V A\"):\n",
    "        title_start_idx = findnumericorvolidx(word_list, 2)\n",
    "        artist = \" \".join(word_list[2:title_start_idx])\n",
    "        if title_start_idx==None:\n",
    "            title=None\n",
    "        else:\n",
    "            title = \" \".join(word_list[title_start_idx:])\n",
    "    # СБ case\n",
    "    elif (name_clean[:2] == \"СБ\"):\n",
    "        title_start_idx = findnumericorvolidx(word_list, 1)\n",
    "        artist = \" \".join(word_list[1:title_start_idx])\n",
    "        if title_start_idx==None:\n",
    "            title=None\n",
    "        else:\n",
    "            title = \" \".join(word_list[title_start_idx:])\n",
    "\n",
    "    # Single word after name cleaning case       \n",
    "    elif len(word_list)==1:\n",
    "        artist = word_list[0]\n",
    "        title = None\n",
    "\n",
    "    # Normal case\n",
    "    else:\n",
    "#         start_points = [((len(word)>1) & (word.istitle())) | word.isnumeric() for word in word_list]\n",
    "        start_points = [(word.istitle() | word.isnumeric() | word.islower()) for word in word_list]\n",
    "#         start_points = [(word.istitle() | word.isnumeric()) & (len(word)>1) for word in word_list]\n",
    "\n",
    "        try:\n",
    "            title_start_idx = start_points[1:].index(True) + 1\n",
    "        except ValueError:\n",
    "            title_start_idx = len(start_points)-1\n",
    "\n",
    "        artist = \" \".join(word_list[:title_start_idx])\n",
    "        title = \" \".join(word_list[title_start_idx:])\n",
    "    \n",
    "    return (artist, title)\n",
    "\n",
    "Try out the above function below\n",
    "\n",
    "music_categories = [55, 56, 57, 58, 59]\n",
    "music_items = items.loc[items.item_category_id.isin(music_categories),:].copy()\n",
    "# music_items.to_csv('music_items.csv')\n",
    "\n",
    "item_id = 17972\n",
    "item_name = music_items.loc[music_items.item_id==item_id,'item_name'].item()\n",
    "\n",
    "print(item_name)\n",
    "artist, title = artist_title_split(item_name)\n",
    "    \n",
    "print(f\"Artist: {artist}, title: {title}\")\n",
    "print(f\"Just artist: {artist_title_split(item_name)[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling and exponential mean encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The moving and rolling average features are generated from the day-level sales_train dataframe which has additional zero item_cnt_day placeholder entries at the beginning and end of each set of unique shop-item combinations. The following cell creates or loads this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_with_start_endpoints(train):\n",
    "    # Need datetime index for this, moving averages are calculated per-day\n",
    "    train[\"date\"] = pd.to_datetime(train[\"date\"], format=\"%d.%m.%Y\")\n",
    "    train = train.set_index(\"date\", drop=False)\n",
    "    # We want to create averages until the end of the shop's life,\n",
    "    # for all item_id-shop combinations add zero item count items\n",
    "    # with the last date that an item was sold in the shop\n",
    "    storelist1 = []\n",
    "    storelist2 = []\n",
    "    start_last_month = pd.Timestamp(\"2015-10-01\")\n",
    "    end_last_month = pd.Timestamp(\"2015-10-31\")\n",
    "    for shop_id in tqdm(train.shop_id.unique()):\n",
    "        first_shop_sale_date = train.loc[\n",
    "            train.shop_id == shop_id, \"date\"\n",
    "        ].min()\n",
    "        last_shop_sale_date = train.loc[\n",
    "            train.shop_id == shop_id, \"date\"\n",
    "        ].max()\n",
    "        # If last sale is in last month of training data, add placeholder\n",
    "        # at the end of the month so timeseries extends to the beginning\n",
    "        # of the test data\n",
    "        if last_shop_sale_date >= start_last_month:\n",
    "            last_shop_sale_date = end_last_month\n",
    "        first_shop_sale_date_block_num = train.loc[\n",
    "            train.shop_id == shop_id, \"date_block_num\"\n",
    "        ].min()\n",
    "        last_shop_sale_date_block_num = train.loc[\n",
    "            train.shop_id == shop_id, \"date_block_num\"\n",
    "        ].max()\n",
    "        for item_id in train[train.shop_id == shop_id].item_id.unique():\n",
    "            first_item_sale_date = train.loc[\n",
    "                train.item_id == item_id, \"date\"\n",
    "            ].min()\n",
    "            first_item_sale_date_block_num = train.loc[\n",
    "                train.item_id == item_id, \"date_block_num\"\n",
    "            ].min()\n",
    "            endpoint_null_sale = {\n",
    "                \"date\": last_shop_sale_date,\n",
    "                \"shop_id\": shop_id,\n",
    "                \"item_id\": item_id,\n",
    "                \"item_cnt_day\": 0.0,\n",
    "                \"date_block_num\": last_shop_sale_date_block_num,\n",
    "            }\n",
    "            startpoint_date = max(\n",
    "                first_shop_sale_date, first_item_sale_date\n",
    "            )\n",
    "            startpoint_date_block_num = max(\n",
    "                first_shop_sale_date_block_num,\n",
    "                first_item_sale_date_block_num,\n",
    "            )\n",
    "            startpoint_null_sale = {\n",
    "                \"date\": startpoint_date,\n",
    "                \"shop_id\": shop_id,\n",
    "                \"item_id\": item_id,\n",
    "                \"item_cnt_day\": 0.0,\n",
    "                \"date_block_num\": startpoint_date_block_num,\n",
    "            }\n",
    "            storelist1.append(endpoint_null_sale)\n",
    "            storelist2.append(startpoint_null_sale)\n",
    "    # Create a dataframe of the endpoints from the list of dictionaries\n",
    "    endpoint_items = pd.DataFrame(storelist1)\n",
    "    endpoint_items = endpoint_items.set_index(\"date\", drop=False)\n",
    "    startpoint_items = pd.DataFrame(storelist2)\n",
    "    startpoint_items = startpoint_items.set_index(\"date\", drop=False)\n",
    "    # Add the endpoints to the original dataset\n",
    "    train_extra = pd.concat([startpoint_items, train, endpoint_items])\n",
    "    return train_extra\n",
    "\n",
    "train_extra = create_train_with_start_endpoints(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove negative sales values from dataframe used to create rolling average features\n",
    "These can cause some strange negative mean monthly sales values when items are returned long after they are purchased, so I'm guessing it's better to remove these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_extra = train_extra[train_extra.item_cnt_day>=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define rolling average functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_average(s, readout_dates, cutoff=None):\n",
    "    \"\"\" Calculates rolling averages on specified readout dates from a sparse dataseries s,\n",
    "    assuming zero sales on days with no entries.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    s: pandas series of scalar data with datetime index\n",
    "    readout_dates: an array of pandas datetimes which specify the dates on which the value of the rolling average will be calculated\n",
    "    cutoff: scalar, date offset from readout point beyond which events do not contribute to readouts.\n",
    "    \"\"\"\n",
    "    if cutoff is None:\n",
    "        cutoff = np.inf\n",
    "\n",
    "    # Convert event dates numpy datetime64 datatype with day resolution\n",
    "    event_dates = s.index.to_numpy(\"datetime64[D]\").reshape((-1, 1))\n",
    "    readout_dates = readout_dates.to_numpy(\"datetime64[D]\").reshape((1, -1))\n",
    "\n",
    "    # Create a n_event_dates * n_readout_dates array of date offsets between the readout dates and event dates\n",
    "    offsets = (readout_dates - event_dates).astype(\"int\")\n",
    "    # Create a binary mask for the values used to calculate readout values (i.e. no future timepoints or past timepoints beyond the cutoff)\n",
    "    selection_mask = (offsets >= 0) & (offsets < cutoff)\n",
    "    # Calculate the window length as either the maximum window length or (readout date) - (start of series)\n",
    "    window_lengths = offsets[0, :].clip(max=cutoff)\n",
    "    normalization_factors = window_lengths\n",
    "    # Create a len(series) x len(readout_dates) masked array of series values by tiling\n",
    "    values = np.broadcast_to(\n",
    "        s.to_numpy().reshape((-1, 1)), shape=offsets.shape\n",
    "    )\n",
    "    values = ma.array(data=values, mask=~selection_mask)\n",
    "    # Sume the unmasked values and divide by the window length to get the mean\n",
    "    readout_values = values.sum(axis=0) / normalization_factors\n",
    "    readout_values = readout_values.data\n",
    "    # Return a dataframe\n",
    "    readout_series = pd.Series(\n",
    "        data=readout_values, index=readout_dates.ravel(), name=s.name\n",
    "    )\n",
    "    return readout_series\n",
    "\n",
    "\n",
    "def rolling_average_monthly_readout(series, cutoff=None):\n",
    "    '''Creates a set of monthly readout points for an series and calls\n",
    "    the rolling average function using the readout points as an argument.'''\n",
    "\n",
    "    idx = series.index\n",
    "    readout_dates = pd.date_range(\n",
    "        start=idx.min(), end=idx.max() + MonthEnd(0), freq=\"M\"\n",
    "    )\n",
    "    readout_series = rolling_average(series, readout_dates, cutoff=cutoff)\n",
    "    return readout_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_shop_item(cutoff, name):\n",
    "    ''' Returns a multiindex series of rolling mean series of all shop_id-item_id combinations\n",
    "    with window length \"cutoff\" and name \"name\" '''\n",
    "\n",
    "    def get_resampled(shop_id, item_id, cutoff):\n",
    "        s = train_extra.loc[\n",
    "            (train_extra[\"item_id\"] == item_id) & (train_extra[\"shop_id\"] == shop_id),\n",
    "            \"item_cnt_day\",\n",
    "        ]\n",
    "        s = rolling_average_monthly_readout(s, cutoff=cutoff)\n",
    "\n",
    "        return {\"item_cnt_day\": s, \"item_id\": item_id, \"shop_id\": shop_id}\n",
    "\n",
    "    storelist = []\n",
    "    for shop_id in tqdm(train_extra.shop_id.unique()):\n",
    "        for item_id in train_extra[train_extra.shop_id == shop_id].item_id.unique():\n",
    "            storelist.append(get_resampled(shop_id, item_id, cutoff))\n",
    "    pool = mp.Pool()\n",
    "    storelist2 = list(pool.map(pd.DataFrame, storelist))\n",
    "    feat_frame = pd.concat(storelist2)\n",
    "    feat_frame = feat_frame.rename(columns={\"item_cnt_day\": name})\n",
    "    dbms = train_extra.resample(\"m\").date_block_num.mean()\n",
    "    feat_frame = feat_frame.merge(dbms, how=\"left\", left_index=True, right_index=True)\n",
    "    feat_frame = feat_frame.set_index([\"item_id\", \"shop_id\", \"date_block_num\"])\n",
    "    feat_series = feat_frame[name]\n",
    "    return feat_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_single_feature(cutoff, encode_feature, return_name):\n",
    "    \"\"\" Encodes shop_id as a rolling mean of item_cnt_day,\n",
    "    sampled at the end of each month, with a window size of cutoff days.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cutoff: int, window length in days\n",
    "    encode_feature: str, return_name of feature to be encoded\n",
    "    return_name: name of feature that will be returned\n",
    "    \"\"\"\n",
    "\n",
    "    def get_resampled(encode_feature, feature_id, cutoff):\n",
    "        s = train_extra.loc[(train_extra[encode_feature] == feature_id), \"item_cnt_day\"]\n",
    "        s = rolling_average_monthly_readout(s, cutoff=cutoff)\n",
    "\n",
    "        return {\"item_cnt_day\": s, encode_feature: feature_id}\n",
    "\n",
    "    storelist = []\n",
    "    for feature_id in tqdm(train_extra[encode_feature].unique()):\n",
    "        storelist.append(get_resampled(encode_feature, feature_id, cutoff))\n",
    "    pool = mp.Pool()\n",
    "    storelist2 = list(pool.map(pd.DataFrame, storelist))\n",
    "    feat_frame = pd.concat(storelist2)\n",
    "    feat_frame = feat_frame.rename(columns={\"item_cnt_day\": return_name})\n",
    "    dbms = train_extra.resample(\"m\").date_block_num.mean()\n",
    "    feat_frame = feat_frame.merge(dbms, how=\"left\", left_index=True, right_index=True)\n",
    "    feat_frame = feat_frame.set_index([encode_feature, \"date_block_num\"])\n",
    "    feat_series = feat_frame[return_name]\n",
    "    return feat_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_id_group_merge(df, feat_series):\n",
    "    ''' Groups by date_block_num and item_id, merges with dataframe with lag 1 '''\n",
    "    feat_series = feat_series[\n",
    "        feat_series.index.get_level_values(\"shop_id\").isin(df.shop_id.unique())\n",
    "    ]\n",
    "    feat_series = feat_series.groupby([\"date_block_num\", \"item_id\"]).mean()\n",
    "    feat_series.name = 'rm_item_' + feat_series.name[feat_series.name.index('win'):]\n",
    "    df = add_lag_feature(df, feat_series, \"item_id\", 1, fillna=0, optimize_mem=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the same but with exponential moving average features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_moving_average(s, readout_dates, alpha=None, halflife=None, cutoff=None):\n",
    "    \"\"\" Calculates exonential moving averages as specified readout dates as a closed form function of the daily sales data,\n",
    "    assuming zero sales on days with no entries. Either alpha or halflife parameters must be provided, see\n",
    "    https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.ewm.html for definition.\n",
    "    \n",
    "    Arguments\n",
    "    s: pandas series of scalar data with datetime index\n",
    "    readout_dates: an array of pandas datetimes which specify the dates on which the value of the moving average will be calculated\n",
    "    alpha: scalar\n",
    "    halflife: scalar\n",
    "    cutoff: scalar, date offset from readout point beyond which events do not contribute to readouts, to potentially speed up calculation over long time series.\n",
    "    \"\"\"\n",
    "    if cutoff is None:\n",
    "        cutoff = np.inf\n",
    "    if halflife is not None:\n",
    "        alpha = 1 - np.e ** (-np.log(2) / halflife)\n",
    "    if alpha is None:\n",
    "        raise ValueError(\"Either alpha or halflife parameters must be provided\")\n",
    "    # Convert event dates numpy datetime64 datatype with day resolution\n",
    "    event_dates = s.index.to_numpy(\"datetime64[D]\").reshape((-1, 1))\n",
    "    readout_dates = readout_dates.to_numpy(\"datetime64[D]\").reshape((1, -1))\n",
    "\n",
    "    # Create a n_event_dates * n_readout_dates array of date offsets between the readout dates and event dates\n",
    "    offsets = (readout_dates - event_dates).astype(\"int\")\n",
    "    # Create a binary mask for the values used to calculate readout values (i.e. no future timepoints or past timepoints beyond the cutoff)\n",
    "    selection_mask = (offsets >= 0) & (offsets < cutoff)\n",
    "    # Create a masked array to hold the values of coefficients of the series values for the calculation of moving averages at the readoutpoints\n",
    "    coeffs = ma.zeros(shape=offsets.shape)\n",
    "    coeffs.mask = ~selection_mask\n",
    "    # Calculate the coefficients of the past values as a function of their offset (i.e. the number of timepoints they are in the past)\n",
    "    # See https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.ewm.html for equation\n",
    "    coeffs[selection_mask] = (1 - alpha) ** offsets[selection_mask]\n",
    "    # For the definition of the normalization factor see # See https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.ewm.html for equation\n",
    "    # Calculate the length of the window being averaged over as larger of either the cutoff delay or the time since the first value in the series\n",
    "    window_lengths = offsets[0, :].clip(max=cutoff)\n",
    "    # For the closed form formula for the sum of 0 to n powers of a value, see https://en.wikipedia.org/wiki/Geometric_series#Closed-form_formula\n",
    "    normalization_factors = (1 - (1 - alpha) ** (window_lengths + 1)) / (1 - (1 - alpha))\n",
    "    # Create the weighted values as the product of original values and coefficients, then normalize to get the readout values\n",
    "    weighted_values = coeffs * s.to_numpy().reshape((-1, 1))\n",
    "    readout_values = weighted_values.sum(axis=0) / normalization_factors\n",
    "    readout_values = readout_values.data\n",
    "    # Return a dataframe\n",
    "    readout_series = pd.Series(\n",
    "        data=readout_values, index=readout_dates.ravel(), name=s.name\n",
    "    )\n",
    "    return readout_series\n",
    "\n",
    "\n",
    "def moving_average_monthly_readout(series, alpha=None, halflife=None, cutoff=None):\n",
    "    \"\"\"Creates a set of monthly readout points for an series and calls\n",
    "    the moving average function using the readout points as an argument.\"\"\"\n",
    "    idx = series.index\n",
    "    readout_dates = pd.date_range(start=idx.min(), end=idx.max() + MonthEnd(0), freq=\"M\")\n",
    "    readout_series = exp_moving_average(\n",
    "        series, readout_dates, alpha=alpha, halflife=halflife, cutoff=cutoff\n",
    "    )\n",
    "    return readout_series\n",
    "\n",
    "\n",
    "def ema_shop_item(halflife, name):\n",
    "    \"\"\" Returns a multiindex series of exponential moving mean series for all shop_id-item_id combinations,\n",
    "    with window length \"cutoff\" and name \"name\" \"\"\"\n",
    "\n",
    "    def get_resampled(shop_id, item_id, halflife):\n",
    "        s = train_extra.loc[\n",
    "            (train_extra[\"item_id\"] == item_id) & (train_extra[\"shop_id\"] == shop_id),\n",
    "            \"item_cnt_day\",\n",
    "        ]\n",
    "        s = moving_average_monthly_readout(s, halflife=halflife)\n",
    "        return {\"item_cnt_day\": s, \"item_id\": item_id, \"shop_id\": shop_id}\n",
    "\n",
    "    storelist = []\n",
    "    for shop_id in tqdm(train_extra.shop_id.unique()):\n",
    "        for item_id in train_extra[train_extra.shop_id == shop_id].item_id.unique():\n",
    "            storelist.append(get_resampled(shop_id, item_id, halflife))\n",
    "    pool = mp.Pool()\n",
    "    storelist2 = list(pool.map(pd.DataFrame, storelist))\n",
    "    feat_frame = pd.concat(storelist2)\n",
    "    feat_frame = feat_frame.rename(columns={\"item_cnt_day\": name})\n",
    "    dbms = train_extra.resample(\"m\").date_block_num.mean()\n",
    "    feat_frame = feat_frame.merge(dbms, how=\"left\", left_index=True, right_index=True)\n",
    "    feat_frame = feat_frame.set_index([\"item_id\", \"shop_id\", \"date_block_num\"])\n",
    "    feat_series = feat_frame[name]\n",
    "    return feat_series\n",
    "\n",
    "\n",
    "def ema_single_feature(halflife, encode_feature, return_name):\n",
    "    \"\"\" Encodes shop_id as a rolling mean of item_cnt_day,\n",
    "    sampled at the end of each month, with a window size of cutoff days.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cutoff: int, window length in days\n",
    "    encode_feature: str, return_name of feature to be encoded\n",
    "    return_name: name of feature that will be returned\n",
    "    \"\"\"\n",
    "\n",
    "    def get_resampled(encode_feature, feature_id, halflife):\n",
    "        s = train_extra.loc[(train_extra[encode_feature] == feature_id), \"item_cnt_day\"]\n",
    "        s = moving_average_monthly_readout(s, halflife=halflife)\n",
    "\n",
    "        return {\"item_cnt_day\": s, encode_feature: feature_id}\n",
    "\n",
    "    storelist = []\n",
    "    for feature_id in tqdm(train_extra[encode_feature].unique()):\n",
    "        storelist.append(get_resampled(encode_feature, feature_id, halflife))\n",
    "    pool = mp.Pool()\n",
    "    storelist2 = list(pool.map(pd.DataFrame, storelist))\n",
    "    feat_frame = pd.concat(storelist2)\n",
    "    feat_frame = feat_frame.rename(columns={\"item_cnt_day\": return_name})\n",
    "    dbms = train_extra.resample(\"m\").date_block_num.mean()\n",
    "    feat_frame = feat_frame.merge(dbms, how=\"left\", left_index=True, right_index=True)\n",
    "    feat_frame = feat_frame.set_index([encode_feature, \"date_block_num\"])\n",
    "    feat_series = feat_frame[return_name]\n",
    "    return feat_series\n",
    "\n",
    "\n",
    "def item_id_group_merge(df, feat_series):\n",
    "    \"\"\" Groups by date_block_num and item_id, merges with dataframe with lag 1 \"\"\"\n",
    "    feat_series = feat_series[\n",
    "        feat_series.index.get_level_values(\"shop_id\").isin(df.shop_id.unique())\n",
    "    ]\n",
    "    feat_series = feat_series.groupby([\"date_block_num\", \"item_id\"]).mean()\n",
    "    feat_series.name = \"ema_item_\" + feat_series.name[feat_series.name.index(\"hl\") :]\n",
    "    df = add_lag_feature(df, feat_series, \"item_id\", 1, fillna=0, optimize_mem=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar name item sales feature for new items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_name_similarity_frame(itemsdf):\n",
    "    # Makes a dataframe of similarity values between item names calculated with FuzzyWuzzy\n",
    "    # itemsdf must have a supercategory_id field\n",
    "    import re\n",
    "    from itertools import combinations\n",
    "\n",
    "    import scipy.sparse as sp\n",
    "    from fuzzywuzzy import fuzz\n",
    "\n",
    "    def strip_sq_brackets(string):\n",
    "        return re.sub(r\"\\[.*?\\]\", \"\", string)\n",
    "\n",
    "    def strip_rd_brackets(string):\n",
    "        return re.sub(r\"\\(.*?\\)\", \"\", string)\n",
    "\n",
    "    items[\"item_name\"] = items[\"item_name\"].apply(strip_sq_brackets).apply(strip_rd_brackets)\n",
    "\n",
    "    itnames = items.item_name.to_list()\n",
    "    itsupcats = items.supercategory_id.to_list()\n",
    "    pairs = combinations(items.index, 2)\n",
    "    sims = sp.dok_matrix((len(itnames), len(itnames)), dtype=np.int8)\n",
    "\n",
    "    for id1, id2 in tqdm(\n",
    "        pairs, total=len(itnames) * (len(itnames) - 1) / 2, desc=\"Calculating similarity values\"\n",
    "    ):\n",
    "        if itsupcats[id1] != itsupcats[id2]:\n",
    "            pass\n",
    "        else:\n",
    "            sims[id1, id2] = fuzz.token_sort_ratio(itnames[id1], itnames[id2], force_ascii=False)\n",
    "\n",
    "    csims = sims.tocsr()\n",
    "    csims = csims + csims.T\n",
    "    csims = pd.DataFrame.sparse.from_spmatrix(csims)\n",
    "    return csims\n",
    "\n",
    "\n",
    "def make_sim_item_features(matrix, sim_frame, return_fields, sim_thresh=50, max_n=5, max_item_age=12):\n",
    "    storelist = []\n",
    "    mean_fields = [s + \"_all_shops\" for s in return_fields]\n",
    "    for date_block_num in tqdm(range(3, 35), \"Generating similar item name features\"):\n",
    "        for item_age in np.sort(matrix.loc[matrix.date_block_num == date_block_num, \"item_age\"].unique()):\n",
    "\n",
    "            def get_sim_item_features(item_ids):\n",
    "                slist = []\n",
    "                for item_id in item_ids:\n",
    "                    sim_items = sim_frame.loc[item_id, item_ids_past].nlargest(max_n)\n",
    "                    sim_items = sim_items[sim_items>sim_thresh]\n",
    "                    if len(sim_items)==0:\n",
    "                        pass\n",
    "                    else:\n",
    "                        sim_item_values = (\n",
    "                            past_months.loc[(slice(None), sim_items.index), return_fields]\n",
    "                            .groupby(\"shop_id\")[return_fields]\n",
    "                            .mean()\n",
    "                        )\n",
    "                        sim_item_values[mean_fields] = sim_item_values.mean()\n",
    "                        sim_item_values[\"item_id\"] = item_id\n",
    "                        slist.append(sim_item_values)\n",
    "                sframe = pd.concat(slist)\n",
    "                sframe[\"date_block_num\"] = date_block_num\n",
    "                sframe = sframe.reset_index()\n",
    "                return sframe\n",
    "            if item_age < date_block_num:\n",
    "                if item_age >= max_item_age:\n",
    "                    past_months = (\n",
    "                        matrix.query(f\"date_block_num<{date_block_num} & date_block_num>1 & item_age>={item_age}\")\n",
    "                        .groupby([\"shop_id\", \"item_id\"])[return_fields]\n",
    "                        .mean()\n",
    "                    )\n",
    "                    item_ids_past = past_months.index.get_level_values(\"item_id\").unique()\n",
    "                    item_ids = matrix.query(\n",
    "                        f\"date_block_num=={date_block_num} & item_age>={item_age}\"\n",
    "                    ).item_id.unique()\n",
    "                    sframe_new = get_sim_item_features(item_ids)\n",
    "                    storelist = storelist + [sframe_new]\n",
    "                    break\n",
    "                else:\n",
    "                    past_months = (\n",
    "                        matrix.query(f\"date_block_num<{date_block_num} & date_block_num>1 & item_age=={item_age}\")\n",
    "                        .groupby([\"shop_id\", \"item_id\"])[return_fields]\n",
    "                        .mean()\n",
    "                    )\n",
    "                    item_ids_past = past_months.index.get_level_values(\"item_id\").unique()\n",
    "                    item_ids = matrix.query(\n",
    "                        f\"date_block_num=={date_block_num} & item_age=={item_age}\"\n",
    "                    ).item_id.unique()\n",
    "                    sframe_new = get_sim_item_features(item_ids)\n",
    "                    storelist = storelist + [sframe_new]\n",
    "    sim_item_features = pd.concat(storelist)\n",
    "    sim_item_field_names = {s: \"sim_item_name_\" + s for s in return_fields + mean_fields}\n",
    "    sim_item_features = sim_item_features.rename(columns=sim_item_field_names)\n",
    "    return sim_item_features\n",
    "\n",
    "\n",
    "def add_sim_item_features(matrix, sim_item_features, fill_na_val=None):\n",
    "    oldcols = matrix.columns\n",
    "    matrix = matrix.merge(sim_item_features, on=[\"date_block_num\", \"shop_id\", \"item_id\"], how=\"left\")\n",
    "    newcols = matrix.columns.difference(oldcols)\n",
    "    if fill_na_val is not None:\n",
    "        matrix[newcols] = matrix[newcols].fillna(fill_na_val)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract artist name or comic type with regex and add as feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artist name feature for music categories and comic type feature for the books - comics category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_name_features(matrix):\n",
    "    # This extracts artist names for music categories and adds them as a feature.\n",
    "    # Assumes that the items table is in data/items.csv\n",
    "    def extract_artist(st):\n",
    "        import re\n",
    "\n",
    "        st = st.strip()\n",
    "        if st.startswith(\"V/A\"):\n",
    "            artist = \"V/A\"\n",
    "        elif st.startswith(\"СБ\"):\n",
    "            artist = \"СБ\"\n",
    "        else:\n",
    "            # Retrieves artist names using the double space or all uppercase pattern\n",
    "            mus_artist_dubspace = re.compile(r\".{2,}?(?=\\s{2,})\")\n",
    "            match_dubspace = mus_artist_dubspace.match(st)\n",
    "            mus_artist_capsonly = re.compile(r\"^([^a-zа-я]+\\s)+\")\n",
    "            match_capsonly = mus_artist_capsonly.match(st)\n",
    "            candidates = [match_dubspace, match_capsonly]\n",
    "            candidates = [m[0] for m in candidates if m is not None]\n",
    "            # Sometimes one of the patterns catches some extra words so choose the shortest one\n",
    "            if len(candidates):\n",
    "                artist = min(candidates, key=len)\n",
    "            else:\n",
    "                # If neither of the previous patterns found something, use the dot-space pattern\n",
    "                mus_artist_dotspace = re.compile(r\".{2,}?(?=\\.\\s)\")\n",
    "                match = mus_artist_dotspace.match(st)\n",
    "                if match:\n",
    "                    artist = match[0]\n",
    "                else:\n",
    "                    artist = \"\"\n",
    "        artist = artist.upper()\n",
    "        artist = re.sub(r\"[^A-ZА-Я ]||\\bTHE\\b\", \"\", artist)\n",
    "        artist = re.sub(r\"\\s{2,}\", \" \", artist)\n",
    "        artist = artist.strip()\n",
    "        return artist\n",
    "\n",
    "    items = pd.read_csv(\"data/items.csv\")\n",
    "    music_categories = [55, 56, 57, 58, 59, 60]\n",
    "    items.loc[\n",
    "        items.item_category_id.isin(music_categories), \"item_name_extra\"\n",
    "    ] = items.loc[items.item_category_id.isin(music_categories), \"item_name\"].apply(\n",
    "        extract_artist\n",
    "    )\n",
    "\n",
    "    def get_comic_type(string):\n",
    "        # The item_name in the comic category starts with the type of comic (manga etc)\n",
    "        string = string.strip()\n",
    "        brk = string.find(\" \")\n",
    "        if brk > 0:\n",
    "            comic_type = string[:brk]\n",
    "        else:\n",
    "            comic_type = \"\"\n",
    "        return comic_type\n",
    "\n",
    "    comic_category = [47]\n",
    "    items.loc[items.item_category_id.isin(comic_category), \"item_name_extra\"] = items.loc[\n",
    "        items.item_category_id.isin(comic_category), \"item_name\"\n",
    "    ].apply(get_comic_type)\n",
    "\n",
    "    matrix = matrix.merge(\n",
    "        items.loc[\n",
    "            items.item_category_id.isin(music_categories + comic_category),\n",
    "            [\"item_id\", \"item_name_extra\"],\n",
    "        ],\n",
    "        on=\"item_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More spare regex code, may be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for name feature processing\n",
    "import re\n",
    "punct_num_set = '[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~0-9]'\n",
    "sq_bracket_extract = re.compile(r'\\[(.+?)\\]') # Square brackets regex\n",
    "rd_bracket_extract = re.compile(r'\\((.+?)\\)') # Round brackets regex\n",
    "\n",
    "def remove_non_letter(string):\n",
    "    return re.sub(punct_num_set, ' ', string)\n",
    "\n",
    "def bracket_content_process(s):\n",
    "    s = [s.split(',') for s in s]\n",
    "    s = list(chain.from_iterable(s))\n",
    "    s = [remove_non_letter(w) for w in s]\n",
    "    s = [w.strip() for w in s]\n",
    "    s = '|'.join(s)\n",
    "    return s\n",
    "\n",
    "# Use the two functions below to extract brackets\n",
    "def extract_sq_bracket_contents(string):\n",
    "    s = sq_bracket_extract.findall(string)\n",
    "    s = bracket_content_process(s)\n",
    "    return s\n",
    "\n",
    "def extract_rd_bracket_contents(string):\n",
    "    s = rd_bracket_extract.findall(string)\n",
    "    s = bracket_content_process(s)\n",
    "    return s\n",
    "\n",
    "def strip_sq_brackets(string):\n",
    "    return re.sub(r'\\[.*?\\]', '', string)\n",
    "\n",
    "def strip_rd_brackets(string):\n",
    "    return re.sub(r'\\(.*?\\)', '', string)\n",
    "\n",
    "# redundant_terms = [\n",
    "#     pc,\n",
    "#     pс,\n",
    "#     рс,\n",
    "#     xbox,\n",
    "#     ps3\n",
    "#     psp\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset splitting and manipulation snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df, test_date_block_num):\n",
    "    # Split off last month of a dataset as a test set, everything before as the train set\n",
    "    test = df.loc[df.date_block_num==test_date_block_num,:]\n",
    "    train = df.loc[df.date_block_num<test_date_block_num,:]\n",
    "    return (train, test)\n",
    "\n",
    "def create_full_train_test(sales_train, test):\n",
    "    '''\n",
    "    Create a train set with all items and all shops in all date blocks (i.e. months).\n",
    "    Note this is not the exact sampling method used in the test set, as the test set has only the cartesian product of unique items and shops in the test month.\n",
    "    '''\n",
    "        # Aggregate sales to the month level\n",
    "    sales_train_grouped = sales_train.groupby(['date_block_num','item_id','shop_id']).agg({'item_cnt_day':'sum','item_price':'mean'})\n",
    "    sales_train_grouped = sales_train_grouped.rename(columns={'item_cnt_day':'item_cnt','item_price':'item_price_mean'})\n",
    "\n",
    "    # Create sets of items, shops and date blocks\n",
    "    item_ids = set(sales_train.item_id).union(set(test.item_id))\n",
    "    shop_ids = set(sales_train.shop_id).union(set(test.shop_id))\n",
    "    date_block_nums = set(sales_train.date_block_num).union(set([34]))\n",
    "\n",
    "    # Create all permutations as indexes\n",
    "    indexdataframe = pd.DataFrame(np.array(list(itertools.product(date_block_nums,item_ids,shop_ids))),columns=['date_block_num','item_id','shop_id'])\n",
    "\n",
    "    fulltrain = indexdataframe.merge(sales_train_grouped,how='left',on=['date_block_num','item_id','shop_id'])\n",
    "    fulltrain.item_cnt = fulltrain.item_cnt.fillna(0)\n",
    "\n",
    "    # Verification code\n",
    "    # after = fulltrain.loc[fulltrain.date_block_num<34,:].groupby('date_block_num').item_cnt.sum()\n",
    "    # before = sales_train.groupby('date_block_num').item_cnt_day.sum()\n",
    "    # (before == after).all()\n",
    "\n",
    "    fulltrain = fulltrain.merge(items, on='item_id', how='left')\n",
    "    fulltrain = fulltrain.drop(columns=['item_name','item_price_mean'])\n",
    "\n",
    "    # Split train and test again\n",
    "    train, test = split_train_test(fulltrain, 34)\n",
    "\n",
    "    return train\n",
    "\n",
    "def xysplit(train, test):\n",
    "    # Split a train and test set into into x and y sets, with item_cnt as the target y variable\n",
    "    y_train = train.item_cnt\n",
    "    X_train = train.drop(columns=['item_cnt'])\n",
    "    y_test = test.item_cnt\n",
    "    X_test = test.drop(columns=['item_cnt'])\n",
    "    return (X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_testlike_train(sales_train, test = None):\n",
    "    # Create a date_block_num / item_id / shop_id index using all combinations of item_id and shop_id occurring within each date_block\n",
    "    # Optionally concatenate the test items to the end\n",
    "    indexlist = []\n",
    "    for i in sales_train.date_block_num.unique():\n",
    "        x = itertools.product([i],\n",
    "                              sales_train.loc[sales_train.date_block_num==i].item_id.unique(),\n",
    "                              sales_train.loc[sales_train.date_block_num==i].shop_id.unique())\n",
    "        indexlist.append(np.array(list(x)))\n",
    "\n",
    "    df = pd.DataFrame(data=np.concatenate(indexlist, axis=0),\n",
    "                      columns=['date_block_num', 'item_id', 'shop_id'])\n",
    "    \n",
    "    # Add revenue column to sales_train\n",
    "    sales_train['item_revenue_day'] = sales_train['item_price'] * sales_train['item_cnt_day']\n",
    "    \n",
    "    # Aggregate item_id / shop_id item_cnts and revenue at the month level\n",
    "    sales_train_grouped = sales_train.groupby(['date_block_num','item_id','shop_id']).agg(\n",
    "                            item_cnt_month=pd.NamedAgg(column='item_cnt_day', aggfunc='sum'),\n",
    "                            item_revenue_month=pd.NamedAgg(column='item_revenue_day', aggfunc='sum'))\n",
    "    \n",
    "    # Merge the grouped data with the index\n",
    "    df = df.merge(sales_train_grouped,how='left',on=['date_block_num','item_id','shop_id'])\n",
    "\n",
    "    if test is not None:\n",
    "        df = pd.concat([df, test])\n",
    "        df = df.drop(columns='ID')\n",
    "        df['date_block_num'] = df['date_block_num'].fillna(34)\n",
    "    \n",
    "    # Fill empty item_cnt entries with 0\n",
    "    df.item_cnt_month = df.item_cnt_month.fillna(0)\n",
    "    df.item_revenue_month = df.item_revenue_month.fillna(0)\n",
    "    \n",
    "    return df.astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to optimize the memory use of a dataframe by downcasting datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks You Guillaume Martin for the Awesome Memory Optimizer!\n",
    "# https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else: df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## monthwise time series cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([22.60605645, 22.62392259, 22.73343515, 24.87741923]), 'score_time': array([0.34364986, 0.34560537, 0.3004148 , 0.34813166]), 'test_score': array([-2.06428627, -1.96297644, -1.59296444, -1.28655077])}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgbm\n",
    "matrix = pd.read_pickle(\"checkpoints/matrixcheckpoint_0.pk1\")\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def time_split(start_date_block, last_date_block):\n",
    "    for test_date_block in range(start_date_block, last_date_block+1):\n",
    "        train_idx = matrix['date_block_num']<test_date_block\n",
    "        test_idx = matrix['date_block_num']==test_date_block\n",
    "        yield train_idx, test_idx\n",
    "\n",
    "start_date_block = 30\n",
    "last_date_block = 33\n",
    "X = matrix.drop(columns='item_cnt_month')\n",
    "y = matrix['item_cnt_month']\n",
    "ts = time_split(start_date_block, last_date_block)\n",
    "params = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"device_type\": \"gpu\",\n",
    "    \"n_jobs\": 5,\n",
    "}\n",
    "booster = lgbm.LGBMRegressor(**params)\n",
    "\n",
    "scores = cross_validate(booster, X, y, scoring='neg_root_mean_squared_error', cv=ts)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection with scikit-learn's cross-validated recursive feature elimination (RFECV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "\n",
    "def time_split(start_date_block, last_date_block):\n",
    "    for test_date_block in range(start_date_block, last_date_block + 1):\n",
    "        train_idx = matrix[\"date_block_num\"] < test_date_block\n",
    "        test_idx = matrix[\"date_block_num\"] == test_date_block\n",
    "        yield train_idx, test_idx\n",
    "\n",
    "\n",
    "cat_cols = [\n",
    "    \"shop_id\",\n",
    "    \"item_category_id\",\n",
    "    \"city_code\",\n",
    "    \"month\",\n",
    "]\n",
    "\n",
    "\n",
    "start_date_block = 33\n",
    "last_date_block = 33\n",
    "X = matrix.drop(\n",
    "    columns=[\"item_revenue_month\",\n",
    "    \"item_price\",\n",
    "    \"item_cnt_month_unclipped\",\n",
    "    \"item_cnt_day_avg\",\n",
    "    \"new_item\",\n",
    "    \"new_shop\",\n",
    "    \"item_age\",\n",
    "    \"shop_age\",\n",
    "    \"digital\",\n",
    "    \"interaction_new_item_digital\",\n",
    "    \"item_cnt_month\",]\n",
    ")\n",
    "y = matrix[\"item_cnt_month\"]\n",
    "ts = time_split(start_date_block, last_date_block)\n",
    "params = {\n",
    "    \"n_estimators\": 40,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"device_type\": \"gpu\",\n",
    "    'metric': 'rmse',\n",
    "    \"n_jobs\": 11,\n",
    "    'num_leaves': 1023,\n",
    "    'min_child_samples':10,\n",
    "    'colsample_bytree':0.7,\n",
    "}\n",
    "booster = lgbm.LGBMRegressor(**params)\n",
    "selector = RFECV(booster, step=1, cv=ts, scoring =  'neg_root_mean_squared_error')\n",
    "selector = selector.fit(X, y)\n",
    "\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.111577\n",
      "0:\tlearn: 1.3947405\ttest: 1.3150546\tbest: 1.3150546 (0)\ttotal: 728ms\tremaining: 12m 7s\n",
      "1:\tlearn: 1.3866864\ttest: 1.3036687\tbest: 1.3036687 (1)\ttotal: 1.35s\tremaining: 11m 14s\n",
      "2:\tlearn: 1.3642924\ttest: 1.2876664\tbest: 1.2876664 (2)\ttotal: 2.26s\tremaining: 12m 31s\n",
      "3:\tlearn: 1.3640395\ttest: 1.2875689\tbest: 1.2875689 (3)\ttotal: 3.27s\tremaining: 13m 34s\n",
      "4:\tlearn: 1.3599991\ttest: 1.2823933\tbest: 1.2823933 (4)\ttotal: 4s\tremaining: 13m 15s\n",
      "5:\tlearn: 1.3492494\ttest: 1.2692452\tbest: 1.2692452 (5)\ttotal: 4.68s\tremaining: 12m 55s\n",
      "6:\tlearn: 1.3381118\ttest: 1.2601970\tbest: 1.2601970 (6)\ttotal: 5.64s\tremaining: 13m 19s\n",
      "7:\tlearn: 1.3315933\ttest: 1.2561025\tbest: 1.2561025 (7)\ttotal: 6.01s\tremaining: 12m 25s\n",
      "8:\tlearn: 1.3171010\ttest: 1.2472730\tbest: 1.2472730 (8)\ttotal: 6.65s\tremaining: 12m 12s\n",
      "9:\tlearn: 1.3132175\ttest: 1.2443963\tbest: 1.2443963 (9)\ttotal: 7.2s\tremaining: 11m 52s\n",
      "10:\tlearn: 1.3091346\ttest: 1.2418928\tbest: 1.2418928 (10)\ttotal: 8.06s\tremaining: 12m 4s\n",
      "11:\tlearn: 1.2979791\ttest: 1.2270459\tbest: 1.2270459 (11)\ttotal: 8.58s\tremaining: 11m 46s\n",
      "12:\tlearn: 1.2850514\ttest: 1.2183637\tbest: 1.2183637 (12)\ttotal: 9.41s\tremaining: 11m 54s\n",
      "13:\tlearn: 1.2828827\ttest: 1.2149957\tbest: 1.2149957 (13)\ttotal: 11.1s\tremaining: 13m 2s\n",
      "14:\tlearn: 1.2816364\ttest: 1.2139389\tbest: 1.2139389 (14)\ttotal: 11.8s\tremaining: 12m 53s\n",
      "15:\tlearn: 1.2761231\ttest: 1.2095842\tbest: 1.2095842 (15)\ttotal: 14.3s\tremaining: 14m 40s\n",
      "16:\tlearn: 1.2743498\ttest: 1.2074230\tbest: 1.2074230 (16)\ttotal: 14.7s\tremaining: 14m 11s\n",
      "17:\tlearn: 1.2714072\ttest: 1.2052224\tbest: 1.2052224 (17)\ttotal: 16.8s\tremaining: 15m 17s\n",
      "18:\tlearn: 1.2622113\ttest: 1.2006648\tbest: 1.2006648 (18)\ttotal: 17.4s\tremaining: 14m 57s\n",
      "19:\tlearn: 1.2470058\ttest: 1.1914532\tbest: 1.1914532 (19)\ttotal: 18.2s\tremaining: 14m 53s\n",
      "20:\tlearn: 1.2452919\ttest: 1.1895242\tbest: 1.1895242 (20)\ttotal: 19.1s\tremaining: 14m 51s\n",
      "21:\tlearn: 1.2442405\ttest: 1.1883872\tbest: 1.1883872 (21)\ttotal: 19.7s\tremaining: 14m 37s\n",
      "22:\tlearn: 1.2437165\ttest: 1.1877947\tbest: 1.1877947 (22)\ttotal: 20.5s\tremaining: 14m 32s\n",
      "23:\tlearn: 1.2381098\ttest: 1.1827363\tbest: 1.1827363 (23)\ttotal: 21.4s\tremaining: 14m 31s\n",
      "24:\tlearn: 1.2368677\ttest: 1.1820712\tbest: 1.1820712 (24)\ttotal: 23.3s\tremaining: 15m 10s\n",
      "25:\tlearn: 1.2336310\ttest: 1.1789927\tbest: 1.1789927 (25)\ttotal: 24s\tremaining: 14m 58s\n",
      "26:\tlearn: 1.2329607\ttest: 1.1784619\tbest: 1.1784619 (26)\ttotal: 24.7s\tremaining: 14m 51s\n",
      "27:\tlearn: 1.2312438\ttest: 1.1754129\tbest: 1.1754129 (27)\ttotal: 25.6s\tremaining: 14m 49s\n",
      "28:\tlearn: 1.2295817\ttest: 1.1746013\tbest: 1.1746013 (28)\ttotal: 26.7s\tremaining: 14m 54s\n",
      "29:\tlearn: 1.2271018\ttest: 1.1723881\tbest: 1.1723881 (29)\ttotal: 27.7s\tremaining: 14m 55s\n",
      "30:\tlearn: 1.2262727\ttest: 1.1712541\tbest: 1.1712541 (30)\ttotal: 29s\tremaining: 15m 6s\n",
      "31:\tlearn: 1.2149631\ttest: 1.1639714\tbest: 1.1639714 (31)\ttotal: 30s\tremaining: 15m 7s\n",
      "32:\tlearn: 1.2120232\ttest: 1.1621322\tbest: 1.1621322 (32)\ttotal: 31s\tremaining: 15m 8s\n",
      "33:\tlearn: 1.2076266\ttest: 1.1592280\tbest: 1.1592280 (33)\ttotal: 32.9s\tremaining: 15m 35s\n",
      "34:\tlearn: 1.2066458\ttest: 1.1576446\tbest: 1.1576446 (34)\ttotal: 33.6s\tremaining: 15m 25s\n",
      "35:\tlearn: 1.2064340\ttest: 1.1574273\tbest: 1.1574273 (35)\ttotal: 35.6s\tremaining: 15m 54s\n",
      "36:\tlearn: 1.1978000\ttest: 1.1519531\tbest: 1.1519531 (36)\ttotal: 36.2s\tremaining: 15m 40s\n",
      "37:\tlearn: 1.1971225\ttest: 1.1512278\tbest: 1.1512278 (37)\ttotal: 37.1s\tremaining: 15m 40s\n",
      "38:\tlearn: 1.1970053\ttest: 1.1510626\tbest: 1.1510626 (38)\ttotal: 37.8s\tremaining: 15m 31s\n",
      "39:\tlearn: 1.1965298\ttest: 1.1506561\tbest: 1.1506561 (39)\ttotal: 40s\tremaining: 15m 59s\n",
      "40:\tlearn: 1.1941826\ttest: 1.1483142\tbest: 1.1483142 (40)\ttotal: 42.4s\tremaining: 16m 31s\n",
      "41:\tlearn: 1.1940683\ttest: 1.1480886\tbest: 1.1480886 (41)\ttotal: 44.6s\tremaining: 16m 57s\n",
      "42:\tlearn: 1.1927503\ttest: 1.1460794\tbest: 1.1460794 (42)\ttotal: 46.5s\tremaining: 17m 16s\n",
      "43:\tlearn: 1.1919298\ttest: 1.1451308\tbest: 1.1451308 (43)\ttotal: 48.9s\tremaining: 17m 42s\n",
      "44:\tlearn: 1.1918485\ttest: 1.1449935\tbest: 1.1449935 (44)\ttotal: 51.3s\tremaining: 18m 8s\n",
      "45:\tlearn: 1.1862482\ttest: 1.1377147\tbest: 1.1377147 (45)\ttotal: 53.8s\tremaining: 18m 36s\n",
      "46:\tlearn: 1.1861002\ttest: 1.1375514\tbest: 1.1375514 (46)\ttotal: 56s\tremaining: 18m 56s\n",
      "47:\tlearn: 1.1851563\ttest: 1.1368091\tbest: 1.1368091 (47)\ttotal: 58.3s\tremaining: 19m 16s\n",
      "48:\tlearn: 1.1851047\ttest: 1.1366549\tbest: 1.1366549 (48)\ttotal: 59.9s\tremaining: 19m 22s\n",
      "49:\tlearn: 1.1835924\ttest: 1.1355025\tbest: 1.1355025 (49)\ttotal: 1m\tremaining: 19m 14s\n",
      "50:\tlearn: 1.1832290\ttest: 1.1353829\tbest: 1.1353829 (50)\ttotal: 1m 1s\tremaining: 19m 6s\n",
      "51:\tlearn: 1.1831823\ttest: 1.1352826\tbest: 1.1352826 (51)\ttotal: 1m 2s\tremaining: 19m 2s\n",
      "52:\tlearn: 1.1830160\ttest: 1.1351616\tbest: 1.1351616 (52)\ttotal: 1m 3s\tremaining: 18m 52s\n",
      "53:\tlearn: 1.1829641\ttest: 1.1350872\tbest: 1.1350872 (53)\ttotal: 1m 4s\tremaining: 18m 50s\n",
      "54:\tlearn: 1.1828690\ttest: 1.1349792\tbest: 1.1349792 (54)\ttotal: 1m 5s\tremaining: 18m 43s\n",
      "55:\tlearn: 1.1826942\ttest: 1.1349445\tbest: 1.1349445 (55)\ttotal: 1m 6s\tremaining: 18m 43s\n",
      "56:\tlearn: 1.1825712\ttest: 1.1347797\tbest: 1.1347797 (56)\ttotal: 1m 8s\tremaining: 18m 46s\n",
      "57:\tlearn: 1.1824673\ttest: 1.1346120\tbest: 1.1346120 (57)\ttotal: 1m 9s\tremaining: 18m 41s\n",
      "58:\tlearn: 1.1813412\ttest: 1.1338018\tbest: 1.1338018 (58)\ttotal: 1m 10s\tremaining: 18m 37s\n",
      "59:\tlearn: 1.1754872\ttest: 1.1300582\tbest: 1.1300582 (59)\ttotal: 1m 11s\tremaining: 18m 33s\n",
      "60:\tlearn: 1.1753374\ttest: 1.1299638\tbest: 1.1299638 (60)\ttotal: 1m 11s\tremaining: 18m 26s\n",
      "61:\tlearn: 1.1752885\ttest: 1.1299065\tbest: 1.1299065 (61)\ttotal: 1m 12s\tremaining: 18m 22s\n",
      "62:\tlearn: 1.1752278\ttest: 1.1298644\tbest: 1.1298644 (62)\ttotal: 1m 13s\tremaining: 18m 17s\n",
      "63:\tlearn: 1.1752225\ttest: 1.1298793\tbest: 1.1298644 (62)\ttotal: 1m 14s\tremaining: 18m 14s\n",
      "64:\tlearn: 1.1751484\ttest: 1.1298853\tbest: 1.1298644 (62)\ttotal: 1m 15s\tremaining: 18m 8s\n",
      "65:\tlearn: 1.1750640\ttest: 1.1298313\tbest: 1.1298313 (65)\ttotal: 1m 16s\tremaining: 18m 4s\n",
      "66:\tlearn: 1.1748527\ttest: 1.1295700\tbest: 1.1295700 (66)\ttotal: 1m 17s\tremaining: 18m 1s\n",
      "67:\tlearn: 1.1741001\ttest: 1.1288384\tbest: 1.1288384 (67)\ttotal: 1m 18s\tremaining: 17m 57s\n",
      "68:\tlearn: 1.1727481\ttest: 1.1270978\tbest: 1.1270978 (68)\ttotal: 1m 19s\tremaining: 17m 54s\n",
      "69:\tlearn: 1.1714398\ttest: 1.1250320\tbest: 1.1250320 (69)\ttotal: 1m 20s\tremaining: 17m 52s\n",
      "70:\tlearn: 1.1671136\ttest: 1.1204965\tbest: 1.1204965 (70)\ttotal: 1m 21s\tremaining: 17m 50s\n",
      "71:\tlearn: 1.1669406\ttest: 1.1205274\tbest: 1.1204965 (70)\ttotal: 1m 22s\tremaining: 17m 46s\n",
      "72:\tlearn: 1.1669272\ttest: 1.1204468\tbest: 1.1204468 (72)\ttotal: 1m 23s\tremaining: 17m 45s\n",
      "73:\tlearn: 1.1667347\ttest: 1.1200955\tbest: 1.1200955 (73)\ttotal: 1m 24s\tremaining: 17m 41s\n",
      "74:\tlearn: 1.1664286\ttest: 1.1200183\tbest: 1.1200183 (74)\ttotal: 1m 25s\tremaining: 17m 38s\n",
      "75:\tlearn: 1.1664195\ttest: 1.1200219\tbest: 1.1200183 (74)\ttotal: 1m 26s\tremaining: 17m 35s\n",
      "76:\tlearn: 1.1664139\ttest: 1.1200261\tbest: 1.1200183 (74)\ttotal: 1m 27s\tremaining: 17m 32s\n",
      "77:\tlearn: 1.1663959\ttest: 1.1199841\tbest: 1.1199841 (77)\ttotal: 1m 28s\tremaining: 17m 30s\n",
      "78:\tlearn: 1.1660748\ttest: 1.1196637\tbest: 1.1196637 (78)\ttotal: 1m 29s\tremaining: 17m 28s\n",
      "79:\tlearn: 1.1660722\ttest: 1.1196565\tbest: 1.1196565 (79)\ttotal: 1m 30s\tremaining: 17m 25s\n",
      "80:\tlearn: 1.1644593\ttest: 1.1173026\tbest: 1.1173026 (80)\ttotal: 1m 32s\tremaining: 17m 25s\n",
      "81:\tlearn: 1.1635149\ttest: 1.1163560\tbest: 1.1163560 (81)\ttotal: 1m 33s\tremaining: 17m 22s\n",
      "82:\tlearn: 1.1576053\ttest: 1.1126998\tbest: 1.1126998 (82)\ttotal: 1m 34s\tremaining: 17m 22s\n",
      "83:\tlearn: 1.1575768\ttest: 1.1127671\tbest: 1.1126998 (82)\ttotal: 1m 35s\tremaining: 17m 18s\n",
      "84:\tlearn: 1.1575430\ttest: 1.1127527\tbest: 1.1126998 (82)\ttotal: 1m 36s\tremaining: 17m 16s\n",
      "85:\tlearn: 1.1561321\ttest: 1.1121979\tbest: 1.1121979 (85)\ttotal: 1m 37s\tremaining: 17m 17s\n",
      "86:\tlearn: 1.1556285\ttest: 1.1117810\tbest: 1.1117810 (86)\ttotal: 1m 38s\tremaining: 17m 13s\n",
      "87:\tlearn: 1.1551414\ttest: 1.1116053\tbest: 1.1116053 (87)\ttotal: 1m 39s\tremaining: 17m 14s\n",
      "88:\tlearn: 1.1550637\ttest: 1.1116409\tbest: 1.1116053 (87)\ttotal: 1m 41s\tremaining: 17m 18s\n",
      "89:\tlearn: 1.1542528\ttest: 1.1105623\tbest: 1.1105623 (89)\ttotal: 1m 43s\tremaining: 17m 25s\n",
      "90:\tlearn: 1.1542424\ttest: 1.1105301\tbest: 1.1105301 (90)\ttotal: 1m 44s\tremaining: 17m 21s\n",
      "91:\tlearn: 1.1542353\ttest: 1.1104967\tbest: 1.1104967 (91)\ttotal: 1m 45s\tremaining: 17m 22s\n",
      "92:\tlearn: 1.1532597\ttest: 1.1095254\tbest: 1.1095254 (92)\ttotal: 1m 47s\tremaining: 17m 24s\n",
      "93:\tlearn: 1.1514745\ttest: 1.1087731\tbest: 1.1087731 (93)\ttotal: 1m 48s\tremaining: 17m 25s\n",
      "94:\tlearn: 1.1512388\ttest: 1.1088201\tbest: 1.1087731 (93)\ttotal: 1m 49s\tremaining: 17m 24s\n",
      "95:\tlearn: 1.1511729\ttest: 1.1087776\tbest: 1.1087731 (93)\ttotal: 1m 50s\tremaining: 17m 21s\n",
      "96:\tlearn: 1.1511202\ttest: 1.1087158\tbest: 1.1087158 (96)\ttotal: 1m 51s\tremaining: 17m 18s\n",
      "97:\tlearn: 1.1509854\ttest: 1.1087143\tbest: 1.1087143 (97)\ttotal: 1m 52s\tremaining: 17m 17s\n",
      "98:\tlearn: 1.1509214\ttest: 1.1088161\tbest: 1.1087143 (97)\ttotal: 1m 54s\tremaining: 17m 18s\n",
      "99:\tlearn: 1.1508732\ttest: 1.1087613\tbest: 1.1087143 (97)\ttotal: 1m 54s\tremaining: 17m 13s\n",
      "100:\tlearn: 1.1508169\ttest: 1.1084761\tbest: 1.1084761 (100)\ttotal: 1m 55s\tremaining: 17m 9s\n",
      "101:\tlearn: 1.1506973\ttest: 1.1085427\tbest: 1.1084761 (100)\ttotal: 1m 56s\tremaining: 17m 8s\n",
      "102:\tlearn: 1.1506866\ttest: 1.1085317\tbest: 1.1084761 (100)\ttotal: 1m 57s\tremaining: 17m 6s\n",
      "103:\tlearn: 1.1506611\ttest: 1.1084647\tbest: 1.1084647 (103)\ttotal: 1m 59s\tremaining: 17m 9s\n",
      "104:\tlearn: 1.1502579\ttest: 1.1085737\tbest: 1.1084647 (103)\ttotal: 2m\tremaining: 17m 10s\n",
      "105:\tlearn: 1.1499364\ttest: 1.1081894\tbest: 1.1081894 (105)\ttotal: 2m 2s\tremaining: 17m 9s\n",
      "106:\tlearn: 1.1495633\ttest: 1.1079454\tbest: 1.1079454 (106)\ttotal: 2m 3s\tremaining: 17m 9s\n",
      "107:\tlearn: 1.1495450\ttest: 1.1079276\tbest: 1.1079276 (107)\ttotal: 2m 4s\tremaining: 17m 10s\n",
      "108:\tlearn: 1.1479189\ttest: 1.1076892\tbest: 1.1076892 (108)\ttotal: 2m 6s\tremaining: 17m 10s\n",
      "109:\tlearn: 1.1478469\ttest: 1.1076278\tbest: 1.1076278 (109)\ttotal: 2m 7s\tremaining: 17m 8s\n",
      "110:\tlearn: 1.1475943\ttest: 1.1074310\tbest: 1.1074310 (110)\ttotal: 2m 8s\tremaining: 17m 7s\n",
      "111:\tlearn: 1.1475665\ttest: 1.1073576\tbest: 1.1073576 (111)\ttotal: 2m 9s\tremaining: 17m 4s\n",
      "112:\tlearn: 1.1475266\ttest: 1.1073128\tbest: 1.1073128 (112)\ttotal: 2m 10s\tremaining: 17m 2s\n",
      "113:\tlearn: 1.1475157\ttest: 1.1073276\tbest: 1.1073128 (112)\ttotal: 2m 11s\tremaining: 16m 59s\n",
      "114:\tlearn: 1.1475113\ttest: 1.1073019\tbest: 1.1073019 (114)\ttotal: 2m 12s\tremaining: 16m 59s\n",
      "115:\tlearn: 1.1474965\ttest: 1.1072747\tbest: 1.1072747 (115)\ttotal: 2m 13s\tremaining: 16m 57s\n",
      "116:\tlearn: 1.1474909\ttest: 1.1072655\tbest: 1.1072655 (116)\ttotal: 2m 14s\tremaining: 16m 55s\n",
      "117:\tlearn: 1.1471393\ttest: 1.1071799\tbest: 1.1071799 (117)\ttotal: 2m 15s\tremaining: 16m 55s\n",
      "118:\tlearn: 1.1470565\ttest: 1.1071431\tbest: 1.1071431 (118)\ttotal: 2m 16s\tremaining: 16m 52s\n",
      "119:\tlearn: 1.1459914\ttest: 1.1069973\tbest: 1.1069973 (119)\ttotal: 2m 18s\tremaining: 16m 52s\n",
      "120:\tlearn: 1.1459827\ttest: 1.1069911\tbest: 1.1069911 (120)\ttotal: 2m 18s\tremaining: 16m 48s\n",
      "121:\tlearn: 1.1458739\ttest: 1.1069178\tbest: 1.1069178 (121)\ttotal: 2m 20s\tremaining: 16m 48s\n",
      "122:\tlearn: 1.1419961\ttest: 1.1026803\tbest: 1.1026803 (122)\ttotal: 2m 20s\tremaining: 16m 44s\n",
      "123:\tlearn: 1.1416800\ttest: 1.1023335\tbest: 1.1023335 (123)\ttotal: 2m 21s\tremaining: 16m 42s\n",
      "124:\tlearn: 1.1416748\ttest: 1.1023247\tbest: 1.1023247 (124)\ttotal: 2m 23s\tremaining: 16m 41s\n",
      "125:\tlearn: 1.1416143\ttest: 1.1022571\tbest: 1.1022571 (125)\ttotal: 2m 24s\tremaining: 16m 41s\n",
      "126:\tlearn: 1.1415416\ttest: 1.1022570\tbest: 1.1022570 (126)\ttotal: 2m 25s\tremaining: 16m 40s\n",
      "127:\tlearn: 1.1415156\ttest: 1.1022422\tbest: 1.1022422 (127)\ttotal: 2m 26s\tremaining: 16m 37s\n",
      "128:\tlearn: 1.1415086\ttest: 1.1022368\tbest: 1.1022368 (128)\ttotal: 2m 27s\tremaining: 16m 37s\n",
      "129:\tlearn: 1.1411771\ttest: 1.1021574\tbest: 1.1021574 (129)\ttotal: 2m 29s\tremaining: 16m 37s\n",
      "130:\tlearn: 1.1386724\ttest: 1.1012429\tbest: 1.1012429 (130)\ttotal: 2m 29s\tremaining: 16m 33s\n",
      "131:\tlearn: 1.1386143\ttest: 1.1012687\tbest: 1.1012429 (130)\ttotal: 2m 30s\tremaining: 16m 32s\n",
      "132:\tlearn: 1.1385487\ttest: 1.1012002\tbest: 1.1012002 (132)\ttotal: 2m 32s\tremaining: 16m 30s\n",
      "133:\tlearn: 1.1383862\ttest: 1.1012790\tbest: 1.1012002 (132)\ttotal: 2m 32s\tremaining: 16m 27s\n",
      "134:\tlearn: 1.1359419\ttest: 1.0987528\tbest: 1.0987528 (134)\ttotal: 2m 34s\tremaining: 16m 26s\n",
      "135:\tlearn: 1.1358906\ttest: 1.0987785\tbest: 1.0987528 (134)\ttotal: 2m 35s\tremaining: 16m 26s\n",
      "136:\tlearn: 1.1356392\ttest: 1.0984873\tbest: 1.0984873 (136)\ttotal: 2m 36s\tremaining: 16m 24s\n",
      "137:\tlearn: 1.1325769\ttest: 1.0973217\tbest: 1.0973217 (137)\ttotal: 2m 37s\tremaining: 16m 26s\n",
      "138:\tlearn: 1.1325577\ttest: 1.0973745\tbest: 1.0973217 (137)\ttotal: 2m 38s\tremaining: 16m 23s\n",
      "139:\tlearn: 1.1325087\ttest: 1.0973318\tbest: 1.0973217 (137)\ttotal: 2m 39s\tremaining: 16m 21s\n",
      "140:\tlearn: 1.1324467\ttest: 1.0972269\tbest: 1.0972269 (140)\ttotal: 2m 41s\tremaining: 16m 21s\n",
      "141:\tlearn: 1.1323512\ttest: 1.0972600\tbest: 1.0972269 (140)\ttotal: 2m 42s\tremaining: 16m 23s\n",
      "142:\tlearn: 1.1322360\ttest: 1.0972275\tbest: 1.0972269 (140)\ttotal: 2m 44s\tremaining: 16m 25s\n",
      "143:\tlearn: 1.1322134\ttest: 1.0972156\tbest: 1.0972156 (143)\ttotal: 2m 45s\tremaining: 16m 25s\n",
      "144:\tlearn: 1.1322051\ttest: 1.0971752\tbest: 1.0971752 (144)\ttotal: 2m 47s\tremaining: 16m 25s\n",
      "145:\tlearn: 1.1316318\ttest: 1.0962640\tbest: 1.0962640 (145)\ttotal: 2m 48s\tremaining: 16m 24s\n",
      "146:\tlearn: 1.1314289\ttest: 1.0961011\tbest: 1.0961011 (146)\ttotal: 2m 49s\tremaining: 16m 23s\n",
      "147:\tlearn: 1.1313997\ttest: 1.0960808\tbest: 1.0960808 (147)\ttotal: 2m 51s\tremaining: 16m 24s\n",
      "148:\tlearn: 1.1313857\ttest: 1.0960398\tbest: 1.0960398 (148)\ttotal: 2m 51s\tremaining: 16m 21s\n",
      "149:\tlearn: 1.1313821\ttest: 1.0960339\tbest: 1.0960339 (149)\ttotal: 2m 52s\tremaining: 16m 19s\n",
      "150:\tlearn: 1.1313687\ttest: 1.0960306\tbest: 1.0960306 (150)\ttotal: 2m 53s\tremaining: 16m 15s\n",
      "151:\tlearn: 1.1310159\ttest: 1.0956397\tbest: 1.0956397 (151)\ttotal: 2m 54s\tremaining: 16m 14s\n",
      "152:\tlearn: 1.1289113\ttest: 1.0921301\tbest: 1.0921301 (152)\ttotal: 2m 56s\tremaining: 16m 14s\n",
      "153:\tlearn: 1.1289058\ttest: 1.0921241\tbest: 1.0921241 (153)\ttotal: 2m 57s\tremaining: 16m 12s\n",
      "154:\tlearn: 1.1289024\ttest: 1.0921149\tbest: 1.0921149 (154)\ttotal: 2m 58s\tremaining: 16m 10s\n",
      "155:\tlearn: 1.1254352\ttest: 1.0886950\tbest: 1.0886950 (155)\ttotal: 2m 59s\tremaining: 16m 9s\n",
      "156:\tlearn: 1.1254228\ttest: 1.0886394\tbest: 1.0886394 (156)\ttotal: 3m\tremaining: 16m 9s\n",
      "157:\tlearn: 1.1252090\ttest: 1.0884173\tbest: 1.0884173 (157)\ttotal: 3m 1s\tremaining: 16m 8s\n",
      "158:\tlearn: 1.1251486\ttest: 1.0882890\tbest: 1.0882890 (158)\ttotal: 3m 2s\tremaining: 16m 6s\n",
      "159:\tlearn: 1.1251454\ttest: 1.0882841\tbest: 1.0882841 (159)\ttotal: 3m 3s\tremaining: 16m 5s\n",
      "160:\tlearn: 1.1246331\ttest: 1.0879001\tbest: 1.0879001 (160)\ttotal: 3m 5s\tremaining: 16m 5s\n",
      "161:\tlearn: 1.1239384\ttest: 1.0875640\tbest: 1.0875640 (161)\ttotal: 3m 6s\tremaining: 16m 2s\n",
      "162:\tlearn: 1.1239004\ttest: 1.0875885\tbest: 1.0875640 (161)\ttotal: 3m 7s\tremaining: 16m\n",
      "163:\tlearn: 1.1238969\ttest: 1.0875816\tbest: 1.0875640 (161)\ttotal: 3m 7s\tremaining: 15m 58s\n",
      "164:\tlearn: 1.1237201\ttest: 1.0875299\tbest: 1.0875299 (164)\ttotal: 3m 8s\tremaining: 15m 56s\n",
      "165:\tlearn: 1.1237160\ttest: 1.0875104\tbest: 1.0875104 (165)\ttotal: 3m 9s\tremaining: 15m 53s\n",
      "166:\tlearn: 1.1232276\ttest: 1.0872955\tbest: 1.0872955 (166)\ttotal: 3m 11s\tremaining: 15m 53s\n",
      "167:\tlearn: 1.1232222\ttest: 1.0872416\tbest: 1.0872416 (167)\ttotal: 3m 12s\tremaining: 15m 54s\n",
      "168:\tlearn: 1.1231839\ttest: 1.0871254\tbest: 1.0871254 (168)\ttotal: 3m 14s\tremaining: 15m 56s\n",
      "169:\tlearn: 1.1231628\ttest: 1.0871734\tbest: 1.0871254 (168)\ttotal: 3m 15s\tremaining: 15m 54s\n",
      "170:\tlearn: 1.1216921\ttest: 1.0867960\tbest: 1.0867960 (170)\ttotal: 3m 16s\tremaining: 15m 52s\n",
      "171:\tlearn: 1.1215448\ttest: 1.0867671\tbest: 1.0867671 (171)\ttotal: 3m 17s\tremaining: 15m 53s\n",
      "172:\tlearn: 1.1215423\ttest: 1.0867814\tbest: 1.0867671 (171)\ttotal: 3m 19s\tremaining: 15m 52s\n",
      "173:\tlearn: 1.1215170\ttest: 1.0867893\tbest: 1.0867671 (171)\ttotal: 3m 20s\tremaining: 15m 54s\n",
      "174:\tlearn: 1.1215036\ttest: 1.0867663\tbest: 1.0867663 (174)\ttotal: 3m 22s\tremaining: 15m 55s\n",
      "175:\tlearn: 1.1214986\ttest: 1.0867221\tbest: 1.0867221 (175)\ttotal: 3m 24s\tremaining: 15m 55s\n",
      "176:\tlearn: 1.1214638\ttest: 1.0866964\tbest: 1.0866964 (176)\ttotal: 3m 25s\tremaining: 15m 55s\n",
      "177:\tlearn: 1.1214613\ttest: 1.0866908\tbest: 1.0866908 (177)\ttotal: 3m 26s\tremaining: 15m 55s\n",
      "178:\tlearn: 1.1205977\ttest: 1.0859117\tbest: 1.0859117 (178)\ttotal: 3m 28s\tremaining: 15m 55s\n",
      "179:\tlearn: 1.1203567\ttest: 1.0858329\tbest: 1.0858329 (179)\ttotal: 3m 29s\tremaining: 15m 55s\n",
      "180:\tlearn: 1.1200909\ttest: 1.0854870\tbest: 1.0854870 (180)\ttotal: 3m 30s\tremaining: 15m 54s\n",
      "181:\tlearn: 1.1200661\ttest: 1.0854844\tbest: 1.0854844 (181)\ttotal: 3m 31s\tremaining: 15m 51s\n",
      "182:\tlearn: 1.1199056\ttest: 1.0854493\tbest: 1.0854493 (182)\ttotal: 3m 32s\tremaining: 15m 50s\n",
      "183:\tlearn: 1.1199012\ttest: 1.0854578\tbest: 1.0854493 (182)\ttotal: 3m 33s\tremaining: 15m 48s\n",
      "184:\tlearn: 1.1189088\ttest: 1.0846919\tbest: 1.0846919 (184)\ttotal: 3m 34s\tremaining: 15m 47s\n",
      "185:\tlearn: 1.1184956\ttest: 1.0843077\tbest: 1.0843077 (185)\ttotal: 3m 36s\tremaining: 15m 46s\n",
      "186:\tlearn: 1.1155327\ttest: 1.0812420\tbest: 1.0812420 (186)\ttotal: 3m 37s\tremaining: 15m 46s\n",
      "187:\tlearn: 1.1153346\ttest: 1.0809499\tbest: 1.0809499 (187)\ttotal: 3m 38s\tremaining: 15m 44s\n",
      "188:\tlearn: 1.1153283\ttest: 1.0809428\tbest: 1.0809428 (188)\ttotal: 3m 39s\tremaining: 15m 42s\n",
      "189:\tlearn: 1.1152631\ttest: 1.0809693\tbest: 1.0809428 (188)\ttotal: 3m 40s\tremaining: 15m 41s\n",
      "190:\tlearn: 1.1119118\ttest: 1.0792021\tbest: 1.0792021 (190)\ttotal: 3m 41s\tremaining: 15m 39s\n",
      "191:\tlearn: 1.1119058\ttest: 1.0791954\tbest: 1.0791954 (191)\ttotal: 3m 42s\tremaining: 15m 37s\n",
      "192:\tlearn: 1.1117504\ttest: 1.0789265\tbest: 1.0789265 (192)\ttotal: 3m 43s\tremaining: 15m 35s\n",
      "193:\tlearn: 1.1117369\ttest: 1.0789414\tbest: 1.0789265 (192)\ttotal: 3m 44s\tremaining: 15m 34s\n",
      "194:\tlearn: 1.1117251\ttest: 1.0789239\tbest: 1.0789239 (194)\ttotal: 3m 45s\tremaining: 15m 32s\n",
      "195:\tlearn: 1.1117202\ttest: 1.0789105\tbest: 1.0789105 (195)\ttotal: 3m 46s\tremaining: 15m 30s\n",
      "196:\tlearn: 1.1117163\ttest: 1.0789046\tbest: 1.0789046 (196)\ttotal: 3m 47s\tremaining: 15m 28s\n",
      "197:\tlearn: 1.1116938\ttest: 1.0788945\tbest: 1.0788945 (197)\ttotal: 3m 49s\tremaining: 15m 27s\n",
      "198:\tlearn: 1.1108771\ttest: 1.0776781\tbest: 1.0776781 (198)\ttotal: 3m 50s\tremaining: 15m 27s\n",
      "199:\tlearn: 1.1108674\ttest: 1.0776247\tbest: 1.0776247 (199)\ttotal: 3m 51s\tremaining: 15m 26s\n",
      "200:\tlearn: 1.1108631\ttest: 1.0776227\tbest: 1.0776227 (200)\ttotal: 3m 52s\tremaining: 15m 25s\n",
      "201:\tlearn: 1.1108622\ttest: 1.0776211\tbest: 1.0776211 (201)\ttotal: 3m 53s\tremaining: 15m 22s\n",
      "202:\tlearn: 1.1108618\ttest: 1.0776169\tbest: 1.0776169 (202)\ttotal: 3m 54s\tremaining: 15m 21s\n",
      "203:\tlearn: 1.1108597\ttest: 1.0776090\tbest: 1.0776090 (203)\ttotal: 3m 55s\tremaining: 15m 19s\n",
      "204:\tlearn: 1.1108583\ttest: 1.0776075\tbest: 1.0776075 (204)\ttotal: 3m 57s\tremaining: 15m 19s\n",
      "205:\tlearn: 1.1108502\ttest: 1.0776336\tbest: 1.0776075 (204)\ttotal: 3m 58s\tremaining: 15m 18s\n",
      "206:\tlearn: 1.1096960\ttest: 1.0774136\tbest: 1.0774136 (206)\ttotal: 3m 59s\tremaining: 15m 17s\n",
      "207:\tlearn: 1.1096763\ttest: 1.0774057\tbest: 1.0774057 (207)\ttotal: 4m\tremaining: 15m 16s\n",
      "208:\tlearn: 1.1096750\ttest: 1.0773998\tbest: 1.0773998 (208)\ttotal: 4m 1s\tremaining: 15m 14s\n",
      "209:\tlearn: 1.1096713\ttest: 1.0773934\tbest: 1.0773934 (209)\ttotal: 4m 2s\tremaining: 15m 12s\n",
      "210:\tlearn: 1.1096712\ttest: 1.0773952\tbest: 1.0773934 (209)\ttotal: 4m 3s\tremaining: 15m 10s\n",
      "211:\tlearn: 1.1096418\ttest: 1.0773774\tbest: 1.0773774 (211)\ttotal: 4m 4s\tremaining: 15m 10s\n",
      "212:\tlearn: 1.1096405\ttest: 1.0773347\tbest: 1.0773347 (212)\ttotal: 4m 5s\tremaining: 15m 8s\n",
      "213:\tlearn: 1.1095790\ttest: 1.0773497\tbest: 1.0773347 (212)\ttotal: 4m 7s\tremaining: 15m 7s\n",
      "214:\tlearn: 1.1095656\ttest: 1.0773230\tbest: 1.0773230 (214)\ttotal: 4m 8s\tremaining: 15m 5s\n",
      "215:\tlearn: 1.1095587\ttest: 1.0772973\tbest: 1.0772973 (215)\ttotal: 4m 9s\tremaining: 15m 4s\n",
      "216:\tlearn: 1.1092248\ttest: 1.0771974\tbest: 1.0771974 (216)\ttotal: 4m 10s\tremaining: 15m 2s\n",
      "217:\tlearn: 1.1092165\ttest: 1.0772125\tbest: 1.0771974 (216)\ttotal: 4m 11s\tremaining: 15m 1s\n",
      "218:\tlearn: 1.1091866\ttest: 1.0771951\tbest: 1.0771951 (218)\ttotal: 4m 12s\tremaining: 15m\n",
      "219:\tlearn: 1.1072842\ttest: 1.0764710\tbest: 1.0764710 (219)\ttotal: 4m 13s\tremaining: 14m 59s\n",
      "220:\tlearn: 1.1072640\ttest: 1.0764381\tbest: 1.0764381 (220)\ttotal: 4m 14s\tremaining: 14m 58s\n",
      "221:\tlearn: 1.1072456\ttest: 1.0763613\tbest: 1.0763613 (221)\ttotal: 4m 16s\tremaining: 14m 57s\n",
      "222:\tlearn: 1.1037011\ttest: 1.0757329\tbest: 1.0757329 (222)\ttotal: 4m 17s\tremaining: 14m 56s\n",
      "223:\tlearn: 1.1034185\ttest: 1.0753484\tbest: 1.0753484 (223)\ttotal: 4m 18s\tremaining: 14m 55s\n",
      "224:\tlearn: 1.1032060\ttest: 1.0749769\tbest: 1.0749769 (224)\ttotal: 4m 19s\tremaining: 14m 53s\n",
      "225:\tlearn: 1.1031960\ttest: 1.0749846\tbest: 1.0749769 (224)\ttotal: 4m 20s\tremaining: 14m 51s\n",
      "226:\tlearn: 1.1031840\ttest: 1.0749780\tbest: 1.0749769 (224)\ttotal: 4m 21s\tremaining: 14m 49s\n",
      "227:\tlearn: 1.1031727\ttest: 1.0749630\tbest: 1.0749630 (227)\ttotal: 4m 22s\tremaining: 14m 48s\n",
      "228:\tlearn: 1.1031320\ttest: 1.0749119\tbest: 1.0749119 (228)\ttotal: 4m 23s\tremaining: 14m 46s\n",
      "229:\tlearn: 1.1030519\ttest: 1.0747568\tbest: 1.0747568 (229)\ttotal: 4m 24s\tremaining: 14m 44s\n",
      "230:\tlearn: 1.1030169\ttest: 1.0746660\tbest: 1.0746660 (230)\ttotal: 4m 25s\tremaining: 14m 43s\n",
      "231:\tlearn: 1.1030077\ttest: 1.0746498\tbest: 1.0746498 (231)\ttotal: 4m 26s\tremaining: 14m 42s\n",
      "232:\tlearn: 1.1030033\ttest: 1.0746475\tbest: 1.0746475 (232)\ttotal: 4m 27s\tremaining: 14m 41s\n",
      "233:\tlearn: 1.1030026\ttest: 1.0746488\tbest: 1.0746475 (232)\ttotal: 4m 28s\tremaining: 14m 39s\n",
      "234:\tlearn: 1.1026569\ttest: 1.0741051\tbest: 1.0741051 (234)\ttotal: 4m 29s\tremaining: 14m 38s\n",
      "235:\tlearn: 1.1024482\ttest: 1.0740563\tbest: 1.0740563 (235)\ttotal: 4m 31s\tremaining: 14m 38s\n",
      "236:\tlearn: 1.1024455\ttest: 1.0740184\tbest: 1.0740184 (236)\ttotal: 4m 32s\tremaining: 14m 36s\n",
      "237:\tlearn: 1.1023556\ttest: 1.0739383\tbest: 1.0739383 (237)\ttotal: 4m 33s\tremaining: 14m 36s\n",
      "238:\tlearn: 1.1022122\ttest: 1.0738411\tbest: 1.0738411 (238)\ttotal: 4m 34s\tremaining: 14m 34s\n",
      "239:\tlearn: 1.1021984\ttest: 1.0738064\tbest: 1.0738064 (239)\ttotal: 4m 35s\tremaining: 14m 33s\n",
      "240:\tlearn: 1.1021942\ttest: 1.0737470\tbest: 1.0737470 (240)\ttotal: 4m 37s\tremaining: 14m 32s\n",
      "241:\tlearn: 1.1020866\ttest: 1.0736783\tbest: 1.0736783 (241)\ttotal: 4m 38s\tremaining: 14m 31s\n",
      "242:\tlearn: 1.1020171\ttest: 1.0736204\tbest: 1.0736204 (242)\ttotal: 4m 39s\tremaining: 14m 31s\n",
      "243:\tlearn: 1.1020034\ttest: 1.0735970\tbest: 1.0735970 (243)\ttotal: 4m 40s\tremaining: 14m 29s\n",
      "244:\tlearn: 1.1018705\ttest: 1.0734892\tbest: 1.0734892 (244)\ttotal: 4m 41s\tremaining: 14m 28s\n",
      "245:\tlearn: 1.1018587\ttest: 1.0734233\tbest: 1.0734233 (245)\ttotal: 4m 43s\tremaining: 14m 27s\n",
      "246:\tlearn: 1.1018572\ttest: 1.0733992\tbest: 1.0733992 (246)\ttotal: 4m 44s\tremaining: 14m 26s\n",
      "247:\tlearn: 1.1013307\ttest: 1.0732836\tbest: 1.0732836 (247)\ttotal: 4m 45s\tremaining: 14m 25s\n",
      "248:\tlearn: 1.1013167\ttest: 1.0732908\tbest: 1.0732836 (247)\ttotal: 4m 46s\tremaining: 14m 25s\n",
      "249:\tlearn: 1.0997964\ttest: 1.0716069\tbest: 1.0716069 (249)\ttotal: 4m 47s\tremaining: 14m 23s\n",
      "250:\tlearn: 1.0997958\ttest: 1.0715733\tbest: 1.0715733 (250)\ttotal: 4m 49s\tremaining: 14m 22s\n",
      "251:\tlearn: 1.0997813\ttest: 1.0715510\tbest: 1.0715510 (251)\ttotal: 4m 50s\tremaining: 14m 21s\n",
      "252:\tlearn: 1.0997402\ttest: 1.0715186\tbest: 1.0715186 (252)\ttotal: 4m 51s\tremaining: 14m 21s\n",
      "253:\tlearn: 1.0976367\ttest: 1.0709064\tbest: 1.0709064 (253)\ttotal: 4m 52s\tremaining: 14m 19s\n",
      "254:\tlearn: 1.0976374\ttest: 1.0709049\tbest: 1.0709049 (254)\ttotal: 4m 53s\tremaining: 14m 17s\n",
      "255:\tlearn: 1.0976365\ttest: 1.0709059\tbest: 1.0709049 (254)\ttotal: 4m 54s\tremaining: 14m 16s\n",
      "256:\tlearn: 1.0976308\ttest: 1.0709008\tbest: 1.0709008 (256)\ttotal: 4m 55s\tremaining: 14m 15s\n",
      "257:\tlearn: 1.0976155\ttest: 1.0708961\tbest: 1.0708961 (257)\ttotal: 4m 56s\tremaining: 14m 14s\n",
      "258:\tlearn: 1.0975324\ttest: 1.0708750\tbest: 1.0708750 (258)\ttotal: 4m 58s\tremaining: 14m 12s\n",
      "259:\tlearn: 1.0975267\ttest: 1.0708797\tbest: 1.0708750 (258)\ttotal: 4m 58s\tremaining: 14m 10s\n",
      "260:\tlearn: 1.0975240\ttest: 1.0708572\tbest: 1.0708572 (260)\ttotal: 5m\tremaining: 14m 9s\n",
      "261:\tlearn: 1.0969399\ttest: 1.0698276\tbest: 1.0698276 (261)\ttotal: 5m 1s\tremaining: 14m 8s\n",
      "262:\tlearn: 1.0968201\ttest: 1.0695089\tbest: 1.0695089 (262)\ttotal: 5m 2s\tremaining: 14m 7s\n",
      "263:\tlearn: 1.0966536\ttest: 1.0695322\tbest: 1.0695089 (262)\ttotal: 5m 3s\tremaining: 14m 6s\n",
      "264:\tlearn: 1.0966322\ttest: 1.0695446\tbest: 1.0695089 (262)\ttotal: 5m 5s\tremaining: 14m 6s\n",
      "265:\tlearn: 1.0966171\ttest: 1.0694957\tbest: 1.0694957 (265)\ttotal: 5m 5s\tremaining: 14m 4s\n",
      "266:\tlearn: 1.0966030\ttest: 1.0695020\tbest: 1.0694957 (265)\ttotal: 5m 6s\tremaining: 14m 1s\n",
      "267:\tlearn: 1.0962928\ttest: 1.0689978\tbest: 1.0689978 (267)\ttotal: 5m 7s\tremaining: 14m\n",
      "268:\tlearn: 1.0944122\ttest: 1.0665315\tbest: 1.0665315 (268)\ttotal: 5m 9s\tremaining: 14m\n",
      "269:\tlearn: 1.0944055\ttest: 1.0665102\tbest: 1.0665102 (269)\ttotal: 5m 10s\tremaining: 13m 59s\n",
      "270:\tlearn: 1.0943304\ttest: 1.0664600\tbest: 1.0664600 (270)\ttotal: 5m 11s\tremaining: 13m 57s\n",
      "271:\tlearn: 1.0940105\ttest: 1.0663667\tbest: 1.0663667 (271)\ttotal: 5m 12s\tremaining: 13m 56s\n",
      "272:\tlearn: 1.0939230\ttest: 1.0663706\tbest: 1.0663667 (271)\ttotal: 5m 13s\tremaining: 13m 55s\n",
      "273:\tlearn: 1.0939089\ttest: 1.0663670\tbest: 1.0663667 (271)\ttotal: 5m 14s\tremaining: 13m 53s\n",
      "274:\tlearn: 1.0938354\ttest: 1.0664120\tbest: 1.0663667 (271)\ttotal: 5m 15s\tremaining: 13m 52s\n",
      "275:\tlearn: 1.0938178\ttest: 1.0663889\tbest: 1.0663667 (271)\ttotal: 5m 16s\tremaining: 13m 50s\n",
      "276:\tlearn: 1.0934432\ttest: 1.0661421\tbest: 1.0661421 (276)\ttotal: 5m 17s\tremaining: 13m 49s\n",
      "277:\tlearn: 1.0933276\ttest: 1.0660257\tbest: 1.0660257 (277)\ttotal: 5m 18s\tremaining: 13m 47s\n",
      "278:\tlearn: 1.0932849\ttest: 1.0659839\tbest: 1.0659839 (278)\ttotal: 5m 20s\tremaining: 13m 47s\n",
      "279:\tlearn: 1.0931997\ttest: 1.0658186\tbest: 1.0658186 (279)\ttotal: 5m 21s\tremaining: 13m 47s\n",
      "280:\tlearn: 1.0925887\ttest: 1.0658258\tbest: 1.0658186 (279)\ttotal: 5m 22s\tremaining: 13m 46s\n",
      "281:\tlearn: 1.0925830\ttest: 1.0657903\tbest: 1.0657903 (281)\ttotal: 5m 24s\tremaining: 13m 45s\n",
      "282:\tlearn: 1.0925720\ttest: 1.0657933\tbest: 1.0657903 (281)\ttotal: 5m 24s\tremaining: 13m 43s\n",
      "283:\tlearn: 1.0925713\ttest: 1.0657652\tbest: 1.0657652 (283)\ttotal: 5m 25s\tremaining: 13m 41s\n",
      "284:\tlearn: 1.0925646\ttest: 1.0657640\tbest: 1.0657640 (284)\ttotal: 5m 26s\tremaining: 13m 40s\n",
      "285:\tlearn: 1.0925599\ttest: 1.0657628\tbest: 1.0657628 (285)\ttotal: 5m 27s\tremaining: 13m 38s\n",
      "286:\tlearn: 1.0923049\ttest: 1.0654809\tbest: 1.0654809 (286)\ttotal: 5m 28s\tremaining: 13m 37s\n",
      "287:\tlearn: 1.0922968\ttest: 1.0654885\tbest: 1.0654809 (286)\ttotal: 5m 30s\tremaining: 13m 35s\n",
      "288:\tlearn: 1.0921817\ttest: 1.0654319\tbest: 1.0654319 (288)\ttotal: 5m 31s\tremaining: 13m 35s\n",
      "289:\tlearn: 1.0921590\ttest: 1.0654587\tbest: 1.0654319 (288)\ttotal: 5m 32s\tremaining: 13m 34s\n",
      "290:\tlearn: 1.0921560\ttest: 1.0654574\tbest: 1.0654319 (288)\ttotal: 5m 33s\tremaining: 13m 32s\n",
      "291:\tlearn: 1.0921514\ttest: 1.0654641\tbest: 1.0654319 (288)\ttotal: 5m 34s\tremaining: 13m 31s\n",
      "292:\tlearn: 1.0918539\ttest: 1.0654976\tbest: 1.0654319 (288)\ttotal: 5m 35s\tremaining: 13m 29s\n",
      "293:\tlearn: 1.0918478\ttest: 1.0654960\tbest: 1.0654319 (288)\ttotal: 5m 36s\tremaining: 13m 27s\n",
      "294:\tlearn: 1.0917664\ttest: 1.0653463\tbest: 1.0653463 (294)\ttotal: 5m 37s\tremaining: 13m 27s\n",
      "295:\tlearn: 1.0917524\ttest: 1.0653437\tbest: 1.0653437 (295)\ttotal: 5m 39s\tremaining: 13m 26s\n",
      "296:\tlearn: 1.0916626\ttest: 1.0652513\tbest: 1.0652513 (296)\ttotal: 5m 40s\tremaining: 13m 25s\n",
      "297:\tlearn: 1.0916587\ttest: 1.0652541\tbest: 1.0652513 (296)\ttotal: 5m 41s\tremaining: 13m 23s\n",
      "298:\tlearn: 1.0914655\ttest: 1.0652662\tbest: 1.0652513 (296)\ttotal: 5m 42s\tremaining: 13m 23s\n",
      "299:\tlearn: 1.0909634\ttest: 1.0651235\tbest: 1.0651235 (299)\ttotal: 5m 43s\tremaining: 13m 22s\n",
      "300:\tlearn: 1.0908485\ttest: 1.0649879\tbest: 1.0649879 (300)\ttotal: 5m 45s\tremaining: 13m 21s\n",
      "301:\tlearn: 1.0908480\ttest: 1.0649874\tbest: 1.0649874 (301)\ttotal: 5m 46s\tremaining: 13m 19s\n",
      "302:\tlearn: 1.0907475\ttest: 1.0648816\tbest: 1.0648816 (302)\ttotal: 5m 47s\tremaining: 13m 18s\n",
      "303:\tlearn: 1.0907372\ttest: 1.0648879\tbest: 1.0648816 (302)\ttotal: 5m 48s\tremaining: 13m 18s\n",
      "304:\tlearn: 1.0906044\ttest: 1.0647146\tbest: 1.0647146 (304)\ttotal: 5m 49s\tremaining: 13m 17s\n",
      "305:\tlearn: 1.0904463\ttest: 1.0646353\tbest: 1.0646353 (305)\ttotal: 5m 51s\tremaining: 13m 16s\n",
      "306:\tlearn: 1.0903020\ttest: 1.0645542\tbest: 1.0645542 (306)\ttotal: 5m 52s\tremaining: 13m 15s\n",
      "307:\tlearn: 1.0896697\ttest: 1.0624431\tbest: 1.0624431 (307)\ttotal: 5m 53s\tremaining: 13m 13s\n",
      "308:\tlearn: 1.0894881\ttest: 1.0625015\tbest: 1.0624431 (307)\ttotal: 5m 54s\tremaining: 13m 13s\n",
      "309:\tlearn: 1.0894368\ttest: 1.0624870\tbest: 1.0624431 (307)\ttotal: 5m 56s\tremaining: 13m 12s\n",
      "310:\tlearn: 1.0894284\ttest: 1.0624819\tbest: 1.0624431 (307)\ttotal: 5m 56s\tremaining: 13m 10s\n",
      "311:\tlearn: 1.0893329\ttest: 1.0624173\tbest: 1.0624173 (311)\ttotal: 5m 57s\tremaining: 13m 9s\n",
      "312:\tlearn: 1.0893234\ttest: 1.0623962\tbest: 1.0623962 (312)\ttotal: 5m 58s\tremaining: 13m 7s\n",
      "313:\tlearn: 1.0892359\ttest: 1.0624502\tbest: 1.0623962 (312)\ttotal: 6m\tremaining: 13m 7s\n",
      "314:\tlearn: 1.0891356\ttest: 1.0622088\tbest: 1.0622088 (314)\ttotal: 6m 1s\tremaining: 13m 6s\n",
      "315:\tlearn: 1.0872005\ttest: 1.0612495\tbest: 1.0612495 (315)\ttotal: 6m 2s\tremaining: 13m 4s\n",
      "316:\tlearn: 1.0871268\ttest: 1.0611171\tbest: 1.0611171 (316)\ttotal: 6m 3s\tremaining: 13m 4s\n",
      "317:\tlearn: 1.0871241\ttest: 1.0611223\tbest: 1.0611171 (316)\ttotal: 6m 4s\tremaining: 13m 2s\n",
      "318:\tlearn: 1.0871187\ttest: 1.0611164\tbest: 1.0611164 (318)\ttotal: 6m 6s\tremaining: 13m 1s\n",
      "319:\tlearn: 1.0870654\ttest: 1.0609516\tbest: 1.0609516 (319)\ttotal: 6m 7s\tremaining: 13m\n",
      "320:\tlearn: 1.0870651\ttest: 1.0609492\tbest: 1.0609492 (320)\ttotal: 6m 7s\tremaining: 12m 58s\n",
      "321:\tlearn: 1.0870497\ttest: 1.0609166\tbest: 1.0609166 (321)\ttotal: 6m 9s\tremaining: 12m 57s\n",
      "322:\tlearn: 1.0867992\ttest: 1.0604271\tbest: 1.0604271 (322)\ttotal: 6m 10s\tremaining: 12m 57s\n",
      "323:\tlearn: 1.0866052\ttest: 1.0601269\tbest: 1.0601269 (323)\ttotal: 6m 11s\tremaining: 12m 55s\n",
      "324:\tlearn: 1.0838629\ttest: 1.0591108\tbest: 1.0591108 (324)\ttotal: 6m 13s\tremaining: 12m 54s\n",
      "325:\tlearn: 1.0838571\ttest: 1.0591140\tbest: 1.0591108 (324)\ttotal: 6m 14s\tremaining: 12m 53s\n",
      "326:\tlearn: 1.0838498\ttest: 1.0590867\tbest: 1.0590867 (326)\ttotal: 6m 15s\tremaining: 12m 52s\n",
      "327:\tlearn: 1.0835712\ttest: 1.0585612\tbest: 1.0585612 (327)\ttotal: 6m 16s\tremaining: 12m 50s\n",
      "328:\tlearn: 1.0835692\ttest: 1.0585755\tbest: 1.0585612 (327)\ttotal: 6m 17s\tremaining: 12m 50s\n",
      "329:\tlearn: 1.0835650\ttest: 1.0585998\tbest: 1.0585612 (327)\ttotal: 6m 18s\tremaining: 12m 49s\n",
      "330:\tlearn: 1.0828933\ttest: 1.0587364\tbest: 1.0585612 (327)\ttotal: 6m 19s\tremaining: 12m 47s\n",
      "331:\tlearn: 1.0826709\ttest: 1.0585983\tbest: 1.0585612 (327)\ttotal: 6m 20s\tremaining: 12m 46s\n",
      "332:\tlearn: 1.0826670\ttest: 1.0585991\tbest: 1.0585612 (327)\ttotal: 6m 22s\tremaining: 12m 45s\n",
      "333:\tlearn: 1.0826517\ttest: 1.0585809\tbest: 1.0585612 (327)\ttotal: 6m 23s\tremaining: 12m 43s\n",
      "334:\tlearn: 1.0826487\ttest: 1.0585462\tbest: 1.0585462 (334)\ttotal: 6m 23s\tremaining: 12m 42s\n",
      "335:\tlearn: 1.0826262\ttest: 1.0585620\tbest: 1.0585462 (334)\ttotal: 6m 25s\tremaining: 12m 40s\n",
      "336:\tlearn: 1.0826147\ttest: 1.0585745\tbest: 1.0585462 (334)\ttotal: 6m 25s\tremaining: 12m 39s\n",
      "337:\tlearn: 1.0823333\ttest: 1.0584771\tbest: 1.0584771 (337)\ttotal: 6m 27s\tremaining: 12m 38s\n",
      "338:\tlearn: 1.0822528\ttest: 1.0583906\tbest: 1.0583906 (338)\ttotal: 6m 28s\tremaining: 12m 37s\n",
      "339:\tlearn: 1.0822456\ttest: 1.0583592\tbest: 1.0583592 (339)\ttotal: 6m 29s\tremaining: 12m 36s\n",
      "340:\tlearn: 1.0817822\ttest: 1.0577197\tbest: 1.0577197 (340)\ttotal: 6m 30s\tremaining: 12m 35s\n",
      "341:\tlearn: 1.0817565\ttest: 1.0577043\tbest: 1.0577043 (341)\ttotal: 6m 32s\tremaining: 12m 34s\n",
      "342:\tlearn: 1.0815780\ttest: 1.0577290\tbest: 1.0577043 (341)\ttotal: 6m 32s\tremaining: 12m 32s\n",
      "343:\tlearn: 1.0815711\ttest: 1.0577109\tbest: 1.0577043 (341)\ttotal: 6m 34s\tremaining: 12m 31s\n",
      "344:\tlearn: 1.0814499\ttest: 1.0574414\tbest: 1.0574414 (344)\ttotal: 6m 35s\tremaining: 12m 30s\n",
      "345:\tlearn: 1.0811215\ttest: 1.0573274\tbest: 1.0573274 (345)\ttotal: 6m 36s\tremaining: 12m 29s\n",
      "346:\tlearn: 1.0808780\ttest: 1.0571660\tbest: 1.0571660 (346)\ttotal: 6m 37s\tremaining: 12m 28s\n",
      "347:\tlearn: 1.0807909\ttest: 1.0571744\tbest: 1.0571660 (346)\ttotal: 6m 39s\tremaining: 12m 27s\n",
      "348:\tlearn: 1.0807525\ttest: 1.0571077\tbest: 1.0571077 (348)\ttotal: 6m 40s\tremaining: 12m 26s\n",
      "349:\tlearn: 1.0806291\ttest: 1.0568087\tbest: 1.0568087 (349)\ttotal: 6m 41s\tremaining: 12m 25s\n",
      "350:\tlearn: 1.0801908\ttest: 1.0560873\tbest: 1.0560873 (350)\ttotal: 6m 42s\tremaining: 12m 24s\n",
      "351:\tlearn: 1.0795357\ttest: 1.0544551\tbest: 1.0544551 (351)\ttotal: 6m 43s\tremaining: 12m 22s\n",
      "352:\tlearn: 1.0795312\ttest: 1.0544573\tbest: 1.0544551 (351)\ttotal: 6m 44s\tremaining: 12m 21s\n",
      "353:\tlearn: 1.0795294\ttest: 1.0544576\tbest: 1.0544551 (351)\ttotal: 6m 45s\tremaining: 12m 20s\n",
      "354:\tlearn: 1.0795245\ttest: 1.0544687\tbest: 1.0544551 (351)\ttotal: 6m 46s\tremaining: 12m 19s\n",
      "355:\tlearn: 1.0795243\ttest: 1.0544664\tbest: 1.0544551 (351)\ttotal: 6m 47s\tremaining: 12m 17s\n",
      "356:\tlearn: 1.0795183\ttest: 1.0544637\tbest: 1.0544551 (351)\ttotal: 6m 48s\tremaining: 12m 16s\n",
      "357:\tlearn: 1.0795114\ttest: 1.0544414\tbest: 1.0544414 (357)\ttotal: 6m 49s\tremaining: 12m 15s\n",
      "358:\tlearn: 1.0795103\ttest: 1.0544015\tbest: 1.0544015 (358)\ttotal: 6m 50s\tremaining: 12m 13s\n",
      "359:\tlearn: 1.0794956\ttest: 1.0543657\tbest: 1.0543657 (359)\ttotal: 6m 51s\tremaining: 12m 12s\n",
      "360:\tlearn: 1.0794862\ttest: 1.0543530\tbest: 1.0543530 (360)\ttotal: 6m 52s\tremaining: 12m 11s\n",
      "361:\tlearn: 1.0794815\ttest: 1.0543518\tbest: 1.0543518 (361)\ttotal: 6m 54s\tremaining: 12m 9s\n",
      "362:\tlearn: 1.0794215\ttest: 1.0542524\tbest: 1.0542524 (362)\ttotal: 6m 55s\tremaining: 12m 8s\n",
      "363:\tlearn: 1.0794212\ttest: 1.0542500\tbest: 1.0542500 (363)\ttotal: 6m 56s\tremaining: 12m 7s\n",
      "364:\tlearn: 1.0789423\ttest: 1.0540801\tbest: 1.0540801 (364)\ttotal: 6m 57s\tremaining: 12m 6s\n",
      "365:\tlearn: 1.0788962\ttest: 1.0539151\tbest: 1.0539151 (365)\ttotal: 6m 58s\tremaining: 12m 5s\n",
      "366:\tlearn: 1.0788910\ttest: 1.0538953\tbest: 1.0538953 (366)\ttotal: 7m\tremaining: 12m 4s\n",
      "367:\tlearn: 1.0788909\ttest: 1.0538923\tbest: 1.0538923 (367)\ttotal: 7m 1s\tremaining: 12m 3s\n",
      "368:\tlearn: 1.0788265\ttest: 1.0537686\tbest: 1.0537686 (368)\ttotal: 7m 2s\tremaining: 12m 2s\n",
      "369:\tlearn: 1.0781085\ttest: 1.0528865\tbest: 1.0528865 (369)\ttotal: 7m 4s\tremaining: 12m 2s\n",
      "370:\tlearn: 1.0781037\ttest: 1.0528849\tbest: 1.0528849 (370)\ttotal: 7m 5s\tremaining: 12m 1s\n",
      "371:\tlearn: 1.0777446\ttest: 1.0529061\tbest: 1.0528849 (370)\ttotal: 7m 7s\tremaining: 12m 1s\n",
      "372:\tlearn: 1.0777319\ttest: 1.0529168\tbest: 1.0528849 (370)\ttotal: 7m 8s\tremaining: 12m\n",
      "373:\tlearn: 1.0777038\ttest: 1.0528352\tbest: 1.0528352 (373)\ttotal: 7m 10s\tremaining: 12m\n",
      "374:\tlearn: 1.0777021\ttest: 1.0528378\tbest: 1.0528352 (373)\ttotal: 7m 11s\tremaining: 11m 58s\n",
      "375:\tlearn: 1.0776994\ttest: 1.0528045\tbest: 1.0528045 (375)\ttotal: 7m 12s\tremaining: 11m 57s\n",
      "376:\tlearn: 1.0776956\ttest: 1.0527758\tbest: 1.0527758 (376)\ttotal: 7m 13s\tremaining: 11m 56s\n",
      "377:\tlearn: 1.0776818\ttest: 1.0527374\tbest: 1.0527374 (377)\ttotal: 7m 15s\tremaining: 11m 55s\n",
      "378:\tlearn: 1.0766408\ttest: 1.0514877\tbest: 1.0514877 (378)\ttotal: 7m 16s\tremaining: 11m 54s\n",
      "379:\tlearn: 1.0766197\ttest: 1.0514628\tbest: 1.0514628 (379)\ttotal: 7m 17s\tremaining: 11m 53s\n",
      "380:\tlearn: 1.0766104\ttest: 1.0514570\tbest: 1.0514570 (380)\ttotal: 7m 18s\tremaining: 11m 51s\n",
      "381:\tlearn: 1.0765979\ttest: 1.0514507\tbest: 1.0514507 (381)\ttotal: 7m 19s\tremaining: 11m 50s\n",
      "382:\tlearn: 1.0765860\ttest: 1.0514480\tbest: 1.0514480 (382)\ttotal: 7m 20s\tremaining: 11m 49s\n",
      "383:\tlearn: 1.0761233\ttest: 1.0512149\tbest: 1.0512149 (383)\ttotal: 7m 21s\tremaining: 11m 48s\n",
      "384:\tlearn: 1.0761176\ttest: 1.0512109\tbest: 1.0512109 (384)\ttotal: 7m 22s\tremaining: 11m 47s\n",
      "385:\tlearn: 1.0750036\ttest: 1.0511181\tbest: 1.0511181 (385)\ttotal: 7m 24s\tremaining: 11m 47s\n",
      "386:\tlearn: 1.0749972\ttest: 1.0511258\tbest: 1.0511181 (385)\ttotal: 7m 25s\tremaining: 11m 46s\n",
      "387:\tlearn: 1.0749947\ttest: 1.0511182\tbest: 1.0511181 (385)\ttotal: 7m 27s\tremaining: 11m 45s\n",
      "388:\tlearn: 1.0749811\ttest: 1.0511096\tbest: 1.0511096 (388)\ttotal: 7m 28s\tremaining: 11m 44s\n",
      "389:\tlearn: 1.0749803\ttest: 1.0511102\tbest: 1.0511096 (388)\ttotal: 7m 29s\tremaining: 11m 42s\n",
      "390:\tlearn: 1.0749776\ttest: 1.0510643\tbest: 1.0510643 (390)\ttotal: 7m 30s\tremaining: 11m 41s\n",
      "391:\tlearn: 1.0749364\ttest: 1.0510454\tbest: 1.0510454 (391)\ttotal: 7m 31s\tremaining: 11m 40s\n",
      "392:\tlearn: 1.0749294\ttest: 1.0510370\tbest: 1.0510370 (392)\ttotal: 7m 33s\tremaining: 11m 39s\n",
      "393:\tlearn: 1.0748571\ttest: 1.0509691\tbest: 1.0509691 (393)\ttotal: 7m 34s\tremaining: 11m 39s\n",
      "394:\tlearn: 1.0748549\ttest: 1.0509715\tbest: 1.0509691 (393)\ttotal: 7m 36s\tremaining: 11m 38s\n",
      "395:\tlearn: 1.0748544\ttest: 1.0509697\tbest: 1.0509691 (393)\ttotal: 7m 37s\tremaining: 11m 37s\n",
      "396:\tlearn: 1.0748522\ttest: 1.0509320\tbest: 1.0509320 (396)\ttotal: 7m 38s\tremaining: 11m 36s\n",
      "397:\tlearn: 1.0748510\ttest: 1.0509354\tbest: 1.0509320 (396)\ttotal: 7m 39s\tremaining: 11m 35s\n",
      "398:\tlearn: 1.0747449\ttest: 1.0507849\tbest: 1.0507849 (398)\ttotal: 7m 40s\tremaining: 11m 34s\n",
      "399:\tlearn: 1.0747347\ttest: 1.0507711\tbest: 1.0507711 (399)\ttotal: 7m 41s\tremaining: 11m 32s\n",
      "400:\tlearn: 1.0747225\ttest: 1.0507739\tbest: 1.0507711 (399)\ttotal: 7m 43s\tremaining: 11m 32s\n",
      "401:\tlearn: 1.0739834\ttest: 1.0501047\tbest: 1.0501047 (401)\ttotal: 7m 44s\tremaining: 11m 30s\n",
      "402:\tlearn: 1.0739697\ttest: 1.0501769\tbest: 1.0501047 (401)\ttotal: 7m 45s\tremaining: 11m 29s\n",
      "403:\tlearn: 1.0738515\ttest: 1.0499790\tbest: 1.0499790 (403)\ttotal: 7m 47s\tremaining: 11m 28s\n",
      "404:\tlearn: 1.0738502\ttest: 1.0499754\tbest: 1.0499754 (404)\ttotal: 7m 47s\tremaining: 11m 27s\n",
      "405:\tlearn: 1.0738457\ttest: 1.0499793\tbest: 1.0499754 (404)\ttotal: 7m 49s\tremaining: 11m 26s\n",
      "406:\tlearn: 1.0734458\ttest: 1.0498200\tbest: 1.0498200 (406)\ttotal: 7m 49s\tremaining: 11m 24s\n",
      "407:\tlearn: 1.0734368\ttest: 1.0498124\tbest: 1.0498124 (407)\ttotal: 7m 50s\tremaining: 11m 23s\n",
      "408:\tlearn: 1.0734256\ttest: 1.0498314\tbest: 1.0498124 (407)\ttotal: 7m 51s\tremaining: 11m 21s\n",
      "409:\tlearn: 1.0734220\ttest: 1.0497871\tbest: 1.0497871 (409)\ttotal: 7m 52s\tremaining: 11m 20s\n",
      "410:\tlearn: 1.0734213\ttest: 1.0497862\tbest: 1.0497862 (410)\ttotal: 7m 53s\tremaining: 11m 19s\n",
      "411:\tlearn: 1.0729815\ttest: 1.0496654\tbest: 1.0496654 (411)\ttotal: 7m 54s\tremaining: 11m 17s\n",
      "412:\tlearn: 1.0727273\ttest: 1.0497953\tbest: 1.0496654 (411)\ttotal: 7m 56s\tremaining: 11m 16s\n",
      "413:\tlearn: 1.0726992\ttest: 1.0497769\tbest: 1.0496654 (411)\ttotal: 7m 57s\tremaining: 11m 16s\n",
      "414:\tlearn: 1.0726904\ttest: 1.0497695\tbest: 1.0496654 (411)\ttotal: 7m 58s\tremaining: 11m 14s\n",
      "415:\tlearn: 1.0726879\ttest: 1.0497583\tbest: 1.0496654 (411)\ttotal: 7m 59s\tremaining: 11m 13s\n",
      "416:\tlearn: 1.0726271\ttest: 1.0496091\tbest: 1.0496091 (416)\ttotal: 8m 1s\tremaining: 11m 12s\n",
      "417:\tlearn: 1.0726256\ttest: 1.0496085\tbest: 1.0496085 (417)\ttotal: 8m 2s\tremaining: 11m 11s\n",
      "418:\tlearn: 1.0726201\ttest: 1.0495841\tbest: 1.0495841 (418)\ttotal: 8m 3s\tremaining: 11m 11s\n",
      "419:\tlearn: 1.0725303\ttest: 1.0495300\tbest: 1.0495300 (419)\ttotal: 8m 5s\tremaining: 11m 10s\n",
      "420:\tlearn: 1.0725116\ttest: 1.0494772\tbest: 1.0494772 (420)\ttotal: 8m 6s\tremaining: 11m 9s\n",
      "421:\tlearn: 1.0723407\ttest: 1.0494168\tbest: 1.0494168 (421)\ttotal: 8m 8s\tremaining: 11m 8s\n",
      "422:\tlearn: 1.0723164\ttest: 1.0494449\tbest: 1.0494168 (421)\ttotal: 8m 8s\tremaining: 11m 6s\n",
      "423:\tlearn: 1.0722783\ttest: 1.0493995\tbest: 1.0493995 (423)\ttotal: 8m 10s\tremaining: 11m 6s\n",
      "424:\tlearn: 1.0722750\ttest: 1.0493965\tbest: 1.0493965 (424)\ttotal: 8m 11s\tremaining: 11m 4s\n",
      "425:\tlearn: 1.0720031\ttest: 1.0491381\tbest: 1.0491381 (425)\ttotal: 8m 12s\tremaining: 11m 3s\n",
      "426:\tlearn: 1.0714858\ttest: 1.0489403\tbest: 1.0489403 (426)\ttotal: 8m 12s\tremaining: 11m 1s\n",
      "427:\tlearn: 1.0714294\ttest: 1.0487730\tbest: 1.0487730 (427)\ttotal: 8m 14s\tremaining: 11m\n",
      "428:\tlearn: 1.0714247\ttest: 1.0487699\tbest: 1.0487699 (428)\ttotal: 8m 15s\tremaining: 10m 59s\n",
      "429:\tlearn: 1.0713754\ttest: 1.0486428\tbest: 1.0486428 (429)\ttotal: 8m 17s\tremaining: 10m 59s\n",
      "430:\tlearn: 1.0713509\ttest: 1.0486593\tbest: 1.0486428 (429)\ttotal: 8m 18s\tremaining: 10m 58s\n",
      "431:\tlearn: 1.0712749\ttest: 1.0486291\tbest: 1.0486291 (431)\ttotal: 8m 19s\tremaining: 10m 57s\n",
      "432:\tlearn: 1.0712007\ttest: 1.0484892\tbest: 1.0484892 (432)\ttotal: 8m 21s\tremaining: 10m 56s\n",
      "433:\tlearn: 1.0711997\ttest: 1.0484894\tbest: 1.0484892 (432)\ttotal: 8m 22s\tremaining: 10m 55s\n",
      "434:\tlearn: 1.0711938\ttest: 1.0485126\tbest: 1.0484892 (432)\ttotal: 8m 24s\tremaining: 10m 54s\n",
      "435:\tlearn: 1.0706236\ttest: 1.0483292\tbest: 1.0483292 (435)\ttotal: 8m 25s\tremaining: 10m 54s\n",
      "436:\tlearn: 1.0705548\ttest: 1.0481777\tbest: 1.0481777 (436)\ttotal: 8m 26s\tremaining: 10m 53s\n",
      "437:\tlearn: 1.0705544\ttest: 1.0481773\tbest: 1.0481773 (437)\ttotal: 8m 28s\tremaining: 10m 52s\n",
      "438:\tlearn: 1.0704905\ttest: 1.0480471\tbest: 1.0480471 (438)\ttotal: 8m 29s\tremaining: 10m 51s\n",
      "439:\tlearn: 1.0704614\ttest: 1.0480592\tbest: 1.0480471 (438)\ttotal: 8m 31s\tremaining: 10m 50s\n",
      "440:\tlearn: 1.0703492\ttest: 1.0478205\tbest: 1.0478205 (440)\ttotal: 8m 32s\tremaining: 10m 49s\n",
      "441:\tlearn: 1.0690741\ttest: 1.0473555\tbest: 1.0473555 (441)\ttotal: 8m 34s\tremaining: 10m 49s\n",
      "442:\tlearn: 1.0690719\ttest: 1.0473390\tbest: 1.0473390 (442)\ttotal: 8m 35s\tremaining: 10m 48s\n",
      "443:\tlearn: 1.0688123\ttest: 1.0466088\tbest: 1.0466088 (443)\ttotal: 8m 36s\tremaining: 10m 47s\n",
      "444:\tlearn: 1.0687140\ttest: 1.0465351\tbest: 1.0465351 (444)\ttotal: 8m 38s\tremaining: 10m 46s\n",
      "445:\tlearn: 1.0680852\ttest: 1.0451889\tbest: 1.0451889 (445)\ttotal: 8m 39s\tremaining: 10m 45s\n",
      "446:\tlearn: 1.0680825\ttest: 1.0451636\tbest: 1.0451636 (446)\ttotal: 8m 40s\tremaining: 10m 44s\n",
      "447:\tlearn: 1.0680781\ttest: 1.0451663\tbest: 1.0451636 (446)\ttotal: 8m 41s\tremaining: 10m 42s\n",
      "448:\tlearn: 1.0680739\ttest: 1.0451659\tbest: 1.0451636 (446)\ttotal: 8m 42s\tremaining: 10m 41s\n",
      "449:\tlearn: 1.0680693\ttest: 1.0452150\tbest: 1.0451636 (446)\ttotal: 8m 43s\tremaining: 10m 40s\n",
      "450:\tlearn: 1.0680652\ttest: 1.0452093\tbest: 1.0451636 (446)\ttotal: 8m 44s\tremaining: 10m 38s\n",
      "451:\tlearn: 1.0680396\ttest: 1.0451985\tbest: 1.0451636 (446)\ttotal: 8m 46s\tremaining: 10m 37s\n",
      "452:\tlearn: 1.0678976\ttest: 1.0449452\tbest: 1.0449452 (452)\ttotal: 8m 47s\tremaining: 10m 37s\n",
      "453:\tlearn: 1.0678620\ttest: 1.0448935\tbest: 1.0448935 (453)\ttotal: 8m 48s\tremaining: 10m 35s\n",
      "454:\tlearn: 1.0678436\ttest: 1.0448597\tbest: 1.0448597 (454)\ttotal: 8m 49s\tremaining: 10m 34s\n",
      "455:\tlearn: 1.0678261\ttest: 1.0448600\tbest: 1.0448597 (454)\ttotal: 8m 51s\tremaining: 10m 33s\n",
      "456:\tlearn: 1.0677782\ttest: 1.0447029\tbest: 1.0447029 (456)\ttotal: 8m 52s\tremaining: 10m 32s\n",
      "457:\tlearn: 1.0677765\ttest: 1.0447027\tbest: 1.0447027 (457)\ttotal: 8m 53s\tremaining: 10m 31s\n",
      "458:\tlearn: 1.0677310\ttest: 1.0447707\tbest: 1.0447027 (457)\ttotal: 8m 54s\tremaining: 10m 30s\n",
      "459:\tlearn: 1.0677120\ttest: 1.0447598\tbest: 1.0447027 (457)\ttotal: 8m 55s\tremaining: 10m 28s\n",
      "460:\tlearn: 1.0677095\ttest: 1.0447390\tbest: 1.0447027 (457)\ttotal: 8m 56s\tremaining: 10m 27s\n",
      "461:\tlearn: 1.0677070\ttest: 1.0447379\tbest: 1.0447027 (457)\ttotal: 8m 58s\tremaining: 10m 26s\n",
      "462:\tlearn: 1.0673337\ttest: 1.0446484\tbest: 1.0446484 (462)\ttotal: 8m 59s\tremaining: 10m 25s\n",
      "463:\tlearn: 1.0672717\ttest: 1.0444818\tbest: 1.0444818 (463)\ttotal: 9m\tremaining: 10m 24s\n",
      "464:\tlearn: 1.0672102\ttest: 1.0443231\tbest: 1.0443231 (464)\ttotal: 9m 2s\tremaining: 10m 23s\n",
      "465:\tlearn: 1.0660904\ttest: 1.0438903\tbest: 1.0438903 (465)\ttotal: 9m 3s\tremaining: 10m 22s\n",
      "466:\tlearn: 1.0659717\ttest: 1.0435914\tbest: 1.0435914 (466)\ttotal: 9m 3s\tremaining: 10m 20s\n",
      "467:\tlearn: 1.0659674\ttest: 1.0435895\tbest: 1.0435895 (467)\ttotal: 9m 5s\tremaining: 10m 19s\n",
      "468:\tlearn: 1.0658863\ttest: 1.0433906\tbest: 1.0433906 (468)\ttotal: 9m 6s\tremaining: 10m 18s\n",
      "469:\tlearn: 1.0658244\ttest: 1.0432738\tbest: 1.0432738 (469)\ttotal: 9m 7s\tremaining: 10m 17s\n",
      "470:\tlearn: 1.0657457\ttest: 1.0433210\tbest: 1.0432738 (469)\ttotal: 9m 8s\tremaining: 10m 16s\n",
      "471:\tlearn: 1.0644394\ttest: 1.0420086\tbest: 1.0420086 (471)\ttotal: 9m 10s\tremaining: 10m 15s\n",
      "472:\tlearn: 1.0638241\ttest: 1.0413586\tbest: 1.0413586 (472)\ttotal: 9m 11s\tremaining: 10m 14s\n",
      "473:\tlearn: 1.0638130\ttest: 1.0413542\tbest: 1.0413542 (473)\ttotal: 9m 12s\tremaining: 10m 13s\n",
      "474:\tlearn: 1.0638116\ttest: 1.0413559\tbest: 1.0413542 (473)\ttotal: 9m 13s\tremaining: 10m 11s\n",
      "475:\tlearn: 1.0638113\ttest: 1.0413537\tbest: 1.0413537 (475)\ttotal: 9m 14s\tremaining: 10m 10s\n",
      "476:\tlearn: 1.0630588\ttest: 1.0410901\tbest: 1.0410901 (476)\ttotal: 9m 16s\tremaining: 10m 9s\n",
      "477:\tlearn: 1.0629884\ttest: 1.0409160\tbest: 1.0409160 (477)\ttotal: 9m 17s\tremaining: 10m 8s\n",
      "478:\tlearn: 1.0629407\ttest: 1.0408548\tbest: 1.0408548 (478)\ttotal: 9m 18s\tremaining: 10m 7s\n",
      "479:\tlearn: 1.0629174\ttest: 1.0408511\tbest: 1.0408511 (479)\ttotal: 9m 20s\tremaining: 10m 6s\n",
      "480:\tlearn: 1.0629149\ttest: 1.0408434\tbest: 1.0408434 (480)\ttotal: 9m 21s\tremaining: 10m 5s\n",
      "481:\tlearn: 1.0629141\ttest: 1.0408423\tbest: 1.0408423 (481)\ttotal: 9m 21s\tremaining: 10m 3s\n",
      "482:\tlearn: 1.0629142\ttest: 1.0408417\tbest: 1.0408417 (482)\ttotal: 9m 23s\tremaining: 10m 2s\n",
      "483:\tlearn: 1.0629037\ttest: 1.0406935\tbest: 1.0406935 (483)\ttotal: 9m 24s\tremaining: 10m 2s\n",
      "484:\tlearn: 1.0628131\ttest: 1.0405412\tbest: 1.0405412 (484)\ttotal: 9m 25s\tremaining: 10m\n",
      "485:\tlearn: 1.0622957\ttest: 1.0402720\tbest: 1.0402720 (485)\ttotal: 9m 27s\tremaining: 9m 59s\n",
      "486:\tlearn: 1.0622916\ttest: 1.0402663\tbest: 1.0402663 (486)\ttotal: 9m 28s\tremaining: 9m 58s\n",
      "487:\tlearn: 1.0622353\ttest: 1.0402332\tbest: 1.0402332 (487)\ttotal: 9m 29s\tremaining: 9m 57s\n",
      "488:\tlearn: 1.0621799\ttest: 1.0401662\tbest: 1.0401662 (488)\ttotal: 9m 30s\tremaining: 9m 56s\n",
      "489:\tlearn: 1.0621211\ttest: 1.0401259\tbest: 1.0401259 (489)\ttotal: 9m 32s\tremaining: 9m 55s\n",
      "490:\tlearn: 1.0620911\ttest: 1.0401179\tbest: 1.0401179 (490)\ttotal: 9m 33s\tremaining: 9m 54s\n",
      "491:\tlearn: 1.0620446\ttest: 1.0400971\tbest: 1.0400971 (491)\ttotal: 9m 34s\tremaining: 9m 52s\n",
      "492:\tlearn: 1.0619993\ttest: 1.0399961\tbest: 1.0399961 (492)\ttotal: 9m 34s\tremaining: 9m 51s\n",
      "493:\tlearn: 1.0619988\ttest: 1.0400007\tbest: 1.0399961 (492)\ttotal: 9m 36s\tremaining: 9m 50s\n",
      "494:\tlearn: 1.0619674\ttest: 1.0399798\tbest: 1.0399798 (494)\ttotal: 9m 37s\tremaining: 9m 49s\n",
      "495:\tlearn: 1.0619661\ttest: 1.0399775\tbest: 1.0399775 (495)\ttotal: 9m 38s\tremaining: 9m 47s\n",
      "496:\tlearn: 1.0619434\ttest: 1.0399621\tbest: 1.0399621 (496)\ttotal: 9m 39s\tremaining: 9m 46s\n",
      "497:\tlearn: 1.0619429\ttest: 1.0399644\tbest: 1.0399621 (496)\ttotal: 9m 40s\tremaining: 9m 45s\n",
      "498:\tlearn: 1.0609417\ttest: 1.0395710\tbest: 1.0395710 (498)\ttotal: 9m 42s\tremaining: 9m 44s\n",
      "499:\tlearn: 1.0609408\ttest: 1.0395718\tbest: 1.0395710 (498)\ttotal: 9m 42s\tremaining: 9m 42s\n",
      "500:\tlearn: 1.0609258\ttest: 1.0395143\tbest: 1.0395143 (500)\ttotal: 9m 44s\tremaining: 9m 41s\n",
      "501:\tlearn: 1.0608436\ttest: 1.0393740\tbest: 1.0393740 (501)\ttotal: 9m 45s\tremaining: 9m 40s\n",
      "502:\tlearn: 1.0607759\ttest: 1.0392197\tbest: 1.0392197 (502)\ttotal: 9m 46s\tremaining: 9m 39s\n",
      "503:\tlearn: 1.0604195\ttest: 1.0388647\tbest: 1.0388647 (503)\ttotal: 9m 47s\tremaining: 9m 38s\n",
      "504:\tlearn: 1.0604193\ttest: 1.0388630\tbest: 1.0388630 (504)\ttotal: 9m 49s\tremaining: 9m 37s\n",
      "505:\tlearn: 1.0604173\ttest: 1.0388815\tbest: 1.0388630 (504)\ttotal: 9m 49s\tremaining: 9m 35s\n",
      "506:\tlearn: 1.0604174\ttest: 1.0388804\tbest: 1.0388630 (504)\ttotal: 9m 51s\tremaining: 9m 34s\n",
      "507:\tlearn: 1.0604162\ttest: 1.0388731\tbest: 1.0388630 (504)\ttotal: 9m 52s\tremaining: 9m 33s\n",
      "508:\tlearn: 1.0604080\ttest: 1.0388700\tbest: 1.0388630 (504)\ttotal: 9m 53s\tremaining: 9m 32s\n",
      "509:\tlearn: 1.0603880\ttest: 1.0387961\tbest: 1.0387961 (509)\ttotal: 9m 54s\tremaining: 9m 31s\n",
      "510:\tlearn: 1.0603796\ttest: 1.0388025\tbest: 1.0387961 (509)\ttotal: 9m 55s\tremaining: 9m 29s\n",
      "511:\tlearn: 1.0603731\ttest: 1.0387746\tbest: 1.0387746 (511)\ttotal: 9m 56s\tremaining: 9m 29s\n",
      "512:\tlearn: 1.0603717\ttest: 1.0388070\tbest: 1.0387746 (511)\ttotal: 9m 58s\tremaining: 9m 27s\n",
      "513:\tlearn: 1.0602274\ttest: 1.0386728\tbest: 1.0386728 (513)\ttotal: 9m 59s\tremaining: 9m 26s\n",
      "514:\tlearn: 1.0602201\ttest: 1.0386693\tbest: 1.0386693 (514)\ttotal: 10m\tremaining: 9m 25s\n",
      "515:\tlearn: 1.0600067\ttest: 1.0380940\tbest: 1.0380940 (515)\ttotal: 10m 1s\tremaining: 9m 24s\n",
      "516:\tlearn: 1.0600059\ttest: 1.0380929\tbest: 1.0380929 (516)\ttotal: 10m 2s\tremaining: 9m 22s\n",
      "517:\tlearn: 1.0599914\ttest: 1.0380755\tbest: 1.0380755 (517)\ttotal: 10m 4s\tremaining: 9m 22s\n",
      "518:\tlearn: 1.0592106\ttest: 1.0378539\tbest: 1.0378539 (518)\ttotal: 10m 5s\tremaining: 9m 21s\n",
      "519:\tlearn: 1.0592090\ttest: 1.0378525\tbest: 1.0378525 (519)\ttotal: 10m 6s\tremaining: 9m 19s\n",
      "520:\tlearn: 1.0591855\ttest: 1.0377766\tbest: 1.0377766 (520)\ttotal: 10m 7s\tremaining: 9m 18s\n",
      "521:\tlearn: 1.0591830\ttest: 1.0377754\tbest: 1.0377754 (521)\ttotal: 10m 8s\tremaining: 9m 17s\n",
      "522:\tlearn: 1.0591208\ttest: 1.0376220\tbest: 1.0376220 (522)\ttotal: 10m 10s\tremaining: 9m 16s\n",
      "523:\tlearn: 1.0591197\ttest: 1.0376206\tbest: 1.0376206 (523)\ttotal: 10m 11s\tremaining: 9m 15s\n",
      "524:\tlearn: 1.0589750\ttest: 1.0373273\tbest: 1.0373273 (524)\ttotal: 10m 12s\tremaining: 9m 13s\n",
      "525:\tlearn: 1.0588735\ttest: 1.0372647\tbest: 1.0372647 (525)\ttotal: 10m 13s\tremaining: 9m 12s\n",
      "526:\tlearn: 1.0587861\ttest: 1.0371857\tbest: 1.0371857 (526)\ttotal: 10m 14s\tremaining: 9m 11s\n",
      "527:\tlearn: 1.0587856\ttest: 1.0371886\tbest: 1.0371857 (526)\ttotal: 10m 15s\tremaining: 9m 10s\n",
      "528:\tlearn: 1.0587303\ttest: 1.0370399\tbest: 1.0370399 (528)\ttotal: 10m 17s\tremaining: 9m 10s\n",
      "529:\tlearn: 1.0587240\ttest: 1.0370567\tbest: 1.0370399 (528)\ttotal: 10m 19s\tremaining: 9m 9s\n",
      "530:\tlearn: 1.0577274\ttest: 1.0366141\tbest: 1.0366141 (530)\ttotal: 10m 20s\tremaining: 9m 7s\n",
      "531:\tlearn: 1.0576613\ttest: 1.0364351\tbest: 1.0364351 (531)\ttotal: 10m 21s\tremaining: 9m 7s\n",
      "532:\tlearn: 1.0576607\ttest: 1.0364335\tbest: 1.0364335 (532)\ttotal: 10m 23s\tremaining: 9m 6s\n",
      "533:\tlearn: 1.0575986\ttest: 1.0362911\tbest: 1.0362911 (533)\ttotal: 10m 24s\tremaining: 9m 5s\n",
      "534:\tlearn: 1.0575856\ttest: 1.0362713\tbest: 1.0362713 (534)\ttotal: 10m 26s\tremaining: 9m 4s\n",
      "535:\tlearn: 1.0575357\ttest: 1.0361124\tbest: 1.0361124 (535)\ttotal: 10m 27s\tremaining: 9m 3s\n",
      "536:\tlearn: 1.0575335\ttest: 1.0360952\tbest: 1.0360952 (536)\ttotal: 10m 28s\tremaining: 9m 1s\n",
      "537:\tlearn: 1.0572192\ttest: 1.0360188\tbest: 1.0360188 (537)\ttotal: 10m 29s\tremaining: 9m\n",
      "538:\tlearn: 1.0571438\ttest: 1.0358112\tbest: 1.0358112 (538)\ttotal: 10m 30s\tremaining: 8m 59s\n",
      "539:\tlearn: 1.0568711\ttest: 1.0355890\tbest: 1.0355890 (539)\ttotal: 10m 32s\tremaining: 8m 58s\n",
      "540:\tlearn: 1.0568300\ttest: 1.0355801\tbest: 1.0355801 (540)\ttotal: 10m 33s\tremaining: 8m 57s\n",
      "541:\tlearn: 1.0549004\ttest: 1.0328369\tbest: 1.0328369 (541)\ttotal: 10m 34s\tremaining: 8m 56s\n",
      "542:\tlearn: 1.0548572\ttest: 1.0327695\tbest: 1.0327695 (542)\ttotal: 10m 35s\tremaining: 8m 54s\n",
      "543:\tlearn: 1.0548510\ttest: 1.0327639\tbest: 1.0327639 (543)\ttotal: 10m 36s\tremaining: 8m 53s\n",
      "544:\tlearn: 1.0547262\ttest: 1.0326189\tbest: 1.0326189 (544)\ttotal: 10m 37s\tremaining: 8m 52s\n",
      "545:\tlearn: 1.0547240\ttest: 1.0326233\tbest: 1.0326189 (544)\ttotal: 10m 39s\tremaining: 8m 51s\n",
      "546:\tlearn: 1.0536331\ttest: 1.0315233\tbest: 1.0315233 (546)\ttotal: 10m 40s\tremaining: 8m 50s\n",
      "547:\tlearn: 1.0536251\ttest: 1.0315077\tbest: 1.0315077 (547)\ttotal: 10m 41s\tremaining: 8m 48s\n",
      "548:\tlearn: 1.0536152\ttest: 1.0314735\tbest: 1.0314735 (548)\ttotal: 10m 42s\tremaining: 8m 47s\n",
      "549:\tlearn: 1.0535825\ttest: 1.0313953\tbest: 1.0313953 (549)\ttotal: 10m 43s\tremaining: 8m 46s\n",
      "550:\tlearn: 1.0535811\ttest: 1.0313870\tbest: 1.0313870 (550)\ttotal: 10m 44s\tremaining: 8m 45s\n",
      "551:\tlearn: 1.0534719\ttest: 1.0312702\tbest: 1.0312702 (551)\ttotal: 10m 46s\tremaining: 8m 44s\n",
      "552:\tlearn: 1.0534699\ttest: 1.0312668\tbest: 1.0312668 (552)\ttotal: 10m 46s\tremaining: 8m 42s\n",
      "553:\tlearn: 1.0532079\ttest: 1.0309658\tbest: 1.0309658 (553)\ttotal: 10m 47s\tremaining: 8m 41s\n",
      "554:\tlearn: 1.0531481\ttest: 1.0309481\tbest: 1.0309481 (554)\ttotal: 10m 49s\tremaining: 8m 40s\n",
      "555:\tlearn: 1.0526848\ttest: 1.0309024\tbest: 1.0309024 (555)\ttotal: 10m 50s\tremaining: 8m 39s\n",
      "556:\tlearn: 1.0525076\ttest: 1.0307665\tbest: 1.0307665 (556)\ttotal: 10m 51s\tremaining: 8m 38s\n",
      "557:\tlearn: 1.0524985\ttest: 1.0307179\tbest: 1.0307179 (557)\ttotal: 10m 52s\tremaining: 8m 36s\n",
      "558:\tlearn: 1.0524110\ttest: 1.0306487\tbest: 1.0306487 (558)\ttotal: 10m 53s\tremaining: 8m 35s\n",
      "559:\tlearn: 1.0519617\ttest: 1.0303670\tbest: 1.0303670 (559)\ttotal: 10m 55s\tremaining: 8m 34s\n",
      "560:\tlearn: 1.0519526\ttest: 1.0303267\tbest: 1.0303267 (560)\ttotal: 10m 56s\tremaining: 8m 33s\n",
      "561:\tlearn: 1.0519503\ttest: 1.0303231\tbest: 1.0303231 (561)\ttotal: 10m 57s\tremaining: 8m 32s\n",
      "562:\tlearn: 1.0519447\ttest: 1.0303172\tbest: 1.0303172 (562)\ttotal: 10m 59s\tremaining: 8m 31s\n",
      "563:\tlearn: 1.0516527\ttest: 1.0302695\tbest: 1.0302695 (563)\ttotal: 11m\tremaining: 8m 30s\n",
      "564:\tlearn: 1.0516076\ttest: 1.0301383\tbest: 1.0301383 (564)\ttotal: 11m 1s\tremaining: 8m 29s\n",
      "565:\tlearn: 1.0504819\ttest: 1.0289040\tbest: 1.0289040 (565)\ttotal: 11m 2s\tremaining: 8m 27s\n",
      "566:\tlearn: 1.0504709\ttest: 1.0289344\tbest: 1.0289040 (565)\ttotal: 11m 3s\tremaining: 8m 26s\n",
      "567:\tlearn: 1.0504709\ttest: 1.0289374\tbest: 1.0289040 (565)\ttotal: 11m 4s\tremaining: 8m 25s\n",
      "568:\tlearn: 1.0504695\ttest: 1.0289365\tbest: 1.0289040 (565)\ttotal: 11m 5s\tremaining: 8m 24s\n",
      "569:\tlearn: 1.0499001\ttest: 1.0280293\tbest: 1.0280293 (569)\ttotal: 11m 6s\tremaining: 8m 23s\n",
      "570:\tlearn: 1.0498983\ttest: 1.0280258\tbest: 1.0280258 (570)\ttotal: 11m 7s\tremaining: 8m 21s\n",
      "571:\tlearn: 1.0497324\ttest: 1.0279674\tbest: 1.0279674 (571)\ttotal: 11m 9s\tremaining: 8m 20s\n",
      "572:\tlearn: 1.0489957\ttest: 1.0269057\tbest: 1.0269057 (572)\ttotal: 11m 10s\tremaining: 8m 19s\n",
      "573:\tlearn: 1.0488291\ttest: 1.0264085\tbest: 1.0264085 (573)\ttotal: 11m 11s\tremaining: 8m 18s\n",
      "574:\tlearn: 1.0488259\ttest: 1.0263876\tbest: 1.0263876 (574)\ttotal: 11m 12s\tremaining: 8m 17s\n",
      "575:\tlearn: 1.0488096\ttest: 1.0263449\tbest: 1.0263449 (575)\ttotal: 11m 13s\tremaining: 8m 16s\n",
      "576:\tlearn: 1.0488007\ttest: 1.0263299\tbest: 1.0263299 (576)\ttotal: 11m 14s\tremaining: 8m 14s\n",
      "577:\tlearn: 1.0487799\ttest: 1.0263287\tbest: 1.0263287 (577)\ttotal: 11m 16s\tremaining: 8m 13s\n",
      "578:\tlearn: 1.0487788\ttest: 1.0263243\tbest: 1.0263243 (578)\ttotal: 11m 17s\tremaining: 8m 12s\n",
      "579:\tlearn: 1.0487788\ttest: 1.0263328\tbest: 1.0263243 (578)\ttotal: 11m 17s\tremaining: 8m 10s\n",
      "580:\tlearn: 1.0487510\ttest: 1.0263273\tbest: 1.0263243 (578)\ttotal: 11m 19s\tremaining: 8m 9s\n",
      "581:\tlearn: 1.0487233\ttest: 1.0263037\tbest: 1.0263037 (581)\ttotal: 11m 20s\tremaining: 8m 8s\n",
      "582:\tlearn: 1.0487222\ttest: 1.0263024\tbest: 1.0263024 (582)\ttotal: 11m 20s\tremaining: 8m 7s\n",
      "583:\tlearn: 1.0487208\ttest: 1.0263040\tbest: 1.0263024 (582)\ttotal: 11m 22s\tremaining: 8m 6s\n",
      "584:\tlearn: 1.0487021\ttest: 1.0263155\tbest: 1.0263024 (582)\ttotal: 11m 23s\tremaining: 8m 5s\n",
      "585:\tlearn: 1.0486762\ttest: 1.0263252\tbest: 1.0263024 (582)\ttotal: 11m 24s\tremaining: 8m 3s\n",
      "586:\tlearn: 1.0484034\ttest: 1.0259372\tbest: 1.0259372 (586)\ttotal: 11m 25s\tremaining: 8m 2s\n",
      "587:\tlearn: 1.0476878\ttest: 1.0257215\tbest: 1.0257215 (587)\ttotal: 11m 27s\tremaining: 8m 1s\n",
      "588:\tlearn: 1.0475982\ttest: 1.0255272\tbest: 1.0255272 (588)\ttotal: 11m 28s\tremaining: 8m\n",
      "589:\tlearn: 1.0475145\ttest: 1.0256322\tbest: 1.0255272 (588)\ttotal: 11m 29s\tremaining: 7m 59s\n",
      "590:\tlearn: 1.0474722\ttest: 1.0255755\tbest: 1.0255272 (588)\ttotal: 11m 31s\tremaining: 7m 58s\n",
      "591:\tlearn: 1.0474717\ttest: 1.0255660\tbest: 1.0255272 (588)\ttotal: 11m 32s\tremaining: 7m 57s\n",
      "592:\tlearn: 1.0474708\ttest: 1.0255616\tbest: 1.0255272 (588)\ttotal: 11m 34s\tremaining: 7m 56s\n",
      "593:\tlearn: 1.0460011\ttest: 1.0251723\tbest: 1.0251723 (593)\ttotal: 11m 35s\tremaining: 7m 55s\n",
      "594:\tlearn: 1.0460001\ttest: 1.0251697\tbest: 1.0251697 (594)\ttotal: 11m 36s\tremaining: 7m 54s\n",
      "595:\tlearn: 1.0454642\ttest: 1.0244243\tbest: 1.0244243 (595)\ttotal: 11m 37s\tremaining: 7m 53s\n",
      "596:\tlearn: 1.0454638\ttest: 1.0244205\tbest: 1.0244205 (596)\ttotal: 11m 38s\tremaining: 7m 51s\n",
      "597:\tlearn: 1.0454341\ttest: 1.0243883\tbest: 1.0243883 (597)\ttotal: 11m 40s\tremaining: 7m 50s\n",
      "598:\tlearn: 1.0453852\ttest: 1.0243399\tbest: 1.0243399 (598)\ttotal: 11m 41s\tremaining: 7m 49s\n",
      "599:\tlearn: 1.0453822\ttest: 1.0243379\tbest: 1.0243379 (599)\ttotal: 11m 43s\tremaining: 7m 48s\n",
      "600:\tlearn: 1.0453754\ttest: 1.0244277\tbest: 1.0243379 (599)\ttotal: 11m 44s\tremaining: 7m 47s\n",
      "601:\tlearn: 1.0453720\ttest: 1.0244274\tbest: 1.0243379 (599)\ttotal: 11m 45s\tremaining: 7m 46s\n",
      "602:\tlearn: 1.0453450\ttest: 1.0244204\tbest: 1.0243379 (599)\ttotal: 11m 47s\tremaining: 7m 45s\n",
      "603:\tlearn: 1.0453302\ttest: 1.0244413\tbest: 1.0243379 (599)\ttotal: 11m 48s\tremaining: 7m 44s\n",
      "604:\tlearn: 1.0452890\ttest: 1.0244421\tbest: 1.0243379 (599)\ttotal: 11m 49s\tremaining: 7m 43s\n",
      "605:\tlearn: 1.0452582\ttest: 1.0243734\tbest: 1.0243379 (599)\ttotal: 11m 50s\tremaining: 7m 42s\n",
      "606:\tlearn: 1.0452118\ttest: 1.0243678\tbest: 1.0243379 (599)\ttotal: 11m 52s\tremaining: 7m 41s\n",
      "607:\tlearn: 1.0452101\ttest: 1.0243715\tbest: 1.0243379 (599)\ttotal: 11m 53s\tremaining: 7m 40s\n",
      "608:\tlearn: 1.0448267\ttest: 1.0240778\tbest: 1.0240778 (608)\ttotal: 11m 54s\tremaining: 7m 38s\n",
      "609:\tlearn: 1.0448262\ttest: 1.0240758\tbest: 1.0240758 (609)\ttotal: 11m 56s\tremaining: 7m 37s\n",
      "610:\tlearn: 1.0448262\ttest: 1.0240739\tbest: 1.0240739 (610)\ttotal: 11m 57s\tremaining: 7m 36s\n",
      "611:\tlearn: 1.0448064\ttest: 1.0240391\tbest: 1.0240391 (611)\ttotal: 11m 58s\tremaining: 7m 35s\n",
      "612:\tlearn: 1.0447593\ttest: 1.0240405\tbest: 1.0240391 (611)\ttotal: 12m\tremaining: 7m 34s\n",
      "613:\tlearn: 1.0446662\ttest: 1.0239187\tbest: 1.0239187 (613)\ttotal: 12m 1s\tremaining: 7m 33s\n",
      "614:\tlearn: 1.0446517\ttest: 1.0239331\tbest: 1.0239187 (613)\ttotal: 12m 2s\tremaining: 7m 32s\n",
      "615:\tlearn: 1.0446007\ttest: 1.0239916\tbest: 1.0239187 (613)\ttotal: 12m 3s\tremaining: 7m 30s\n",
      "616:\tlearn: 1.0443899\ttest: 1.0240500\tbest: 1.0239187 (613)\ttotal: 12m 4s\tremaining: 7m 29s\n",
      "617:\tlearn: 1.0443851\ttest: 1.0240373\tbest: 1.0239187 (613)\ttotal: 12m 5s\tremaining: 7m 28s\n",
      "618:\tlearn: 1.0443795\ttest: 1.0240460\tbest: 1.0239187 (613)\ttotal: 12m 6s\tremaining: 7m 27s\n",
      "619:\tlearn: 1.0441754\ttest: 1.0239814\tbest: 1.0239187 (613)\ttotal: 12m 7s\tremaining: 7m 26s\n",
      "620:\tlearn: 1.0441737\ttest: 1.0239782\tbest: 1.0239187 (613)\ttotal: 12m 8s\tremaining: 7m 24s\n",
      "621:\tlearn: 1.0438668\ttest: 1.0235577\tbest: 1.0235577 (621)\ttotal: 12m 10s\tremaining: 7m 23s\n",
      "622:\tlearn: 1.0435419\ttest: 1.0229282\tbest: 1.0229282 (622)\ttotal: 12m 11s\tremaining: 7m 22s\n",
      "623:\tlearn: 1.0435360\ttest: 1.0229412\tbest: 1.0229282 (622)\ttotal: 12m 12s\tremaining: 7m 21s\n",
      "624:\tlearn: 1.0435255\ttest: 1.0229217\tbest: 1.0229217 (624)\ttotal: 12m 13s\tremaining: 7m 20s\n",
      "625:\tlearn: 1.0425795\ttest: 1.0216940\tbest: 1.0216940 (625)\ttotal: 12m 14s\tremaining: 7m 18s\n",
      "626:\tlearn: 1.0425796\ttest: 1.0216925\tbest: 1.0216925 (626)\ttotal: 12m 15s\tremaining: 7m 17s\n",
      "627:\tlearn: 1.0425757\ttest: 1.0216933\tbest: 1.0216925 (626)\ttotal: 12m 16s\tremaining: 7m 16s\n",
      "628:\tlearn: 1.0423286\ttest: 1.0216187\tbest: 1.0216187 (628)\ttotal: 12m 17s\tremaining: 7m 15s\n",
      "629:\tlearn: 1.0422701\ttest: 1.0216716\tbest: 1.0216187 (628)\ttotal: 12m 19s\tremaining: 7m 14s\n",
      "630:\tlearn: 1.0422693\ttest: 1.0216689\tbest: 1.0216187 (628)\ttotal: 12m 20s\tremaining: 7m 12s\n",
      "631:\tlearn: 1.0422621\ttest: 1.0216716\tbest: 1.0216187 (628)\ttotal: 12m 21s\tremaining: 7m 11s\n",
      "632:\tlearn: 1.0422611\ttest: 1.0216716\tbest: 1.0216187 (628)\ttotal: 12m 22s\tremaining: 7m 10s\n",
      "633:\tlearn: 1.0422401\ttest: 1.0216520\tbest: 1.0216187 (628)\ttotal: 12m 23s\tremaining: 7m 9s\n",
      "634:\tlearn: 1.0422391\ttest: 1.0216531\tbest: 1.0216187 (628)\ttotal: 12m 25s\tremaining: 7m 8s\n",
      "635:\tlearn: 1.0422284\ttest: 1.0215999\tbest: 1.0215999 (635)\ttotal: 12m 26s\tremaining: 7m 7s\n",
      "636:\tlearn: 1.0422074\ttest: 1.0215306\tbest: 1.0215306 (636)\ttotal: 12m 27s\tremaining: 7m 6s\n",
      "637:\tlearn: 1.0422062\ttest: 1.0215293\tbest: 1.0215293 (637)\ttotal: 12m 28s\tremaining: 7m 4s\n",
      "638:\tlearn: 1.0413788\ttest: 1.0203517\tbest: 1.0203517 (638)\ttotal: 12m 29s\tremaining: 7m 3s\n",
      "639:\tlearn: 1.0410980\ttest: 1.0200867\tbest: 1.0200867 (639)\ttotal: 12m 31s\tremaining: 7m 2s\n",
      "640:\tlearn: 1.0406837\ttest: 1.0196663\tbest: 1.0196663 (640)\ttotal: 12m 32s\tremaining: 7m 1s\n",
      "641:\tlearn: 1.0406110\ttest: 1.0196342\tbest: 1.0196342 (641)\ttotal: 12m 33s\tremaining: 7m\n",
      "642:\tlearn: 1.0406102\ttest: 1.0196341\tbest: 1.0196341 (642)\ttotal: 12m 34s\tremaining: 6m 58s\n",
      "643:\tlearn: 1.0403257\ttest: 1.0193227\tbest: 1.0193227 (643)\ttotal: 12m 35s\tremaining: 6m 57s\n",
      "644:\tlearn: 1.0403034\ttest: 1.0192904\tbest: 1.0192904 (644)\ttotal: 12m 36s\tremaining: 6m 56s\n",
      "645:\tlearn: 1.0402869\ttest: 1.0193128\tbest: 1.0192904 (644)\ttotal: 12m 38s\tremaining: 6m 55s\n",
      "646:\tlearn: 1.0402573\ttest: 1.0192677\tbest: 1.0192677 (646)\ttotal: 12m 39s\tremaining: 6m 54s\n",
      "647:\tlearn: 1.0394598\ttest: 1.0182133\tbest: 1.0182133 (647)\ttotal: 12m 41s\tremaining: 6m 53s\n",
      "648:\tlearn: 1.0394595\ttest: 1.0182110\tbest: 1.0182110 (648)\ttotal: 12m 42s\tremaining: 6m 52s\n",
      "649:\tlearn: 1.0394096\ttest: 1.0181203\tbest: 1.0181203 (649)\ttotal: 12m 43s\tremaining: 6m 51s\n",
      "650:\tlearn: 1.0390080\ttest: 1.0176086\tbest: 1.0176086 (650)\ttotal: 12m 44s\tremaining: 6m 50s\n",
      "651:\tlearn: 1.0389908\ttest: 1.0176474\tbest: 1.0176086 (650)\ttotal: 12m 46s\tremaining: 6m 49s\n",
      "652:\tlearn: 1.0384009\ttest: 1.0168374\tbest: 1.0168374 (652)\ttotal: 12m 48s\tremaining: 6m 48s\n",
      "653:\tlearn: 1.0383714\ttest: 1.0166658\tbest: 1.0166658 (653)\ttotal: 12m 50s\tremaining: 6m 47s\n",
      "654:\tlearn: 1.0382473\ttest: 1.0163751\tbest: 1.0163751 (654)\ttotal: 12m 51s\tremaining: 6m 46s\n",
      "655:\tlearn: 1.0382313\ttest: 1.0164489\tbest: 1.0163751 (654)\ttotal: 12m 52s\tremaining: 6m 45s\n",
      "656:\tlearn: 1.0380135\ttest: 1.0160492\tbest: 1.0160492 (656)\ttotal: 12m 54s\tremaining: 6m 44s\n",
      "657:\tlearn: 1.0380056\ttest: 1.0160591\tbest: 1.0160492 (656)\ttotal: 12m 55s\tremaining: 6m 42s\n",
      "658:\tlearn: 1.0373936\ttest: 1.0157841\tbest: 1.0157841 (658)\ttotal: 12m 56s\tremaining: 6m 41s\n",
      "659:\tlearn: 1.0373925\ttest: 1.0157850\tbest: 1.0157841 (658)\ttotal: 12m 57s\tremaining: 6m 40s\n",
      "660:\tlearn: 1.0373083\ttest: 1.0157403\tbest: 1.0157403 (660)\ttotal: 12m 59s\tremaining: 6m 39s\n",
      "661:\tlearn: 1.0372385\ttest: 1.0155588\tbest: 1.0155588 (661)\ttotal: 13m\tremaining: 6m 38s\n",
      "662:\tlearn: 1.0372379\ttest: 1.0155630\tbest: 1.0155588 (661)\ttotal: 13m 1s\tremaining: 6m 37s\n",
      "663:\tlearn: 1.0372374\ttest: 1.0155637\tbest: 1.0155588 (661)\ttotal: 13m 2s\tremaining: 6m 36s\n",
      "664:\tlearn: 1.0372341\ttest: 1.0155792\tbest: 1.0155588 (661)\ttotal: 13m 3s\tremaining: 6m 34s\n",
      "665:\tlearn: 1.0372045\ttest: 1.0154904\tbest: 1.0154904 (665)\ttotal: 13m 4s\tremaining: 6m 33s\n",
      "666:\tlearn: 1.0371975\ttest: 1.0155629\tbest: 1.0154904 (665)\ttotal: 13m 5s\tremaining: 6m 32s\n",
      "667:\tlearn: 1.0371982\ttest: 1.0155618\tbest: 1.0154904 (665)\ttotal: 13m 6s\tremaining: 6m 31s\n",
      "668:\tlearn: 1.0371808\ttest: 1.0155876\tbest: 1.0154904 (665)\ttotal: 13m 8s\tremaining: 6m 29s\n",
      "669:\tlearn: 1.0371487\ttest: 1.0155956\tbest: 1.0154904 (665)\ttotal: 13m 9s\tremaining: 6m 28s\n",
      "670:\tlearn: 1.0371454\ttest: 1.0155837\tbest: 1.0154904 (665)\ttotal: 13m 10s\tremaining: 6m 27s\n",
      "671:\tlearn: 1.0366567\ttest: 1.0156341\tbest: 1.0154904 (665)\ttotal: 13m 12s\tremaining: 6m 26s\n",
      "672:\tlearn: 1.0366468\ttest: 1.0157563\tbest: 1.0154904 (665)\ttotal: 13m 13s\tremaining: 6m 25s\n",
      "673:\tlearn: 1.0362405\ttest: 1.0154511\tbest: 1.0154511 (673)\ttotal: 13m 14s\tremaining: 6m 24s\n",
      "674:\tlearn: 1.0362258\ttest: 1.0155336\tbest: 1.0154511 (673)\ttotal: 13m 16s\tremaining: 6m 23s\n",
      "675:\tlearn: 1.0362258\ttest: 1.0155336\tbest: 1.0154511 (673)\ttotal: 13m 16s\tremaining: 6m 21s\n",
      "676:\tlearn: 1.0361780\ttest: 1.0155866\tbest: 1.0154511 (673)\ttotal: 13m 18s\tremaining: 6m 20s\n",
      "677:\tlearn: 1.0359657\ttest: 1.0157102\tbest: 1.0154511 (673)\ttotal: 13m 19s\tremaining: 6m 19s\n",
      "678:\tlearn: 1.0359652\ttest: 1.0157081\tbest: 1.0154511 (673)\ttotal: 13m 20s\tremaining: 6m 18s\n",
      "679:\tlearn: 1.0359550\ttest: 1.0156713\tbest: 1.0154511 (673)\ttotal: 13m 21s\tremaining: 6m 17s\n",
      "680:\tlearn: 1.0359507\ttest: 1.0156566\tbest: 1.0154511 (673)\ttotal: 13m 23s\tremaining: 6m 16s\n",
      "681:\tlearn: 1.0358062\ttest: 1.0156195\tbest: 1.0154511 (673)\ttotal: 13m 24s\tremaining: 6m 15s\n",
      "682:\tlearn: 1.0356793\ttest: 1.0155526\tbest: 1.0154511 (673)\ttotal: 13m 25s\tremaining: 6m 13s\n",
      "683:\tlearn: 1.0353688\ttest: 1.0155411\tbest: 1.0154511 (673)\ttotal: 13m 27s\tremaining: 6m 12s\n",
      "684:\tlearn: 1.0353138\ttest: 1.0155320\tbest: 1.0154511 (673)\ttotal: 13m 28s\tremaining: 6m 11s\n",
      "685:\tlearn: 1.0352866\ttest: 1.0154961\tbest: 1.0154511 (673)\ttotal: 13m 29s\tremaining: 6m 10s\n",
      "686:\tlearn: 1.0352519\ttest: 1.0152966\tbest: 1.0152966 (686)\ttotal: 13m 30s\tremaining: 6m 9s\n",
      "687:\tlearn: 1.0351845\ttest: 1.0152920\tbest: 1.0152920 (687)\ttotal: 13m 31s\tremaining: 6m 8s\n",
      "688:\tlearn: 1.0351840\ttest: 1.0152931\tbest: 1.0152920 (687)\ttotal: 13m 32s\tremaining: 6m 6s\n",
      "689:\tlearn: 1.0351511\ttest: 1.0151240\tbest: 1.0151240 (689)\ttotal: 13m 34s\tremaining: 6m 5s\n",
      "690:\tlearn: 1.0351119\ttest: 1.0147982\tbest: 1.0147982 (690)\ttotal: 13m 35s\tremaining: 6m 4s\n",
      "691:\tlearn: 1.0350398\ttest: 1.0148211\tbest: 1.0147982 (690)\ttotal: 13m 36s\tremaining: 6m 3s\n",
      "692:\tlearn: 1.0350394\ttest: 1.0148359\tbest: 1.0147982 (690)\ttotal: 13m 37s\tremaining: 6m 2s\n",
      "693:\tlearn: 1.0349429\ttest: 1.0147212\tbest: 1.0147212 (693)\ttotal: 13m 38s\tremaining: 6m 1s\n",
      "694:\tlearn: 1.0349019\ttest: 1.0147997\tbest: 1.0147212 (693)\ttotal: 13m 39s\tremaining: 5m 59s\n",
      "695:\tlearn: 1.0349019\ttest: 1.0147973\tbest: 1.0147212 (693)\ttotal: 13m 40s\tremaining: 5m 58s\n",
      "696:\tlearn: 1.0349012\ttest: 1.0147969\tbest: 1.0147212 (693)\ttotal: 13m 41s\tremaining: 5m 57s\n",
      "697:\tlearn: 1.0349006\ttest: 1.0147969\tbest: 1.0147212 (693)\ttotal: 13m 42s\tremaining: 5m 55s\n",
      "698:\tlearn: 1.0343548\ttest: 1.0146230\tbest: 1.0146230 (698)\ttotal: 13m 44s\tremaining: 5m 54s\n",
      "699:\tlearn: 1.0343534\ttest: 1.0146198\tbest: 1.0146198 (699)\ttotal: 13m 45s\tremaining: 5m 53s\n",
      "700:\tlearn: 1.0343082\ttest: 1.0145711\tbest: 1.0145711 (700)\ttotal: 13m 46s\tremaining: 5m 52s\n",
      "701:\tlearn: 1.0343011\ttest: 1.0145657\tbest: 1.0145657 (701)\ttotal: 13m 47s\tremaining: 5m 51s\n",
      "702:\tlearn: 1.0342971\ttest: 1.0145507\tbest: 1.0145507 (702)\ttotal: 13m 48s\tremaining: 5m 50s\n",
      "703:\tlearn: 1.0342908\ttest: 1.0145517\tbest: 1.0145507 (702)\ttotal: 13m 49s\tremaining: 5m 48s\n",
      "704:\tlearn: 1.0342839\ttest: 1.0145482\tbest: 1.0145482 (704)\ttotal: 13m 51s\tremaining: 5m 47s\n",
      "705:\tlearn: 1.0342828\ttest: 1.0145454\tbest: 1.0145454 (705)\ttotal: 13m 52s\tremaining: 5m 46s\n",
      "706:\tlearn: 1.0341984\ttest: 1.0145211\tbest: 1.0145211 (706)\ttotal: 13m 53s\tremaining: 5m 45s\n",
      "707:\tlearn: 1.0341710\ttest: 1.0144105\tbest: 1.0144105 (707)\ttotal: 13m 54s\tremaining: 5m 44s\n",
      "708:\tlearn: 1.0341695\ttest: 1.0143995\tbest: 1.0143995 (708)\ttotal: 13m 55s\tremaining: 5m 42s\n",
      "709:\tlearn: 1.0341168\ttest: 1.0142239\tbest: 1.0142239 (709)\ttotal: 13m 56s\tremaining: 5m 41s\n",
      "710:\tlearn: 1.0340409\ttest: 1.0141257\tbest: 1.0141257 (710)\ttotal: 13m 57s\tremaining: 5m 40s\n",
      "711:\tlearn: 1.0340143\ttest: 1.0140303\tbest: 1.0140303 (711)\ttotal: 13m 58s\tremaining: 5m 39s\n",
      "712:\tlearn: 1.0340019\ttest: 1.0140296\tbest: 1.0140296 (712)\ttotal: 13m 59s\tremaining: 5m 37s\n",
      "713:\tlearn: 1.0337545\ttest: 1.0137621\tbest: 1.0137621 (713)\ttotal: 14m\tremaining: 5m 36s\n",
      "714:\tlearn: 1.0337536\ttest: 1.0137585\tbest: 1.0137585 (714)\ttotal: 14m 1s\tremaining: 5m 35s\n",
      "715:\tlearn: 1.0337373\ttest: 1.0137454\tbest: 1.0137454 (715)\ttotal: 14m 2s\tremaining: 5m 34s\n",
      "716:\tlearn: 1.0337373\ttest: 1.0137624\tbest: 1.0137454 (715)\ttotal: 14m 3s\tremaining: 5m 33s\n",
      "717:\tlearn: 1.0336873\ttest: 1.0136545\tbest: 1.0136545 (717)\ttotal: 14m 4s\tremaining: 5m 31s\n",
      "718:\tlearn: 1.0336073\ttest: 1.0135401\tbest: 1.0135401 (718)\ttotal: 14m 5s\tremaining: 5m 30s\n",
      "719:\tlearn: 1.0335983\ttest: 1.0135899\tbest: 1.0135401 (718)\ttotal: 14m 7s\tremaining: 5m 29s\n",
      "720:\tlearn: 1.0335859\ttest: 1.0135648\tbest: 1.0135401 (718)\ttotal: 14m 8s\tremaining: 5m 28s\n",
      "721:\tlearn: 1.0335709\ttest: 1.0135474\tbest: 1.0135401 (718)\ttotal: 14m 9s\tremaining: 5m 27s\n",
      "722:\tlearn: 1.0335672\ttest: 1.0135255\tbest: 1.0135255 (722)\ttotal: 14m 10s\tremaining: 5m 25s\n",
      "723:\tlearn: 1.0335491\ttest: 1.0135224\tbest: 1.0135224 (723)\ttotal: 14m 12s\tremaining: 5m 24s\n",
      "724:\tlearn: 1.0335083\ttest: 1.0134021\tbest: 1.0134021 (724)\ttotal: 14m 13s\tremaining: 5m 23s\n",
      "725:\tlearn: 1.0331925\ttest: 1.0133371\tbest: 1.0133371 (725)\ttotal: 14m 14s\tremaining: 5m 22s\n",
      "726:\tlearn: 1.0331286\ttest: 1.0133309\tbest: 1.0133309 (726)\ttotal: 14m 16s\tremaining: 5m 21s\n",
      "727:\tlearn: 1.0331043\ttest: 1.0133210\tbest: 1.0133210 (727)\ttotal: 14m 17s\tremaining: 5m 20s\n",
      "728:\tlearn: 1.0330975\ttest: 1.0132999\tbest: 1.0132999 (728)\ttotal: 14m 18s\tremaining: 5m 19s\n",
      "729:\tlearn: 1.0330930\ttest: 1.0132859\tbest: 1.0132859 (729)\ttotal: 14m 19s\tremaining: 5m 17s\n",
      "730:\tlearn: 1.0330832\ttest: 1.0133889\tbest: 1.0132859 (729)\ttotal: 14m 20s\tremaining: 5m 16s\n",
      "731:\tlearn: 1.0330780\ttest: 1.0133742\tbest: 1.0132859 (729)\ttotal: 14m 21s\tremaining: 5m 15s\n",
      "732:\tlearn: 1.0330532\ttest: 1.0135392\tbest: 1.0132859 (729)\ttotal: 14m 23s\tremaining: 5m 14s\n",
      "733:\tlearn: 1.0330531\ttest: 1.0135377\tbest: 1.0132859 (729)\ttotal: 14m 23s\tremaining: 5m 13s\n",
      "734:\tlearn: 1.0330488\ttest: 1.0135107\tbest: 1.0132859 (729)\ttotal: 14m 24s\tremaining: 5m 11s\n",
      "735:\tlearn: 1.0329868\ttest: 1.0135074\tbest: 1.0132859 (729)\ttotal: 14m 26s\tremaining: 5m 10s\n",
      "736:\tlearn: 1.0329856\ttest: 1.0135083\tbest: 1.0132859 (729)\ttotal: 14m 27s\tremaining: 5m 9s\n",
      "737:\tlearn: 1.0329813\ttest: 1.0134871\tbest: 1.0132859 (729)\ttotal: 14m 28s\tremaining: 5m 8s\n",
      "738:\tlearn: 1.0329812\ttest: 1.0134829\tbest: 1.0132859 (729)\ttotal: 14m 29s\tremaining: 5m 6s\n",
      "739:\tlearn: 1.0329807\ttest: 1.0134798\tbest: 1.0132859 (729)\ttotal: 14m 30s\tremaining: 5m 5s\n",
      "740:\tlearn: 1.0328859\ttest: 1.0133359\tbest: 1.0132859 (729)\ttotal: 14m 30s\tremaining: 5m 4s\n",
      "741:\tlearn: 1.0328800\ttest: 1.0133390\tbest: 1.0132859 (729)\ttotal: 14m 31s\tremaining: 5m 3s\n",
      "742:\tlearn: 1.0328672\ttest: 1.0133345\tbest: 1.0132859 (729)\ttotal: 14m 32s\tremaining: 5m 1s\n",
      "743:\tlearn: 1.0327174\ttest: 1.0132472\tbest: 1.0132472 (743)\ttotal: 14m 34s\tremaining: 5m\n",
      "744:\tlearn: 1.0327161\ttest: 1.0132435\tbest: 1.0132435 (744)\ttotal: 14m 35s\tremaining: 4m 59s\n",
      "745:\tlearn: 1.0326933\ttest: 1.0132460\tbest: 1.0132435 (744)\ttotal: 14m 36s\tremaining: 4m 58s\n",
      "746:\tlearn: 1.0326934\ttest: 1.0132442\tbest: 1.0132435 (744)\ttotal: 14m 37s\tremaining: 4m 57s\n",
      "747:\tlearn: 1.0326760\ttest: 1.0132535\tbest: 1.0132435 (744)\ttotal: 14m 38s\tremaining: 4m 56s\n",
      "748:\tlearn: 1.0325965\ttest: 1.0129384\tbest: 1.0129384 (748)\ttotal: 14m 40s\tremaining: 4m 54s\n",
      "749:\tlearn: 1.0325710\ttest: 1.0129007\tbest: 1.0129007 (749)\ttotal: 14m 41s\tremaining: 4m 53s\n",
      "750:\tlearn: 1.0325172\ttest: 1.0129264\tbest: 1.0129007 (749)\ttotal: 14m 42s\tremaining: 4m 52s\n",
      "751:\tlearn: 1.0324456\ttest: 1.0127171\tbest: 1.0127171 (751)\ttotal: 14m 43s\tremaining: 4m 51s\n",
      "752:\tlearn: 1.0324449\ttest: 1.0127153\tbest: 1.0127153 (752)\ttotal: 14m 44s\tremaining: 4m 50s\n",
      "753:\tlearn: 1.0324451\ttest: 1.0127123\tbest: 1.0127123 (753)\ttotal: 14m 45s\tremaining: 4m 48s\n",
      "754:\tlearn: 1.0324449\ttest: 1.0127091\tbest: 1.0127091 (754)\ttotal: 14m 46s\tremaining: 4m 47s\n",
      "755:\tlearn: 1.0324394\ttest: 1.0126918\tbest: 1.0126918 (755)\ttotal: 14m 47s\tremaining: 4m 46s\n",
      "756:\tlearn: 1.0324200\ttest: 1.0126959\tbest: 1.0126918 (755)\ttotal: 14m 49s\tremaining: 4m 45s\n",
      "757:\tlearn: 1.0324093\ttest: 1.0127093\tbest: 1.0126918 (755)\ttotal: 14m 50s\tremaining: 4m 44s\n",
      "758:\tlearn: 1.0324088\ttest: 1.0127069\tbest: 1.0126918 (755)\ttotal: 14m 51s\tremaining: 4m 42s\n",
      "759:\tlearn: 1.0324081\ttest: 1.0127037\tbest: 1.0126918 (755)\ttotal: 14m 52s\tremaining: 4m 41s\n",
      "760:\tlearn: 1.0324018\ttest: 1.0127135\tbest: 1.0126918 (755)\ttotal: 14m 53s\tremaining: 4m 40s\n",
      "761:\tlearn: 1.0324007\ttest: 1.0127134\tbest: 1.0126918 (755)\ttotal: 14m 54s\tremaining: 4m 39s\n",
      "762:\tlearn: 1.0323644\ttest: 1.0127600\tbest: 1.0126918 (755)\ttotal: 14m 55s\tremaining: 4m 38s\n",
      "763:\tlearn: 1.0321911\ttest: 1.0127409\tbest: 1.0126918 (755)\ttotal: 14m 57s\tremaining: 4m 37s\n",
      "764:\tlearn: 1.0321891\ttest: 1.0127467\tbest: 1.0126918 (755)\ttotal: 14m 57s\tremaining: 4m 35s\n",
      "765:\tlearn: 1.0321885\ttest: 1.0127457\tbest: 1.0126918 (755)\ttotal: 14m 58s\tremaining: 4m 34s\n",
      "766:\tlearn: 1.0321834\ttest: 1.0126962\tbest: 1.0126918 (755)\ttotal: 15m\tremaining: 4m 33s\n",
      "767:\tlearn: 1.0321406\ttest: 1.0126200\tbest: 1.0126200 (767)\ttotal: 15m 1s\tremaining: 4m 32s\n",
      "768:\tlearn: 1.0321400\ttest: 1.0126175\tbest: 1.0126175 (768)\ttotal: 15m 2s\tremaining: 4m 30s\n",
      "769:\tlearn: 1.0320623\ttest: 1.0125519\tbest: 1.0125519 (769)\ttotal: 15m 3s\tremaining: 4m 29s\n",
      "770:\tlearn: 1.0320543\ttest: 1.0125466\tbest: 1.0125466 (770)\ttotal: 15m 4s\tremaining: 4m 28s\n",
      "771:\tlearn: 1.0319725\ttest: 1.0124549\tbest: 1.0124549 (771)\ttotal: 15m 5s\tremaining: 4m 27s\n",
      "772:\tlearn: 1.0318884\ttest: 1.0123654\tbest: 1.0123654 (772)\ttotal: 15m 7s\tremaining: 4m 26s\n",
      "773:\tlearn: 1.0318379\ttest: 1.0121777\tbest: 1.0121777 (773)\ttotal: 15m 8s\tremaining: 4m 25s\n",
      "774:\tlearn: 1.0317820\ttest: 1.0120903\tbest: 1.0120903 (774)\ttotal: 15m 10s\tremaining: 4m 24s\n",
      "775:\tlearn: 1.0317782\ttest: 1.0120858\tbest: 1.0120858 (775)\ttotal: 15m 11s\tremaining: 4m 23s\n",
      "776:\tlearn: 1.0317762\ttest: 1.0120860\tbest: 1.0120858 (775)\ttotal: 15m 12s\tremaining: 4m 21s\n",
      "777:\tlearn: 1.0317451\ttest: 1.0120802\tbest: 1.0120802 (777)\ttotal: 15m 14s\tremaining: 4m 20s\n",
      "778:\tlearn: 1.0317451\ttest: 1.0120774\tbest: 1.0120774 (778)\ttotal: 15m 15s\tremaining: 4m 19s\n",
      "779:\tlearn: 1.0317304\ttest: 1.0120714\tbest: 1.0120714 (779)\ttotal: 15m 16s\tremaining: 4m 18s\n",
      "780:\tlearn: 1.0317280\ttest: 1.0120731\tbest: 1.0120714 (779)\ttotal: 15m 17s\tremaining: 4m 17s\n",
      "781:\tlearn: 1.0316927\ttest: 1.0119600\tbest: 1.0119600 (781)\ttotal: 15m 18s\tremaining: 4m 16s\n",
      "782:\tlearn: 1.0316804\ttest: 1.0119860\tbest: 1.0119600 (781)\ttotal: 15m 20s\tremaining: 4m 15s\n",
      "783:\tlearn: 1.0313074\ttest: 1.0114996\tbest: 1.0114996 (783)\ttotal: 15m 21s\tremaining: 4m 13s\n",
      "784:\tlearn: 1.0313021\ttest: 1.0114977\tbest: 1.0114977 (784)\ttotal: 15m 22s\tremaining: 4m 12s\n",
      "785:\tlearn: 1.0312702\ttest: 1.0114406\tbest: 1.0114406 (785)\ttotal: 15m 24s\tremaining: 4m 11s\n",
      "786:\tlearn: 1.0312668\ttest: 1.0114553\tbest: 1.0114406 (785)\ttotal: 15m 25s\tremaining: 4m 10s\n",
      "787:\tlearn: 1.0312616\ttest: 1.0115082\tbest: 1.0114406 (785)\ttotal: 15m 26s\tremaining: 4m 9s\n",
      "788:\tlearn: 1.0312425\ttest: 1.0114965\tbest: 1.0114406 (785)\ttotal: 15m 27s\tremaining: 4m 8s\n",
      "789:\tlearn: 1.0312402\ttest: 1.0114757\tbest: 1.0114406 (785)\ttotal: 15m 28s\tremaining: 4m 6s\n",
      "790:\tlearn: 1.0312225\ttest: 1.0114029\tbest: 1.0114029 (790)\ttotal: 15m 29s\tremaining: 4m 5s\n",
      "791:\tlearn: 1.0305658\ttest: 1.0113978\tbest: 1.0113978 (791)\ttotal: 15m 30s\tremaining: 4m 4s\n",
      "792:\tlearn: 1.0304645\ttest: 1.0114135\tbest: 1.0113978 (791)\ttotal: 15m 32s\tremaining: 4m 3s\n",
      "793:\tlearn: 1.0304630\ttest: 1.0114050\tbest: 1.0113978 (791)\ttotal: 15m 33s\tremaining: 4m 2s\n",
      "794:\tlearn: 1.0304355\ttest: 1.0114029\tbest: 1.0113978 (791)\ttotal: 15m 34s\tremaining: 4m\n",
      "795:\tlearn: 1.0302113\ttest: 1.0114543\tbest: 1.0113978 (791)\ttotal: 15m 35s\tremaining: 3m 59s\n",
      "796:\tlearn: 1.0302090\ttest: 1.0114435\tbest: 1.0113978 (791)\ttotal: 15m 36s\tremaining: 3m 58s\n",
      "797:\tlearn: 1.0302081\ttest: 1.0114423\tbest: 1.0113978 (791)\ttotal: 15m 37s\tremaining: 3m 57s\n",
      "798:\tlearn: 1.0302055\ttest: 1.0114459\tbest: 1.0113978 (791)\ttotal: 15m 38s\tremaining: 3m 56s\n",
      "799:\tlearn: 1.0301219\ttest: 1.0115246\tbest: 1.0113978 (791)\ttotal: 15m 39s\tremaining: 3m 54s\n",
      "800:\tlearn: 1.0301180\ttest: 1.0115080\tbest: 1.0113978 (791)\ttotal: 15m 41s\tremaining: 3m 53s\n",
      "801:\tlearn: 1.0300406\ttest: 1.0114618\tbest: 1.0113978 (791)\ttotal: 15m 42s\tremaining: 3m 52s\n",
      "802:\tlearn: 1.0300148\ttest: 1.0114561\tbest: 1.0113978 (791)\ttotal: 15m 43s\tremaining: 3m 51s\n",
      "803:\tlearn: 1.0300081\ttest: 1.0114553\tbest: 1.0113978 (791)\ttotal: 15m 44s\tremaining: 3m 50s\n",
      "804:\tlearn: 1.0300030\ttest: 1.0114723\tbest: 1.0113978 (791)\ttotal: 15m 46s\tremaining: 3m 49s\n",
      "805:\tlearn: 1.0300002\ttest: 1.0114692\tbest: 1.0113978 (791)\ttotal: 15m 46s\tremaining: 3m 47s\n",
      "806:\tlearn: 1.0299385\ttest: 1.0113777\tbest: 1.0113777 (806)\ttotal: 15m 48s\tremaining: 3m 46s\n",
      "807:\tlearn: 1.0299374\ttest: 1.0113773\tbest: 1.0113773 (807)\ttotal: 15m 48s\tremaining: 3m 45s\n",
      "808:\tlearn: 1.0299328\ttest: 1.0113877\tbest: 1.0113773 (807)\ttotal: 15m 49s\tremaining: 3m 44s\n",
      "809:\tlearn: 1.0299320\ttest: 1.0113882\tbest: 1.0113773 (807)\ttotal: 15m 50s\tremaining: 3m 43s\n",
      "810:\tlearn: 1.0292819\ttest: 1.0113821\tbest: 1.0113773 (807)\ttotal: 15m 52s\tremaining: 3m 41s\n",
      "811:\tlearn: 1.0292692\ttest: 1.0113374\tbest: 1.0113374 (811)\ttotal: 15m 53s\tremaining: 3m 40s\n",
      "812:\tlearn: 1.0292663\ttest: 1.0113305\tbest: 1.0113305 (812)\ttotal: 15m 55s\tremaining: 3m 39s\n",
      "813:\tlearn: 1.0292604\ttest: 1.0112793\tbest: 1.0112793 (813)\ttotal: 15m 56s\tremaining: 3m 38s\n",
      "814:\tlearn: 1.0291822\ttest: 1.0113252\tbest: 1.0112793 (813)\ttotal: 15m 57s\tremaining: 3m 37s\n",
      "815:\tlearn: 1.0291817\ttest: 1.0113155\tbest: 1.0112793 (813)\ttotal: 15m 58s\tremaining: 3m 36s\n",
      "816:\tlearn: 1.0291652\ttest: 1.0112972\tbest: 1.0112793 (813)\ttotal: 15m 59s\tremaining: 3m 35s\n",
      "817:\tlearn: 1.0291620\ttest: 1.0112977\tbest: 1.0112793 (813)\ttotal: 16m\tremaining: 3m 33s\n",
      "818:\tlearn: 1.0287791\ttest: 1.0110774\tbest: 1.0110774 (818)\ttotal: 16m 2s\tremaining: 3m 32s\n",
      "819:\tlearn: 1.0287781\ttest: 1.0110759\tbest: 1.0110759 (819)\ttotal: 16m 3s\tremaining: 3m 31s\n",
      "820:\tlearn: 1.0287329\ttest: 1.0110228\tbest: 1.0110228 (820)\ttotal: 16m 3s\tremaining: 3m 30s\n",
      "821:\tlearn: 1.0287315\ttest: 1.0109939\tbest: 1.0109939 (821)\ttotal: 16m 4s\tremaining: 3m 28s\n",
      "822:\tlearn: 1.0287304\ttest: 1.0109912\tbest: 1.0109912 (822)\ttotal: 16m 6s\tremaining: 3m 27s\n",
      "823:\tlearn: 1.0287059\ttest: 1.0109953\tbest: 1.0109912 (822)\ttotal: 16m 7s\tremaining: 3m 26s\n",
      "824:\tlearn: 1.0287058\ttest: 1.0109913\tbest: 1.0109912 (822)\ttotal: 16m 9s\tremaining: 3m 25s\n",
      "825:\tlearn: 1.0286458\ttest: 1.0108859\tbest: 1.0108859 (825)\ttotal: 16m 10s\tremaining: 3m 24s\n",
      "826:\tlearn: 1.0286450\ttest: 1.0108824\tbest: 1.0108824 (826)\ttotal: 16m 11s\tremaining: 3m 23s\n",
      "827:\tlearn: 1.0286444\ttest: 1.0108791\tbest: 1.0108791 (827)\ttotal: 16m 12s\tremaining: 3m 21s\n",
      "828:\tlearn: 1.0286080\ttest: 1.0109513\tbest: 1.0108791 (827)\ttotal: 16m 13s\tremaining: 3m 20s\n",
      "829:\tlearn: 1.0285562\ttest: 1.0108842\tbest: 1.0108791 (827)\ttotal: 16m 14s\tremaining: 3m 19s\n",
      "830:\tlearn: 1.0285372\ttest: 1.0108609\tbest: 1.0108609 (830)\ttotal: 16m 16s\tremaining: 3m 18s\n",
      "831:\tlearn: 1.0285089\ttest: 1.0109447\tbest: 1.0108609 (830)\ttotal: 16m 17s\tremaining: 3m 17s\n",
      "832:\tlearn: 1.0285029\ttest: 1.0109511\tbest: 1.0108609 (830)\ttotal: 16m 18s\tremaining: 3m 16s\n",
      "833:\tlearn: 1.0282047\ttest: 1.0107553\tbest: 1.0107553 (833)\ttotal: 16m 19s\tremaining: 3m 15s\n",
      "834:\tlearn: 1.0282036\ttest: 1.0107548\tbest: 1.0107548 (834)\ttotal: 16m 21s\tremaining: 3m 13s\n",
      "835:\tlearn: 1.0281912\ttest: 1.0107562\tbest: 1.0107548 (834)\ttotal: 16m 22s\tremaining: 3m 12s\n",
      "836:\tlearn: 1.0281903\ttest: 1.0107521\tbest: 1.0107521 (836)\ttotal: 16m 23s\tremaining: 3m 11s\n",
      "837:\tlearn: 1.0281648\ttest: 1.0107318\tbest: 1.0107318 (837)\ttotal: 16m 25s\tremaining: 3m 10s\n",
      "838:\tlearn: 1.0281646\ttest: 1.0107338\tbest: 1.0107318 (837)\ttotal: 16m 26s\tremaining: 3m 9s\n",
      "839:\tlearn: 1.0281643\ttest: 1.0107340\tbest: 1.0107318 (837)\ttotal: 16m 27s\tremaining: 3m 8s\n",
      "840:\tlearn: 1.0281640\ttest: 1.0107304\tbest: 1.0107304 (840)\ttotal: 16m 28s\tremaining: 3m 6s\n",
      "841:\tlearn: 1.0280041\ttest: 1.0105261\tbest: 1.0105261 (841)\ttotal: 16m 29s\tremaining: 3m 5s\n",
      "842:\tlearn: 1.0279876\ttest: 1.0105259\tbest: 1.0105259 (842)\ttotal: 16m 30s\tremaining: 3m 4s\n",
      "843:\tlearn: 1.0279229\ttest: 1.0104849\tbest: 1.0104849 (843)\ttotal: 16m 31s\tremaining: 3m 3s\n",
      "844:\tlearn: 1.0278476\ttest: 1.0104877\tbest: 1.0104849 (843)\ttotal: 16m 32s\tremaining: 3m 2s\n",
      "845:\tlearn: 1.0278459\ttest: 1.0104850\tbest: 1.0104849 (843)\ttotal: 16m 34s\tremaining: 3m\n",
      "846:\tlearn: 1.0278429\ttest: 1.0104844\tbest: 1.0104844 (846)\ttotal: 16m 35s\tremaining: 2m 59s\n",
      "847:\tlearn: 1.0277442\ttest: 1.0104275\tbest: 1.0104275 (847)\ttotal: 16m 36s\tremaining: 2m 58s\n",
      "848:\tlearn: 1.0277412\ttest: 1.0104205\tbest: 1.0104205 (848)\ttotal: 16m 37s\tremaining: 2m 57s\n",
      "849:\tlearn: 1.0276635\ttest: 1.0105089\tbest: 1.0104205 (848)\ttotal: 16m 38s\tremaining: 2m 56s\n",
      "850:\tlearn: 1.0274524\ttest: 1.0105544\tbest: 1.0104205 (848)\ttotal: 16m 39s\tremaining: 2m 55s\n",
      "851:\tlearn: 1.0274466\ttest: 1.0105378\tbest: 1.0104205 (848)\ttotal: 16m 40s\tremaining: 2m 53s\n",
      "852:\tlearn: 1.0274336\ttest: 1.0105103\tbest: 1.0104205 (848)\ttotal: 16m 41s\tremaining: 2m 52s\n",
      "853:\tlearn: 1.0274279\ttest: 1.0105140\tbest: 1.0104205 (848)\ttotal: 16m 43s\tremaining: 2m 51s\n",
      "854:\tlearn: 1.0274277\ttest: 1.0105108\tbest: 1.0104205 (848)\ttotal: 16m 44s\tremaining: 2m 50s\n",
      "855:\tlearn: 1.0274261\ttest: 1.0105079\tbest: 1.0104205 (848)\ttotal: 16m 45s\tremaining: 2m 49s\n",
      "856:\tlearn: 1.0274237\ttest: 1.0105096\tbest: 1.0104205 (848)\ttotal: 16m 46s\tremaining: 2m 47s\n",
      "857:\tlearn: 1.0274238\ttest: 1.0105078\tbest: 1.0104205 (848)\ttotal: 16m 47s\tremaining: 2m 46s\n",
      "858:\tlearn: 1.0273963\ttest: 1.0105059\tbest: 1.0104205 (848)\ttotal: 16m 48s\tremaining: 2m 45s\n",
      "859:\tlearn: 1.0273479\ttest: 1.0105178\tbest: 1.0104205 (848)\ttotal: 16m 49s\tremaining: 2m 44s\n",
      "860:\tlearn: 1.0273073\ttest: 1.0106845\tbest: 1.0104205 (848)\ttotal: 16m 51s\tremaining: 2m 43s\n",
      "861:\tlearn: 1.0271496\ttest: 1.0106765\tbest: 1.0104205 (848)\ttotal: 16m 52s\tremaining: 2m 42s\n",
      "862:\tlearn: 1.0271283\ttest: 1.0107041\tbest: 1.0104205 (848)\ttotal: 16m 53s\tremaining: 2m 40s\n",
      "863:\tlearn: 1.0271233\ttest: 1.0107366\tbest: 1.0104205 (848)\ttotal: 16m 55s\tremaining: 2m 39s\n",
      "864:\tlearn: 1.0271116\ttest: 1.0107230\tbest: 1.0104205 (848)\ttotal: 16m 56s\tremaining: 2m 38s\n",
      "865:\tlearn: 1.0271107\ttest: 1.0107196\tbest: 1.0104205 (848)\ttotal: 16m 57s\tremaining: 2m 37s\n",
      "866:\tlearn: 1.0271002\ttest: 1.0107295\tbest: 1.0104205 (848)\ttotal: 16m 58s\tremaining: 2m 36s\n",
      "867:\tlearn: 1.0270928\ttest: 1.0107958\tbest: 1.0104205 (848)\ttotal: 16m 59s\tremaining: 2m 35s\n",
      "868:\tlearn: 1.0270875\ttest: 1.0107750\tbest: 1.0104205 (848)\ttotal: 17m\tremaining: 2m 33s\n",
      "869:\tlearn: 1.0270548\ttest: 1.0107632\tbest: 1.0104205 (848)\ttotal: 17m 1s\tremaining: 2m 32s\n",
      "870:\tlearn: 1.0270553\ttest: 1.0107599\tbest: 1.0104205 (848)\ttotal: 17m 2s\tremaining: 2m 31s\n",
      "871:\tlearn: 1.0270427\ttest: 1.0107307\tbest: 1.0104205 (848)\ttotal: 17m 3s\tremaining: 2m 30s\n",
      "872:\tlearn: 1.0270424\ttest: 1.0107306\tbest: 1.0104205 (848)\ttotal: 17m 4s\tremaining: 2m 29s\n",
      "873:\tlearn: 1.0270142\ttest: 1.0106295\tbest: 1.0104205 (848)\ttotal: 17m 6s\tremaining: 2m 27s\n",
      "874:\tlearn: 1.0270085\ttest: 1.0106209\tbest: 1.0104205 (848)\ttotal: 17m 7s\tremaining: 2m 26s\n",
      "875:\tlearn: 1.0269957\ttest: 1.0106347\tbest: 1.0104205 (848)\ttotal: 17m 8s\tremaining: 2m 25s\n",
      "876:\tlearn: 1.0269922\ttest: 1.0106678\tbest: 1.0104205 (848)\ttotal: 17m 9s\tremaining: 2m 24s\n",
      "877:\tlearn: 1.0269851\ttest: 1.0106237\tbest: 1.0104205 (848)\ttotal: 17m 10s\tremaining: 2m 23s\n",
      "878:\tlearn: 1.0268563\ttest: 1.0104055\tbest: 1.0104055 (878)\ttotal: 17m 12s\tremaining: 2m 22s\n",
      "879:\tlearn: 1.0268477\ttest: 1.0104482\tbest: 1.0104055 (878)\ttotal: 17m 13s\tremaining: 2m 20s\n",
      "880:\tlearn: 1.0268252\ttest: 1.0104623\tbest: 1.0104055 (878)\ttotal: 17m 14s\tremaining: 2m 19s\n",
      "881:\tlearn: 1.0267761\ttest: 1.0103724\tbest: 1.0103724 (881)\ttotal: 17m 15s\tremaining: 2m 18s\n",
      "882:\tlearn: 1.0267688\ttest: 1.0103371\tbest: 1.0103371 (882)\ttotal: 17m 17s\tremaining: 2m 17s\n",
      "883:\tlearn: 1.0267370\ttest: 1.0102833\tbest: 1.0102833 (883)\ttotal: 17m 18s\tremaining: 2m 16s\n",
      "884:\tlearn: 1.0266766\ttest: 1.0098416\tbest: 1.0098416 (884)\ttotal: 17m 18s\tremaining: 2m 15s\n",
      "885:\tlearn: 1.0266116\ttest: 1.0097894\tbest: 1.0097894 (885)\ttotal: 17m 20s\tremaining: 2m 13s\n",
      "886:\tlearn: 1.0266098\ttest: 1.0097826\tbest: 1.0097826 (886)\ttotal: 17m 21s\tremaining: 2m 12s\n",
      "887:\tlearn: 1.0265229\ttest: 1.0095899\tbest: 1.0095899 (887)\ttotal: 17m 22s\tremaining: 2m 11s\n",
      "888:\tlearn: 1.0264684\ttest: 1.0095922\tbest: 1.0095899 (887)\ttotal: 17m 23s\tremaining: 2m 10s\n",
      "889:\tlearn: 1.0264405\ttest: 1.0096290\tbest: 1.0095899 (887)\ttotal: 17m 24s\tremaining: 2m 9s\n",
      "890:\tlearn: 1.0263742\ttest: 1.0095048\tbest: 1.0095048 (890)\ttotal: 17m 25s\tremaining: 2m 7s\n",
      "891:\tlearn: 1.0263375\ttest: 1.0096110\tbest: 1.0095048 (890)\ttotal: 17m 27s\tremaining: 2m 6s\n",
      "892:\tlearn: 1.0263156\ttest: 1.0095682\tbest: 1.0095048 (890)\ttotal: 17m 28s\tremaining: 2m 5s\n",
      "893:\tlearn: 1.0263040\ttest: 1.0095694\tbest: 1.0095048 (890)\ttotal: 17m 30s\tremaining: 2m 4s\n",
      "894:\tlearn: 1.0262780\ttest: 1.0096413\tbest: 1.0095048 (890)\ttotal: 17m 31s\tremaining: 2m 3s\n",
      "895:\tlearn: 1.0262149\ttest: 1.0096052\tbest: 1.0095048 (890)\ttotal: 17m 33s\tremaining: 2m 2s\n",
      "896:\tlearn: 1.0261978\ttest: 1.0096730\tbest: 1.0095048 (890)\ttotal: 17m 34s\tremaining: 2m 1s\n",
      "897:\tlearn: 1.0258404\ttest: 1.0094766\tbest: 1.0094766 (897)\ttotal: 17m 36s\tremaining: 1m 59s\n",
      "898:\tlearn: 1.0258371\ttest: 1.0094740\tbest: 1.0094740 (898)\ttotal: 17m 37s\tremaining: 1m 58s\n",
      "899:\tlearn: 1.0258365\ttest: 1.0094810\tbest: 1.0094740 (898)\ttotal: 17m 38s\tremaining: 1m 57s\n",
      "900:\tlearn: 1.0258357\ttest: 1.0094922\tbest: 1.0094740 (898)\ttotal: 17m 39s\tremaining: 1m 56s\n",
      "901:\tlearn: 1.0258217\ttest: 1.0095109\tbest: 1.0094740 (898)\ttotal: 17m 40s\tremaining: 1m 55s\n",
      "902:\tlearn: 1.0257958\ttest: 1.0094915\tbest: 1.0094740 (898)\ttotal: 17m 42s\tremaining: 1m 54s\n",
      "903:\tlearn: 1.0257641\ttest: 1.0094573\tbest: 1.0094573 (903)\ttotal: 17m 43s\tremaining: 1m 52s\n",
      "904:\tlearn: 1.0257615\ttest: 1.0094469\tbest: 1.0094469 (904)\ttotal: 17m 44s\tremaining: 1m 51s\n",
      "905:\tlearn: 1.0256690\ttest: 1.0094478\tbest: 1.0094469 (904)\ttotal: 17m 46s\tremaining: 1m 50s\n",
      "906:\tlearn: 1.0256679\ttest: 1.0094502\tbest: 1.0094469 (904)\ttotal: 17m 47s\tremaining: 1m 49s\n",
      "907:\tlearn: 1.0256590\ttest: 1.0094698\tbest: 1.0094469 (904)\ttotal: 17m 48s\tremaining: 1m 48s\n",
      "908:\tlearn: 1.0256419\ttest: 1.0094730\tbest: 1.0094469 (904)\ttotal: 17m 49s\tremaining: 1m 47s\n",
      "909:\tlearn: 1.0256256\ttest: 1.0094557\tbest: 1.0094469 (904)\ttotal: 17m 50s\tremaining: 1m 45s\n",
      "910:\tlearn: 1.0254642\ttest: 1.0092069\tbest: 1.0092069 (910)\ttotal: 17m 52s\tremaining: 1m 44s\n",
      "911:\tlearn: 1.0254273\ttest: 1.0092103\tbest: 1.0092069 (910)\ttotal: 17m 53s\tremaining: 1m 43s\n",
      "912:\tlearn: 1.0254264\ttest: 1.0092128\tbest: 1.0092069 (910)\ttotal: 17m 54s\tremaining: 1m 42s\n",
      "913:\tlearn: 1.0250872\ttest: 1.0090828\tbest: 1.0090828 (913)\ttotal: 17m 56s\tremaining: 1m 41s\n",
      "914:\tlearn: 1.0250833\ttest: 1.0090777\tbest: 1.0090777 (914)\ttotal: 17m 56s\tremaining: 1m 40s\n",
      "915:\tlearn: 1.0250620\ttest: 1.0091118\tbest: 1.0090777 (914)\ttotal: 17m 58s\tremaining: 1m 38s\n",
      "916:\tlearn: 1.0250398\ttest: 1.0091371\tbest: 1.0090777 (914)\ttotal: 17m 59s\tremaining: 1m 37s\n",
      "917:\tlearn: 1.0250394\ttest: 1.0091315\tbest: 1.0090777 (914)\ttotal: 17m 59s\tremaining: 1m 36s\n",
      "918:\tlearn: 1.0250160\ttest: 1.0091504\tbest: 1.0090777 (914)\ttotal: 18m 1s\tremaining: 1m 35s\n",
      "919:\tlearn: 1.0250106\ttest: 1.0091722\tbest: 1.0090777 (914)\ttotal: 18m 2s\tremaining: 1m 34s\n",
      "920:\tlearn: 1.0250091\ttest: 1.0091688\tbest: 1.0090777 (914)\ttotal: 18m 3s\tremaining: 1m 32s\n",
      "921:\tlearn: 1.0250098\ttest: 1.0091695\tbest: 1.0090777 (914)\ttotal: 18m 4s\tremaining: 1m 31s\n",
      "922:\tlearn: 1.0249909\ttest: 1.0091248\tbest: 1.0090777 (914)\ttotal: 18m 6s\tremaining: 1m 30s\n",
      "923:\tlearn: 1.0249709\ttest: 1.0091286\tbest: 1.0090777 (914)\ttotal: 18m 7s\tremaining: 1m 29s\n",
      "924:\tlearn: 1.0249500\ttest: 1.0091116\tbest: 1.0090777 (914)\ttotal: 18m 9s\tremaining: 1m 28s\n",
      "925:\tlearn: 1.0249457\ttest: 1.0090766\tbest: 1.0090766 (925)\ttotal: 18m 10s\tremaining: 1m 27s\n",
      "926:\tlearn: 1.0249431\ttest: 1.0090666\tbest: 1.0090666 (926)\ttotal: 18m 11s\tremaining: 1m 25s\n",
      "927:\tlearn: 1.0249036\ttest: 1.0089082\tbest: 1.0089082 (927)\ttotal: 18m 12s\tremaining: 1m 24s\n",
      "928:\tlearn: 1.0248993\ttest: 1.0088989\tbest: 1.0088989 (928)\ttotal: 18m 13s\tremaining: 1m 23s\n",
      "929:\tlearn: 1.0248873\ttest: 1.0089000\tbest: 1.0088989 (928)\ttotal: 18m 15s\tremaining: 1m 22s\n",
      "930:\tlearn: 1.0248870\ttest: 1.0088987\tbest: 1.0088987 (930)\ttotal: 18m 16s\tremaining: 1m 21s\n",
      "931:\tlearn: 1.0248674\ttest: 1.0089470\tbest: 1.0088987 (930)\ttotal: 18m 18s\tremaining: 1m 20s\n",
      "932:\tlearn: 1.0248258\ttest: 1.0090588\tbest: 1.0088987 (930)\ttotal: 18m 19s\tremaining: 1m 18s\n",
      "933:\tlearn: 1.0247255\ttest: 1.0090388\tbest: 1.0088987 (930)\ttotal: 18m 20s\tremaining: 1m 17s\n",
      "934:\tlearn: 1.0247196\ttest: 1.0090270\tbest: 1.0088987 (930)\ttotal: 18m 22s\tremaining: 1m 16s\n",
      "935:\tlearn: 1.0247194\ttest: 1.0090238\tbest: 1.0088987 (930)\ttotal: 18m 22s\tremaining: 1m 15s\n",
      "936:\tlearn: 1.0246977\ttest: 1.0090288\tbest: 1.0088987 (930)\ttotal: 18m 24s\tremaining: 1m 14s\n",
      "937:\tlearn: 1.0246959\ttest: 1.0090273\tbest: 1.0088987 (930)\ttotal: 18m 25s\tremaining: 1m 13s\n",
      "938:\tlearn: 1.0245970\ttest: 1.0090863\tbest: 1.0088987 (930)\ttotal: 18m 26s\tremaining: 1m 11s\n",
      "939:\tlearn: 1.0245149\ttest: 1.0090255\tbest: 1.0088987 (930)\ttotal: 18m 28s\tremaining: 1m 10s\n",
      "940:\tlearn: 1.0244945\ttest: 1.0089954\tbest: 1.0088987 (930)\ttotal: 18m 29s\tremaining: 1m 9s\n",
      "941:\tlearn: 1.0241664\ttest: 1.0090209\tbest: 1.0088987 (930)\ttotal: 18m 30s\tremaining: 1m 8s\n",
      "942:\tlearn: 1.0241661\ttest: 1.0090163\tbest: 1.0088987 (930)\ttotal: 18m 31s\tremaining: 1m 7s\n",
      "943:\tlearn: 1.0241633\ttest: 1.0090124\tbest: 1.0088987 (930)\ttotal: 18m 33s\tremaining: 1m 6s\n",
      "944:\tlearn: 1.0241628\ttest: 1.0090125\tbest: 1.0088987 (930)\ttotal: 18m 34s\tremaining: 1m 4s\n",
      "945:\tlearn: 1.0241315\ttest: 1.0088994\tbest: 1.0088987 (930)\ttotal: 18m 35s\tremaining: 1m 3s\n",
      "946:\tlearn: 1.0241295\ttest: 1.0088916\tbest: 1.0088916 (946)\ttotal: 18m 36s\tremaining: 1m 2s\n",
      "947:\tlearn: 1.0241302\ttest: 1.0088887\tbest: 1.0088887 (947)\ttotal: 18m 37s\tremaining: 1m 1s\n",
      "948:\tlearn: 1.0241244\ttest: 1.0089290\tbest: 1.0088887 (947)\ttotal: 18m 38s\tremaining: 1m\n",
      "949:\tlearn: 1.0241132\ttest: 1.0088820\tbest: 1.0088820 (949)\ttotal: 18m 39s\tremaining: 58.9s\n",
      "950:\tlearn: 1.0240908\ttest: 1.0087426\tbest: 1.0087426 (950)\ttotal: 18m 40s\tremaining: 57.7s\n",
      "951:\tlearn: 1.0240607\ttest: 1.0087060\tbest: 1.0087060 (951)\ttotal: 18m 42s\tremaining: 56.6s\n",
      "952:\tlearn: 1.0240424\ttest: 1.0087337\tbest: 1.0087060 (951)\ttotal: 18m 43s\tremaining: 55.4s\n",
      "953:\tlearn: 1.0239916\ttest: 1.0089397\tbest: 1.0087060 (951)\ttotal: 18m 44s\tremaining: 54.2s\n",
      "954:\tlearn: 1.0239108\ttest: 1.0089228\tbest: 1.0087060 (951)\ttotal: 18m 45s\tremaining: 53.1s\n",
      "955:\tlearn: 1.0238395\ttest: 1.0088416\tbest: 1.0087060 (951)\ttotal: 18m 47s\tremaining: 51.9s\n",
      "956:\tlearn: 1.0238390\ttest: 1.0088437\tbest: 1.0087060 (951)\ttotal: 18m 48s\tremaining: 50.7s\n",
      "957:\tlearn: 1.0238245\ttest: 1.0088521\tbest: 1.0087060 (951)\ttotal: 18m 49s\tremaining: 49.5s\n",
      "958:\tlearn: 1.0238235\ttest: 1.0088477\tbest: 1.0087060 (951)\ttotal: 18m 50s\tremaining: 48.3s\n",
      "959:\tlearn: 1.0238112\ttest: 1.0088090\tbest: 1.0087060 (951)\ttotal: 18m 51s\tremaining: 47.1s\n",
      "960:\tlearn: 1.0238108\ttest: 1.0088089\tbest: 1.0087060 (951)\ttotal: 18m 52s\tremaining: 46s\n",
      "961:\tlearn: 1.0237091\ttest: 1.0087368\tbest: 1.0087060 (951)\ttotal: 18m 53s\tremaining: 44.8s\n",
      "962:\tlearn: 1.0237046\ttest: 1.0087358\tbest: 1.0087060 (951)\ttotal: 18m 54s\tremaining: 43.6s\n",
      "963:\tlearn: 1.0234983\ttest: 1.0085704\tbest: 1.0085704 (963)\ttotal: 18m 56s\tremaining: 42.4s\n",
      "964:\tlearn: 1.0234691\ttest: 1.0085680\tbest: 1.0085680 (964)\ttotal: 18m 57s\tremaining: 41.3s\n",
      "965:\tlearn: 1.0232744\ttest: 1.0085786\tbest: 1.0085680 (964)\ttotal: 18m 58s\tremaining: 40.1s\n",
      "966:\tlearn: 1.0232069\ttest: 1.0085052\tbest: 1.0085052 (966)\ttotal: 18m 59s\tremaining: 38.9s\n",
      "967:\tlearn: 1.0231136\ttest: 1.0083519\tbest: 1.0083519 (967)\ttotal: 19m\tremaining: 37.7s\n",
      "968:\tlearn: 1.0229989\ttest: 1.0082537\tbest: 1.0082537 (968)\ttotal: 19m 1s\tremaining: 36.5s\n",
      "969:\tlearn: 1.0228882\ttest: 1.0081838\tbest: 1.0081838 (969)\ttotal: 19m 2s\tremaining: 35.3s\n",
      "970:\tlearn: 1.0228694\ttest: 1.0081482\tbest: 1.0081482 (970)\ttotal: 19m 4s\tremaining: 34.2s\n",
      "971:\tlearn: 1.0228493\ttest: 1.0080697\tbest: 1.0080697 (971)\ttotal: 19m 5s\tremaining: 33s\n",
      "972:\tlearn: 1.0228401\ttest: 1.0080563\tbest: 1.0080563 (972)\ttotal: 19m 6s\tremaining: 31.8s\n",
      "973:\tlearn: 1.0227910\ttest: 1.0079982\tbest: 1.0079982 (973)\ttotal: 19m 8s\tremaining: 30.6s\n",
      "974:\tlearn: 1.0227600\ttest: 1.0079861\tbest: 1.0079861 (974)\ttotal: 19m 9s\tremaining: 29.5s\n",
      "975:\tlearn: 1.0227206\ttest: 1.0079735\tbest: 1.0079735 (975)\ttotal: 19m 11s\tremaining: 28.3s\n",
      "976:\tlearn: 1.0226800\ttest: 1.0079831\tbest: 1.0079735 (975)\ttotal: 19m 12s\tremaining: 27.1s\n",
      "977:\tlearn: 1.0225854\ttest: 1.0077864\tbest: 1.0077864 (977)\ttotal: 19m 13s\tremaining: 26s\n",
      "978:\tlearn: 1.0225630\ttest: 1.0078335\tbest: 1.0077864 (977)\ttotal: 19m 15s\tremaining: 24.8s\n",
      "979:\tlearn: 1.0225523\ttest: 1.0078198\tbest: 1.0077864 (977)\ttotal: 19m 16s\tremaining: 23.6s\n",
      "980:\tlearn: 1.0225264\ttest: 1.0077703\tbest: 1.0077703 (980)\ttotal: 19m 18s\tremaining: 22.4s\n",
      "981:\tlearn: 1.0223675\ttest: 1.0075229\tbest: 1.0075229 (981)\ttotal: 19m 19s\tremaining: 21.2s\n",
      "982:\tlearn: 1.0222478\ttest: 1.0072887\tbest: 1.0072887 (982)\ttotal: 19m 20s\tremaining: 20.1s\n",
      "983:\tlearn: 1.0220652\ttest: 1.0071512\tbest: 1.0071512 (983)\ttotal: 19m 21s\tremaining: 18.9s\n",
      "984:\tlearn: 1.0219974\ttest: 1.0070175\tbest: 1.0070175 (984)\ttotal: 19m 23s\tremaining: 17.7s\n",
      "985:\tlearn: 1.0218871\ttest: 1.0068833\tbest: 1.0068833 (985)\ttotal: 19m 24s\tremaining: 16.5s\n",
      "986:\tlearn: 1.0217783\ttest: 1.0067902\tbest: 1.0067902 (986)\ttotal: 19m 25s\tremaining: 15.4s\n",
      "987:\tlearn: 1.0217775\ttest: 1.0067901\tbest: 1.0067901 (987)\ttotal: 19m 26s\tremaining: 14.2s\n",
      "988:\tlearn: 1.0216422\ttest: 1.0066053\tbest: 1.0066053 (988)\ttotal: 19m 27s\tremaining: 13s\n",
      "989:\tlearn: 1.0216275\ttest: 1.0066437\tbest: 1.0066053 (988)\ttotal: 19m 29s\tremaining: 11.8s\n",
      "990:\tlearn: 1.0215806\ttest: 1.0065842\tbest: 1.0065842 (990)\ttotal: 19m 29s\tremaining: 10.6s\n",
      "991:\tlearn: 1.0215251\ttest: 1.0065515\tbest: 1.0065515 (991)\ttotal: 19m 30s\tremaining: 9.44s\n",
      "992:\tlearn: 1.0214847\ttest: 1.0065616\tbest: 1.0065515 (991)\ttotal: 19m 32s\tremaining: 8.26s\n",
      "993:\tlearn: 1.0213893\ttest: 1.0065381\tbest: 1.0065381 (993)\ttotal: 19m 33s\tremaining: 7.08s\n",
      "994:\tlearn: 1.0213882\ttest: 1.0065403\tbest: 1.0065381 (993)\ttotal: 19m 34s\tremaining: 5.9s\n",
      "995:\tlearn: 1.0213867\ttest: 1.0065339\tbest: 1.0065339 (995)\ttotal: 19m 34s\tremaining: 4.72s\n",
      "996:\tlearn: 1.0213716\ttest: 1.0065183\tbest: 1.0065183 (996)\ttotal: 19m 36s\tremaining: 3.54s\n",
      "997:\tlearn: 1.0212293\ttest: 1.0066748\tbest: 1.0065183 (996)\ttotal: 19m 37s\tremaining: 2.36s\n",
      "998:\tlearn: 1.0212179\ttest: 1.0067945\tbest: 1.0065183 (996)\ttotal: 19m 38s\tremaining: 1.18s\n",
      "999:\tlearn: 1.0211886\ttest: 1.0068115\tbest: 1.0065183 (996)\ttotal: 19m 39s\tremaining: 0us\n",
      "bestTest = 1.006518278\n",
      "bestIteration = 996\n",
      "Shrink model to first 997 iterations.\n",
      "1.0065183452964175\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "basic = [\n",
    "    \"shop_id\",\n",
    "    \"new_item\",\n",
    "    \"new_shop\",\n",
    "    \"item_category_id\",\n",
    "    \"digital\",\n",
    "    \"supercategory_id\",\n",
    "    \"platform_id\",\n",
    "    \"city_code\",\n",
    "    \"month\",\n",
    "    \"year\",\n",
    "]\n",
    "\n",
    "# initialize data\n",
    "# initialize Pool\n",
    "train_pool = Pool(X_train, y_train, cat_features=basic)\n",
    "test_pool = Pool(X_valid, cat_features=basic)\n",
    "\n",
    "# specify the training parameters\n",
    "model = CatBoostRegressor(\n",
    "    #     iterations=200,\n",
    "    #     learning_rate=1,\n",
    "    early_stopping_rounds=30,\n",
    "    loss_function=\"RMSE\",\n",
    "    task_type=\"GPU\",\n",
    ")\n",
    "# train the model\n",
    "model.fit(\n",
    "    train_pool, eval_set=(X_valid, y_valid),\n",
    ")\n",
    "# make the prediction using the resulting model\n",
    "preds = model.predict(test_pool)\n",
    "rmse = mean_squared_error(y_valid, preds, squared=False)\n",
    "\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean predicted sales of digital items in non-digital shops is 0.0032863835924329724\n",
      "Mean predicted sales of non-digital items in digital shop 55 is 0.017218524949990644\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean predicted sales of digital items in non-digital shops is {(~X_test.shop_id.isin([12, 55])) & (X_test.digital==1)].item_cnt_month.mean()}\")\n",
    "print(f\"Mean predicted sales of non-digital items in digital shop 55 is {X_test[(X_test.shop_id==55) & (X_test.digital==0)].item_cnt_month.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7060136244246081\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "X_valid['item_cnt_month'] = booster.predict(X_valid.drop(columns=dropcols))\n",
    "rmse = mean_squared_error(y_valid, X_valid['item_cnt_month'].clip(0,20), squared=False)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid.loc[(~X_valid.shop_id.isin([12, 55])) & (X_valid.digital==1), 'item_cnt_month'] = 0\n",
    "X_valid.loc[(X_valid.shop_id==55) & (X_valid.digital!=1), 'item_cnt_month'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7059638564032783\n"
     ]
    }
   ],
   "source": [
    "rmse = mean_squared_error(y_valid, X_valid['item_cnt_month'].clip(0,20), squared=False)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: replace the predictions for shop 36 (if any) with the predictions for shop 37 from the same city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "shop37 = X_test.loc[X_test.shop_id==37,:]\n",
    "X_test = X_test.loc[X_test.shop_id!=36,:]\n",
    "shop37.loc[:,'shop_id'] = 36\n",
    "X_test = pd.concat([X_test,shop37])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
