{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "addressed-qualification",
   "metadata": {},
   "source": [
    "Basic ensembling by training multiple LightGBM boosters with different parameters and averaging the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "structural-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import futuresalesutility as fu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "realistic-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.read_pickle(\"checkpoint_final.pkl\")\n",
    "items = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/items.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-rogers",
   "metadata": {},
   "source": [
    "Dataset splitting and booster fitting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "embedded-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_x_y(matrix, test_month, keep_from_month=3):\n",
    "    def split_train_test(matrix, test_month=33):\n",
    "        # Split the matrix into train and test sets.\n",
    "        test_month = fu.list_if_not(test_month, int)\n",
    "        test = matrix.loc[matrix.date_block_num.isin(test_month), :]\n",
    "        train = matrix.loc[matrix.date_block_num < min(test_month), :]\n",
    "        return train, test\n",
    "\n",
    "    def xysplit(matrix):\n",
    "        # Split a train and test set into into x and y sets, with item_cnt as the target y variable\n",
    "        y = matrix.item_cnt_month\n",
    "        X = matrix.drop(columns=[\"item_cnt_month\"])\n",
    "        return (X, y)\n",
    "\n",
    "    matrix = matrix.drop(\n",
    "        columns=[\"item_revenue_month\", \"item_price\", \"item_cnt_month_original\", \"item_cnt_day_avg\",], errors=\"ignore\",\n",
    "    )\n",
    "\n",
    "    train, test = split_train_test(matrix, test_month)\n",
    "    train = train[train.date_block_num >= keep_from_month]\n",
    "    X_train, y_train = xysplit(train)\n",
    "    X_test, y_test = xysplit(test)\n",
    "    return (X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "accurate-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"lightgbm\")\n",
    "\n",
    "import lightgbm as lgbm\n",
    "\n",
    "def fit_booster(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test=None,\n",
    "    y_test=None,\n",
    "    params=None,\n",
    "    categoricals=[],\n",
    "    dropcols=[],\n",
    "    early_stopping_rounds=None,\n",
    "):\n",
    "    # Regular booster fitting function\n",
    "    if params is None:\n",
    "        params = {\"learning_rate\": 0.1, \"subsample_for_bin\": 300000, \"n_estimators\": 5000}\n",
    "\n",
    "    if X_test is not None:\n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "    else:\n",
    "        eval_set = [(X_train, y_train)]\n",
    "\n",
    "    booster = lgbm.LGBMRegressor(**params)\n",
    "    categoricals = [c for c in categoricals if c in X_train.columns]\n",
    "    booster.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=eval_set,\n",
    "        eval_metric=[\"rmse\"],\n",
    "        verbose=50,\n",
    "        categorical_feature=categoricals,\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "    )\n",
    "\n",
    "    return booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "educated-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (matrix == float(\"inf\")).any().any():\n",
    "    raise ValueError(\"Dataframe contains inf entries! This can crash some models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-blowing",
   "metadata": {},
   "source": [
    "Define the parameters sets to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "laden-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = [\n",
    "    {\n",
    "        \"num_leaves\": 966,\n",
    "        \"cat_smooth\": 45.01680827234465,\n",
    "        \"min_child_samples\": 27,\n",
    "        \"min_child_weight\": 0.021144950289224463,\n",
    "        \"max_bin\": 214,\n",
    "        \"n_estimators\": 500,\n",
    "    },\n",
    "    {\n",
    "        \"num_leaves\": 940,\n",
    "        \"cat_smooth\": 43.418286701105615,\n",
    "        \"min_child_samples\": 29,\n",
    "        \"min_child_weight\": 0.003944267312494195,\n",
    "        \"max_bin\": 133,\n",
    "        \"n_estimators\": 572,\n",
    "    },\n",
    "    {\n",
    "        \"num_leaves\": 971,\n",
    "        \"cat_smooth\": 40.103611531065525,\n",
    "        \"min_child_samples\": 30,\n",
    "        \"min_child_weight\": 0.03951287458923346,\n",
    "        \"max_bin\": 212,\n",
    "        \"n_estimators\": 828,\n",
    "    },\n",
    "    {\n",
    "        \"num_leaves\": 965,\n",
    "        \"cat_smooth\": 40.05144976454027,\n",
    "        \"min_child_samples\": 27,\n",
    "        \"min_child_weight\": 0.029220951478909872,\n",
    "        \"max_bin\": 211,\n",
    "        \"n_estimators\": 870,\n",
    "    },\n",
    "    {\n",
    "        \"num_leaves\": 961,\n",
    "        \"cat_smooth\": 40.013529776221134,\n",
    "        \"min_child_samples\": 29,\n",
    "        \"min_child_weight\": 0.026526521644599493,\n",
    "        \"max_bin\": 210,\n",
    "        \"n_estimators\": 897,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-quality",
   "metadata": {},
   "source": [
    "Fit a booster with each of the parameters sets and store the boosters in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "portuguese-commander",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttraining's rmse: 0.968386\ttraining's l2: 0.937772\tvalid_1's rmse: 0.898216\tvalid_1's l2: 0.806792\n",
      "[100]\ttraining's rmse: 0.830554\ttraining's l2: 0.68982\tvalid_1's rmse: 0.816243\tvalid_1's l2: 0.666253\n",
      "[150]\ttraining's rmse: 0.758335\ttraining's l2: 0.575072\tvalid_1's rmse: 0.780877\tvalid_1's l2: 0.609769\n",
      "[200]\ttraining's rmse: 0.717255\ttraining's l2: 0.514455\tvalid_1's rmse: 0.765201\tvalid_1's l2: 0.585533\n",
      "[250]\ttraining's rmse: 0.690625\ttraining's l2: 0.476962\tvalid_1's rmse: 0.758236\tvalid_1's l2: 0.574922\n",
      "[300]\ttraining's rmse: 0.67156\ttraining's l2: 0.450993\tvalid_1's rmse: 0.75455\tvalid_1's l2: 0.569346\n",
      "[350]\ttraining's rmse: 0.656569\ttraining's l2: 0.431082\tvalid_1's rmse: 0.753019\tvalid_1's l2: 0.567038\n",
      "[400]\ttraining's rmse: 0.644466\ttraining's l2: 0.415337\tvalid_1's rmse: 0.751246\tvalid_1's l2: 0.564371\n",
      "[450]\ttraining's rmse: 0.634133\ttraining's l2: 0.402124\tvalid_1's rmse: 0.750622\tvalid_1's l2: 0.563433\n",
      "[500]\ttraining's rmse: 0.625014\ttraining's l2: 0.390642\tvalid_1's rmse: 0.7495\tvalid_1's l2: 0.56175\n",
      "[550]\ttraining's rmse: 0.617145\ttraining's l2: 0.380868\tvalid_1's rmse: 0.749215\tvalid_1's l2: 0.561323\n",
      "[600]\ttraining's rmse: 0.610191\ttraining's l2: 0.372334\tvalid_1's rmse: 0.748934\tvalid_1's l2: 0.560902\n",
      "[650]\ttraining's rmse: 0.603716\ttraining's l2: 0.364472\tvalid_1's rmse: 0.748671\tvalid_1's l2: 0.560508\n",
      "Early stopping, best iteration is:\n",
      "[645]\ttraining's rmse: 0.604332\ttraining's l2: 0.365218\tvalid_1's rmse: 0.748652\tvalid_1's l2: 0.56048\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_x_y(matrix, [33], keep_from_month=2)\n",
    "boosterstore = []\n",
    "for i, params in enumerate(best_params):\n",
    "    params.update(\n",
    "        {\"n_jobs\": 11,}\n",
    "    )\n",
    "    booster = fit_booster(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        params=params,\n",
    "        categoricals=[\"item_category_id\", \"month\"],\n",
    "        dropcols=[\"shop_id\", \"digital\"],\n",
    "        early_stopping_rounds=10,\n",
    "    )\n",
    "    boosterstore.append(booster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-underground",
   "metadata": {},
   "source": [
    "Generate predictions from each of the stored boosters and take the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "caring-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_prediction(boosterstore, X_test):\n",
    "    predframe = X_test.loc[:, [\"shop_id\", \"item_id\", \"digital\"]]\n",
    "    for i, booster in enumerate(boosterstore):\n",
    "        predframe[\"prediction\"] = booster.predict(\n",
    "            X_test.drop(columns=[\"prediction\", \"shop_id\", \"digital\"], errors=\"ignore\")\n",
    "        )\n",
    "        predframe[\"prediction\"] = predframe[\"prediction\"].clip(0, 20)\n",
    "        predframe.loc[(predframe.shop_id == 55) & (predframe.digital != 1), \"prediction\"] = 0\n",
    "        predframe.loc[(predframe.shop_id != 55) & (predframe.digital == 1), \"prediction\"] = 0\n",
    "        predframe[\"prediction\"] = predframe[\"prediction\"]\n",
    "        predframe = predframe.rename(columns={\"prediction\": i})\n",
    "    predframe[\"prediction\"] = predframe.drop(columns=[\"shop_id\", \"item_id\", \"digital\"]).mean(\n",
    "        axis=1\n",
    "    )\n",
    "    return predframe[\"prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_x_y(matrix.drop(columns=[\"shop_id\", \"digital\"]), 34, keep_from_month=2)\n",
    "X_test['prediction'] = mean_prediction(boosterstore, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-falls",
   "metadata": {},
   "source": [
    "Get the RMSE of the predictions (assuming validation is being done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "employed-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['item_cnt_month'] = y_test\n",
    "X_test[['item_cnt_month', 'prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "vocal-judges",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9026308520020633\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = mean_squared_error(y_test, X_test['prediction'], squared=False)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-practice",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-seller",
   "metadata": {},
   "source": [
    "Sales of digital items should be zero for shops other than 55, and vice-versa, force set these values to zero if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "happy-nevada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean predicted sales of digital items in non-digital shops is 0.0032863835924329724\n",
      "Mean predicted sales of non-digital items in digital shop 55 is 0.017218524949990644\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean predicted sales of digital items in non-digital shops is {(~X_test.shop_id.isin([12, 55])) & (X_test.digital==1)].item_cnt_month.mean()}\")\n",
    "print(f\"Mean predicted sales of non-digital items in digital shop 55 is {X_test[(X_test.shop_id==55) & (X_test.digital==0)].item_cnt_month.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "regulation-spank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7060136244246081\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "X_valid['item_cnt_month'] = booster.predict(X_valid.drop(columns=dropcols))\n",
    "rmse = mean_squared_error(y_valid, X_valid['item_cnt_month'].clip(0,20), squared=False)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "material-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid.loc[(~X_valid.shop_id.isin([12, 55])) & (X_valid.digital==1), 'item_cnt_month'] = 0\n",
    "X_valid.loc[(X_valid.shop_id==55) & (X_valid.digital!=1), 'item_cnt_month'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "expensive-discrimination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7059638564032783\n"
     ]
    }
   ],
   "source": [
    "rmse = mean_squared_error(y_valid, X_valid['item_cnt_month'].clip(0,20), squared=False)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-preparation",
   "metadata": {},
   "source": [
    "Optional: replace the predictions for shop 36 (if any) with the predictions for shop 37 from the same city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "armed-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "shop37 = X_test.loc[X_test.shop_id==37,:]\n",
    "X_test = X_test.loc[X_test.shop_id!=36,:]\n",
    "shop37.loc[:,'shop_id'] = 36\n",
    "X_test = pd.concat([X_test,shop37])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
